<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SinglePartitionReadCommand.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Cassandara Coverage Report</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.db</a> &gt; <span class="el_source">SinglePartitionReadCommand.java</span></div><h1>SinglePartitionReadCommand.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.cassandra.db;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.NavigableSet;
import java.util.TreeSet;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.Sets;

import org.apache.cassandra.cache.IRowCacheEntry;
import org.apache.cassandra.cache.RowCacheKey;
import org.apache.cassandra.cache.RowCacheSentinel;
import org.apache.cassandra.config.DatabaseDescriptor;
import org.apache.cassandra.db.filter.ClusteringIndexFilter;
import org.apache.cassandra.db.filter.ClusteringIndexNamesFilter;
import org.apache.cassandra.db.filter.ClusteringIndexSliceFilter;
import org.apache.cassandra.db.filter.ColumnFilter;
import org.apache.cassandra.db.filter.DataLimits;
import org.apache.cassandra.db.filter.RowFilter;
import org.apache.cassandra.db.lifecycle.SSTableSet;
import org.apache.cassandra.db.lifecycle.View;
import org.apache.cassandra.db.memtable.Memtable;
import org.apache.cassandra.db.partitions.CachedBTreePartition;
import org.apache.cassandra.db.partitions.CachedPartition;
import org.apache.cassandra.db.partitions.ImmutableBTreePartition;
import org.apache.cassandra.db.partitions.PartitionIterator;
import org.apache.cassandra.db.partitions.PartitionIterators;
import org.apache.cassandra.db.partitions.SingletonUnfilteredPartitionIterator;
import org.apache.cassandra.db.partitions.UnfilteredPartitionIterator;
import org.apache.cassandra.db.rows.Cell;
import org.apache.cassandra.db.rows.Row;
import org.apache.cassandra.db.rows.Rows;
import org.apache.cassandra.db.rows.Unfiltered;
import org.apache.cassandra.db.rows.UnfilteredRowIterator;
import org.apache.cassandra.db.rows.UnfilteredRowIteratorWithLowerBound;
import org.apache.cassandra.db.rows.UnfilteredRowIterators;
import org.apache.cassandra.db.rows.WrappingUnfilteredRowIterator;
import org.apache.cassandra.db.transform.RTBoundValidator;
import org.apache.cassandra.db.transform.Transformation;
import org.apache.cassandra.db.virtual.VirtualKeyspaceRegistry;
import org.apache.cassandra.db.virtual.VirtualTable;
import org.apache.cassandra.exceptions.RequestExecutionException;
import org.apache.cassandra.index.Index;
import org.apache.cassandra.io.sstable.SSTableReadsListener;
import org.apache.cassandra.io.sstable.format.SSTableReader;
import org.apache.cassandra.io.util.DataInputPlus;
import org.apache.cassandra.io.util.DataOutputPlus;
import org.apache.cassandra.metrics.TableMetrics;
import org.apache.cassandra.net.Verb;
import org.apache.cassandra.schema.ColumnMetadata;
import org.apache.cassandra.schema.TableMetadata;
import org.apache.cassandra.service.CacheService;
import org.apache.cassandra.service.ClientState;
import org.apache.cassandra.service.StorageProxy;
import org.apache.cassandra.tracing.Tracing;
import org.apache.cassandra.utils.FBUtilities;
import org.apache.cassandra.utils.btree.BTreeSet;

/**
 * A read command that selects a (part of a) single partition.
 */
public class SinglePartitionReadCommand extends ReadCommand implements SinglePartitionReadQuery
{
<span class="fc" id="L88">    protected static final SelectionDeserializer selectionDeserializer = new Deserializer();</span>

    protected final DecoratedKey partitionKey;
    protected final ClusteringIndexFilter clusteringIndexFilter;

    @VisibleForTesting
    protected SinglePartitionReadCommand(boolean isDigest,
                                         int digestVersion,
                                         boolean acceptsTransient,
                                         TableMetadata metadata,
                                         long nowInSec,
                                         ColumnFilter columnFilter,
                                         RowFilter rowFilter,
                                         DataLimits limits,
                                         DecoratedKey partitionKey,
                                         ClusteringIndexFilter clusteringIndexFilter,
                                         Index.QueryPlan indexQueryPlan,
                                         boolean trackWarnings)
    {
<span class="fc" id="L107">        super(Kind.SINGLE_PARTITION, isDigest, digestVersion, acceptsTransient, metadata, nowInSec, columnFilter, rowFilter, limits, indexQueryPlan, trackWarnings);</span>
<span class="pc bpc" id="L108" title="1 of 2 branches missed.">        assert partitionKey.getPartitioner() == metadata.partitioner;</span>
<span class="fc" id="L109">        this.partitionKey = partitionKey;</span>
<span class="fc" id="L110">        this.clusteringIndexFilter = clusteringIndexFilter;</span>
<span class="fc" id="L111">    }</span>

    private static SinglePartitionReadCommand create(boolean isDigest,
                                                    int digestVersion,
                                                    boolean acceptsTransient,
                                                    TableMetadata metadata,
                                                    long nowInSec,
                                                    ColumnFilter columnFilter,
                                                    RowFilter rowFilter,
                                                    DataLimits limits,
                                                    DecoratedKey partitionKey,
                                                    ClusteringIndexFilter clusteringIndexFilter,
                                                    Index.QueryPlan indexQueryPlan,
                                                    boolean trackWarnings)
    {
<span class="fc bfc" id="L126" title="All 2 branches covered.">        if (metadata.isVirtual())</span>
        {
<span class="fc" id="L128">            return new VirtualTableSinglePartitionReadCommand(isDigest,</span>
                                                              digestVersion,
                                                              acceptsTransient,
                                                              metadata,
                                                              nowInSec,
                                                              columnFilter,
                                                              rowFilter,
                                                              limits,
                                                              partitionKey,
                                                              clusteringIndexFilter,
                                                              indexQueryPlan,
                                                              trackWarnings);
        }
<span class="fc" id="L141">        return new SinglePartitionReadCommand(isDigest,</span>
                                              digestVersion,
                                              acceptsTransient,
                                              metadata,
                                              nowInSec,
                                              columnFilter,
                                              rowFilter,
                                              limits,
                                              partitionKey,
                                              clusteringIndexFilter,
                                              indexQueryPlan,
                                              trackWarnings);
    }

    /**
     * Creates a new read command on a single partition.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param columnFilter the column filter to use for the query.
     * @param rowFilter the row filter to use for the query.
     * @param limits the limits to use for the query.
     * @param partitionKey the partition key for the partition to query.
     * @param clusteringIndexFilter the clustering index filter to use for the query.
     * @param indexQueryPlan explicitly specified index to use for the query
     *
     * @return a newly created read command.
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata,
                                                    long nowInSec,
                                                    ColumnFilter columnFilter,
                                                    RowFilter rowFilter,
                                                    DataLimits limits,
                                                    DecoratedKey partitionKey,
                                                    ClusteringIndexFilter clusteringIndexFilter,
                                                    Index.QueryPlan indexQueryPlan)
    {
<span class="fc" id="L178">        return create(false,</span>
                      0,
                      false,
                      metadata,
                      nowInSec,
                      columnFilter,
                      rowFilter,
                      limits,
                      partitionKey,
                      clusteringIndexFilter,
                      indexQueryPlan,
                      false);
    }

    /**
     * Creates a new read command on a single partition.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param columnFilter the column filter to use for the query.
     * @param rowFilter the row filter to use for the query.
     * @param limits the limits to use for the query.
     * @param partitionKey the partition key for the partition to query.
     * @param clusteringIndexFilter the clustering index filter to use for the query.
     *
     * @return a newly created read command.
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata,
                                                    long nowInSec,
                                                    ColumnFilter columnFilter,
                                                    RowFilter rowFilter,
                                                    DataLimits limits,
                                                    DecoratedKey partitionKey,
                                                    ClusteringIndexFilter clusteringIndexFilter)
    {
<span class="fc" id="L213">        return create(metadata,</span>
                      nowInSec,
                      columnFilter,
                      rowFilter,
                      limits,
                      partitionKey,
                      clusteringIndexFilter,
<span class="fc" id="L220">                      findIndexQueryPlan(metadata, rowFilter));</span>
    }

    /**
     * Creates a new read command on a single partition.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     * @param columnFilter the column filter to use for the query.
     * @param filter the clustering index filter to use for the query.
     *
     * @return a newly created read command. The returned command will use no row filter and have no limits.
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata,
                                                    long nowInSec,
                                                    DecoratedKey key,
                                                    ColumnFilter columnFilter,
                                                    ClusteringIndexFilter filter)
    {
<span class="fc" id="L240">        return create(metadata, nowInSec, columnFilter, RowFilter.none(), DataLimits.NONE, key, filter);</span>
    }

    /**
     * Creates a new read command that queries a single partition in its entirety.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     *
     * @return a newly created read command that queries all the rows of {@code key}.
     */
    public static SinglePartitionReadCommand fullPartitionRead(TableMetadata metadata, long nowInSec, DecoratedKey key)
    {
<span class="nc" id="L254">        return create(metadata, nowInSec, key, Slices.ALL);</span>
    }

    /**
     * Creates a new read command that queries a single partition in its entirety.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     *
     * @return a newly created read command that queries all the rows of {@code key}.
     */
    public static SinglePartitionReadCommand fullPartitionRead(TableMetadata metadata, long nowInSec, ByteBuffer key)
    {
<span class="nc" id="L268">        return create(metadata, nowInSec, metadata.partitioner.decorateKey(key), Slices.ALL);</span>
    }

    /**
     * Creates a new single partition slice command for the provided single slice.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     * @param slice the slice of rows to query.
     *
     * @return a newly created read command that queries {@code slice} in {@code key}. The returned query will
     * query every columns for the table (without limit or row filtering) and be in forward order.
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata, long nowInSec, DecoratedKey key, Slice slice)
    {
<span class="nc" id="L284">        return create(metadata, nowInSec, key, Slices.with(metadata.comparator, slice));</span>
    }

    /**
     * Creates a new single partition slice command for the provided slices.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     * @param slices the slices of rows to query.
     *
     * @return a newly created read command that queries the {@code slices} in {@code key}. The returned query will
     * query every columns for the table (without limit or row filtering) and be in forward order.
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata, long nowInSec, DecoratedKey key, Slices slices)
    {
<span class="nc" id="L300">        ClusteringIndexSliceFilter filter = new ClusteringIndexSliceFilter(slices, false);</span>
<span class="nc" id="L301">        return create(metadata, nowInSec, ColumnFilter.all(metadata), RowFilter.none(), DataLimits.NONE, key, filter);</span>
    }

    /**
     * Creates a new single partition slice command for the provided slices.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     * @param slices the slices of rows to query.
     *
     * @return a newly created read command that queries the {@code slices} in {@code key}. The returned query will
     * query every columns for the table (without limit or row filtering) and be in forward order.
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata, long nowInSec, ByteBuffer key, Slices slices)
    {
<span class="nc" id="L317">        return create(metadata, nowInSec, metadata.partitioner.decorateKey(key), slices);</span>
    }

    /**
     * Creates a new single partition name command for the provided rows.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     * @param names the clustering for the rows to query.
     *
     * @return a newly created read command that queries the {@code names} in {@code key}. The returned query will
     * query every columns (without limit or row filtering) and be in forward order.
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata, long nowInSec, DecoratedKey key, NavigableSet&lt;Clustering&lt;?&gt;&gt; names)
    {
<span class="nc" id="L333">        ClusteringIndexNamesFilter filter = new ClusteringIndexNamesFilter(names, false);</span>
<span class="nc" id="L334">        return create(metadata, nowInSec, ColumnFilter.all(metadata), RowFilter.none(), DataLimits.NONE, key, filter);</span>
    }

    /**
     * Creates a new single partition name command for the provided row.
     *
     * @param metadata the table to query.
     * @param nowInSec the time in seconds to use are &quot;now&quot; for this query.
     * @param key the partition key for the partition to query.
     * @param name the clustering for the row to query.
     *
     * @return a newly created read command that queries {@code name} in {@code key}. The returned query will
     * query every columns (without limit or row filtering).
     */
    public static SinglePartitionReadCommand create(TableMetadata metadata, long nowInSec, DecoratedKey key, Clustering&lt;?&gt; name)
    {
<span class="nc" id="L350">        return create(metadata, nowInSec, key, FBUtilities.singleton(name, metadata.comparator));</span>
    }

    public SinglePartitionReadCommand copy()
    {
<span class="nc" id="L355">        return create(isDigestQuery(),</span>
<span class="nc" id="L356">                      digestVersion(),</span>
<span class="nc" id="L357">                      acceptsTransient(),</span>
<span class="nc" id="L358">                      metadata(),</span>
<span class="nc" id="L359">                      nowInSec(),</span>
<span class="nc" id="L360">                      columnFilter(),</span>
<span class="nc" id="L361">                      rowFilter(),</span>
<span class="nc" id="L362">                      limits(),</span>
<span class="nc" id="L363">                      partitionKey(),</span>
<span class="nc" id="L364">                      clusteringIndexFilter(),</span>
<span class="nc" id="L365">                      indexQueryPlan(),</span>
<span class="nc" id="L366">                      isTrackingWarnings());</span>
    }

    @Override
    protected SinglePartitionReadCommand copyAsDigestQuery()
    {
<span class="fc" id="L372">        return create(true,</span>
<span class="fc" id="L373">                      digestVersion(),</span>
<span class="fc" id="L374">                      acceptsTransient(),</span>
<span class="fc" id="L375">                      metadata(),</span>
<span class="fc" id="L376">                      nowInSec(),</span>
<span class="fc" id="L377">                      columnFilter(),</span>
<span class="fc" id="L378">                      rowFilter(),</span>
<span class="fc" id="L379">                      limits(),</span>
<span class="fc" id="L380">                      partitionKey(),</span>
<span class="fc" id="L381">                      clusteringIndexFilter(),</span>
<span class="fc" id="L382">                      indexQueryPlan(),</span>
<span class="fc" id="L383">                      isTrackingWarnings());</span>
    }

    @Override
    protected SinglePartitionReadCommand copyAsTransientQuery()
    {
<span class="fc" id="L389">        return create(false,</span>
                      0,
                      true,
<span class="fc" id="L392">                      metadata(),</span>
<span class="fc" id="L393">                      nowInSec(),</span>
<span class="fc" id="L394">                      columnFilter(),</span>
<span class="fc" id="L395">                      rowFilter(),</span>
<span class="fc" id="L396">                      limits(),</span>
<span class="fc" id="L397">                      partitionKey(),</span>
<span class="fc" id="L398">                      clusteringIndexFilter(),</span>
<span class="fc" id="L399">                      indexQueryPlan(),</span>
<span class="fc" id="L400">                      isTrackingWarnings());</span>
    }

    @Override
    public SinglePartitionReadCommand withUpdatedLimit(DataLimits newLimits)
    {
<span class="nc" id="L406">        return create(isDigestQuery(),</span>
<span class="nc" id="L407">                      digestVersion(),</span>
<span class="nc" id="L408">                      acceptsTransient(),</span>
<span class="nc" id="L409">                      metadata(),</span>
<span class="nc" id="L410">                      nowInSec(),</span>
<span class="nc" id="L411">                      columnFilter(),</span>
<span class="nc" id="L412">                      rowFilter(),</span>
                      newLimits,
<span class="nc" id="L414">                      partitionKey(),</span>
<span class="nc" id="L415">                      clusteringIndexFilter(),</span>
<span class="nc" id="L416">                      indexQueryPlan(),</span>
<span class="nc" id="L417">                      isTrackingWarnings());</span>
    }

    @Override
    public DecoratedKey partitionKey()
    {
<span class="fc" id="L423">        return partitionKey;</span>
    }

    @Override
    public ClusteringIndexFilter clusteringIndexFilter()
    {
<span class="fc" id="L429">        return clusteringIndexFilter;</span>
    }

    public ClusteringIndexFilter clusteringIndexFilter(DecoratedKey key)
    {
<span class="nc" id="L434">        return clusteringIndexFilter;</span>
    }

    public long getTimeout(TimeUnit unit)
    {
<span class="fc" id="L439">        return DatabaseDescriptor.getReadRpcTimeout(unit);</span>
    }

    public boolean isReversed()
    {
<span class="fc" id="L444">        return clusteringIndexFilter.isReversed();</span>
    }

    @Override
    public SinglePartitionReadCommand forPaging(Clustering&lt;?&gt; lastReturned, DataLimits limits)
    {
        // We shouldn't have set digest yet when reaching that point
<span class="pc bpc" id="L451" title="1 of 2 branches missed.">        assert !isDigestQuery();</span>
<span class="fc" id="L452">        SinglePartitionReadCommand cmd = create(metadata(),</span>
<span class="fc" id="L453">                                                nowInSec(),</span>
<span class="fc" id="L454">                                                columnFilter(),</span>
<span class="fc" id="L455">                                                rowFilter(),</span>
                                                limits,
<span class="fc" id="L457">                                                partitionKey(),</span>
<span class="pc bpc" id="L458" title="1 of 2 branches missed.">                                                lastReturned == null ? clusteringIndexFilter() : clusteringIndexFilter.forPaging(metadata().comparator, lastReturned, false));</span>
<span class="pc bpc" id="L459" title="1 of 2 branches missed.">        if (isTrackingWarnings())</span>
<span class="fc" id="L460">            cmd.trackWarnings();</span>
<span class="fc" id="L461">        return cmd;</span>
    }

    @Override
    public PartitionIterator execute(ConsistencyLevel consistency, ClientState state, long queryStartNanoTime) throws RequestExecutionException
    {
<span class="pc bpc" id="L467" title="1 of 2 branches missed.">        if (clusteringIndexFilter.isEmpty(metadata().comparator))</span>
<span class="nc" id="L468">            return EmptyIterators.partition();</span>

<span class="fc" id="L470">        return StorageProxy.read(Group.one(this), consistency, queryStartNanoTime);</span>
    }

    protected void recordLatency(TableMetrics metric, long latencyNanos)
    {
<span class="fc" id="L475">        metric.readLatency.addNano(latencyNanos);</span>
<span class="fc" id="L476">    }</span>

    @SuppressWarnings(&quot;resource&quot;) // we close the created iterator through closing the result of this method (and SingletonUnfilteredPartitionIterator ctor cannot fail)
    protected UnfilteredPartitionIterator queryStorage(final ColumnFamilyStore cfs, ReadExecutionController executionController)
    {
        // skip the row cache and go directly to sstables/memtable if repaired status of
        // data is being tracked. This is only requested after an initial digest mismatch
<span class="pc bpc" id="L483" title="3 of 4 branches missed.">        UnfilteredRowIterator partition = cfs.isRowCacheEnabled() &amp;&amp; !executionController.isTrackingRepairedStatus()</span>
<span class="nc" id="L484">                                        ? getThroughCache(cfs, executionController)</span>
<span class="fc" id="L485">                                        : queryMemtableAndDisk(cfs, executionController);</span>
<span class="fc" id="L486">        return new SingletonUnfilteredPartitionIterator(partition);</span>
    }

    /**
     * Fetch the rows requested if in cache; if not, read it from disk and cache it.
     * &lt;p&gt;
     * If the partition is cached, and the filter given is within its bounds, we return
     * from cache, otherwise from disk.
     * &lt;p&gt;
     * If the partition is is not cached, we figure out what filter is &quot;biggest&quot;, read
     * that from disk, then filter the result and either cache that or return it.
     */
    @SuppressWarnings(&quot;resource&quot;)
    private UnfilteredRowIterator getThroughCache(ColumnFamilyStore cfs, ReadExecutionController executionController)
    {
<span class="nc bnc" id="L501" title="All 2 branches missed.">        assert !cfs.isIndex(); // CASSANDRA-5732</span>
<span class="nc bnc" id="L502" title="All 2 branches missed.">        assert cfs.isRowCacheEnabled() : String.format(&quot;Row cache is not enabled on table [%s]&quot;, cfs.name);</span>

<span class="nc" id="L504">        RowCacheKey key = new RowCacheKey(metadata(), partitionKey());</span>

        // Attempt a sentinel-read-cache sequence.  if a write invalidates our sentinel, we'll return our
        // (now potentially obsolete) data, but won't cache it. see CASSANDRA-3862
        // TODO: don't evict entire partitions on writes (#2864)
<span class="nc" id="L509">        IRowCacheEntry cached = CacheService.instance.rowCache.get(key);</span>
<span class="nc bnc" id="L510" title="All 2 branches missed.">        if (cached != null)</span>
        {
<span class="nc bnc" id="L512" title="All 2 branches missed.">            if (cached instanceof RowCacheSentinel)</span>
            {
                // Some other read is trying to cache the value, just do a normal non-caching read
<span class="nc" id="L515">                Tracing.trace(&quot;Row cache miss (race)&quot;);</span>
<span class="nc" id="L516">                cfs.metric.rowCacheMiss.inc();</span>
<span class="nc" id="L517">                return queryMemtableAndDisk(cfs, executionController);</span>
            }

<span class="nc" id="L520">            CachedPartition cachedPartition = (CachedPartition)cached;</span>
<span class="nc bnc" id="L521" title="All 2 branches missed.">            if (cfs.isFilterFullyCoveredBy(clusteringIndexFilter(), limits(), cachedPartition, nowInSec(), metadata().enforceStrictLiveness()))</span>
            {
<span class="nc" id="L523">                cfs.metric.rowCacheHit.inc();</span>
<span class="nc" id="L524">                Tracing.trace(&quot;Row cache hit&quot;);</span>
<span class="nc" id="L525">                UnfilteredRowIterator unfilteredRowIterator = clusteringIndexFilter().getUnfilteredRowIterator(columnFilter(), cachedPartition);</span>
<span class="nc" id="L526">                cfs.metric.updateSSTableIterated(0);</span>
<span class="nc" id="L527">                return unfilteredRowIterator;</span>
            }

<span class="nc" id="L530">            cfs.metric.rowCacheHitOutOfRange.inc();</span>
<span class="nc" id="L531">            Tracing.trace(&quot;Ignoring row cache as cached value could not satisfy query&quot;);</span>
<span class="nc" id="L532">            return queryMemtableAndDisk(cfs, executionController);</span>
        }

<span class="nc" id="L535">        cfs.metric.rowCacheMiss.inc();</span>
<span class="nc" id="L536">        Tracing.trace(&quot;Row cache miss&quot;);</span>

        // Note that on tables with no clustering keys, any positive value of
        // rowsToCache implies caching the full partition
<span class="nc bnc" id="L540" title="All 2 branches missed.">        boolean cacheFullPartitions = metadata().clusteringColumns().size() &gt; 0 ?</span>
<span class="nc" id="L541">                                      metadata().params.caching.cacheAllRows() :</span>
<span class="nc" id="L542">                                      metadata().params.caching.cacheRows();</span>

        // To be able to cache what we read, what we read must at least covers what the cache holds, that
        // is the 'rowsToCache' first rows of the partition. We could read those 'rowsToCache' first rows
        // systematically, but we'd have to &quot;extend&quot; that to whatever is needed for the user query that the
        // 'rowsToCache' first rows don't cover and it's not trivial with our existing filters. So currently
        // we settle for caching what we read only if the user query does query the head of the partition since
        // that's the common case of when we'll be able to use the cache anyway. One exception is if we cache
        // full partitions, in which case we just always read it all and cache.
<span class="nc bnc" id="L551" title="All 4 branches missed.">        if (cacheFullPartitions || clusteringIndexFilter().isHeadFilter())</span>
        {
<span class="nc" id="L553">            RowCacheSentinel sentinel = new RowCacheSentinel();</span>
<span class="nc" id="L554">            boolean sentinelSuccess = CacheService.instance.rowCache.putIfAbsent(key, sentinel);</span>
<span class="nc" id="L555">            boolean sentinelReplaced = false;</span>

            try
            {
<span class="nc" id="L559">                final int rowsToCache = metadata().params.caching.rowsPerPartitionToCache();</span>
<span class="nc" id="L560">                final boolean enforceStrictLiveness = metadata().enforceStrictLiveness();</span>

                @SuppressWarnings(&quot;resource&quot;) // we close on exception or upon closing the result of this method
<span class="nc" id="L563">                UnfilteredRowIterator iter = fullPartitionRead(metadata(), nowInSec(), partitionKey()).queryMemtableAndDisk(cfs, executionController);</span>
                try
                {
                    // Use a custom iterator instead of DataLimits to avoid stopping the original iterator
<span class="nc" id="L567">                    UnfilteredRowIterator toCacheIterator = new WrappingUnfilteredRowIterator()</span>
                    {
                        private int rowsCounted = 0;

                        @Override
                        public UnfilteredRowIterator wrapped()
                        {
                            return iter;
                        }

                        @Override
                        public boolean hasNext()
                        {
                            return rowsCounted &lt; rowsToCache &amp;&amp; iter.hasNext();
                        }

                        @Override
                        public Unfiltered next()
                        {
                            Unfiltered unfiltered = iter.next();
                            if (unfiltered.isRow())
                            {
                                Row row = (Row) unfiltered;
                                if (row.hasLiveData(nowInSec(), enforceStrictLiveness))
                                    rowsCounted++;
                            }
                            return unfiltered;
                        }
                    };

                    // We want to cache only rowsToCache rows
<span class="nc" id="L598">                    CachedPartition toCache = CachedBTreePartition.create(toCacheIterator, nowInSec());</span>
<span class="nc bnc" id="L599" title="All 4 branches missed.">                    if (sentinelSuccess &amp;&amp; !toCache.isEmpty())</span>
                    {
<span class="nc" id="L601">                        Tracing.trace(&quot;Caching {} rows&quot;, toCache.rowCount());</span>
<span class="nc" id="L602">                        CacheService.instance.rowCache.replace(key, sentinel, toCache);</span>
                        // Whether or not the previous replace has worked, our sentinel is not in the cache anymore
<span class="nc" id="L604">                        sentinelReplaced = true;</span>
                    }

                    // We then re-filter out what this query wants.
                    // Note that in the case where we don't cache full partitions, it's possible that the current query is interested in more
                    // than what we've cached, so we can't just use toCache.
<span class="nc" id="L610">                    UnfilteredRowIterator cacheIterator = clusteringIndexFilter().getUnfilteredRowIterator(columnFilter(), toCache);</span>
<span class="nc bnc" id="L611" title="All 2 branches missed.">                    if (cacheFullPartitions)</span>
                    {
                        // Everything is guaranteed to be in 'toCache', we're done with 'iter'
<span class="nc bnc" id="L614" title="All 2 branches missed.">                        assert !iter.hasNext();</span>
<span class="nc" id="L615">                        iter.close();</span>
<span class="nc" id="L616">                        return cacheIterator;</span>
                    }
<span class="nc" id="L618">                    return UnfilteredRowIterators.concat(cacheIterator, clusteringIndexFilter().filterNotIndexed(columnFilter(), iter));</span>
                }
<span class="nc" id="L620">                catch (RuntimeException | Error e)</span>
                {
<span class="nc" id="L622">                    iter.close();</span>
<span class="nc" id="L623">                    throw e;</span>
                }
            }
            finally
            {
<span class="nc bnc" id="L628" title="All 4 branches missed.">                if (sentinelSuccess &amp;&amp; !sentinelReplaced)</span>
<span class="nc" id="L629">                    cfs.invalidateCachedPartition(key);</span>
            }
        }

<span class="nc" id="L633">        Tracing.trace(&quot;Fetching data but not populating cache as query does not query from the start of the partition&quot;);</span>
<span class="nc" id="L634">        return queryMemtableAndDisk(cfs, executionController);</span>
    }

    /**
     * Queries both memtable and sstables to fetch the result of this query.
     * &lt;p&gt;
     * Please note that this method:
     *   1) does not check the row cache.
     *   2) does not apply the query limit, nor the row filter (and so ignore 2ndary indexes).
     *      Those are applied in {@link ReadCommand#executeLocally}.
     *   3) does not record some of the read metrics (latency, scanned cells histograms) nor
     *      throws TombstoneOverwhelmingException.
     * It is publicly exposed because there is a few places where that is exactly what we want,
     * but it should be used only where you know you don't need thoses things.
     * &lt;p&gt;
     * Also note that one must have created a {@code ReadExecutionController} on the queried table and we require it as
     * a parameter to enforce that fact, even though it's not explicitlly used by the method.
     */
    public UnfilteredRowIterator queryMemtableAndDisk(ColumnFamilyStore cfs, ReadExecutionController executionController)
    {
<span class="pc bpc" id="L654" title="2 of 4 branches missed.">        assert executionController != null &amp;&amp; executionController.validForReadOn(cfs);</span>
<span class="fc" id="L655">        Tracing.trace(&quot;Executing single-partition query on {}&quot;, cfs.name);</span>

<span class="fc" id="L657">        return queryMemtableAndDiskInternal(cfs, executionController);</span>
    }

    private UnfilteredRowIterator queryMemtableAndDiskInternal(ColumnFamilyStore cfs, ReadExecutionController controller)
    {
        /*
         * We have 2 main strategies:
         *   1) We query memtables and sstables simulateneously. This is our most generic strategy and the one we use
         *      unless we have a names filter that we know we can optimize futher.
         *   2) If we have a name filter (so we query specific rows), we can make a bet: that all column for all queried row
         *      will have data in the most recent sstable(s), thus saving us from reading older ones. This does imply we
         *      have a way to guarantee we have all the data for what is queried, which is only possible for name queries
         *      and if we have neither non-frozen collections/UDTs nor counters.
         *      If a non-frozen collection or UDT is queried we can't guarantee that an older sstable won't have some
         *      elements that weren't in the most recent sstables.
         *      Counters are intrinsically a collection of shards and so have the same problem.
         *      Counter tables are also special in the sense that their rows do not have primary key liveness
         *      as INSERT statements are not supported on counter tables. Due to that even if only the primary key
         *      columns where queried, querying SSTables in timestamp order will always be less efficient for counter tables.
         *      Also, if tracking repaired data then we skip this optimization so we can collate the repaired sstables
         *      and generate a digest over their merge, which procludes an early return.
         */
<span class="fc bfc" id="L679" title="All 2 branches covered.">        if (clusteringIndexFilter() instanceof ClusteringIndexNamesFilter</span>
<span class="pc bpc" id="L680" title="1 of 2 branches missed.">            &amp;&amp; !metadata().isCounter()</span>
<span class="fc bfc" id="L681" title="All 2 branches covered.">            &amp;&amp; !queriesMulticellType()</span>
<span class="pc bpc" id="L682" title="1 of 2 branches missed.">            &amp;&amp; !controller.isTrackingRepairedStatus())</span>
        {
<span class="fc" id="L684">            return queryMemtableAndSSTablesInTimestampOrder(cfs, (ClusteringIndexNamesFilter)clusteringIndexFilter(), controller);</span>
        }

<span class="fc" id="L687">        Tracing.trace(&quot;Acquiring sstable references&quot;);</span>
<span class="fc" id="L688">        ColumnFamilyStore.ViewFragment view = cfs.select(View.select(SSTableSet.LIVE, partitionKey()));</span>
<span class="fc" id="L689">        view.sstables.sort(SSTableReader.maxTimestampDescending);</span>
<span class="fc" id="L690">        ClusteringIndexFilter filter = clusteringIndexFilter();</span>
<span class="fc" id="L691">        long minTimestamp = Long.MAX_VALUE;</span>
<span class="fc" id="L692">        long mostRecentPartitionTombstone = Long.MIN_VALUE;</span>
<span class="fc" id="L693">        InputCollector&lt;UnfilteredRowIterator&gt; inputCollector = iteratorsForPartition(view, controller);</span>
        try
        {
<span class="fc" id="L696">            SSTableReadMetricsCollector metricsCollector = new SSTableReadMetricsCollector();</span>

<span class="fc bfc" id="L698" title="All 2 branches covered.">            for (Memtable memtable : view.memtables)</span>
            {
                @SuppressWarnings(&quot;resource&quot;) // 'iter' is added to iterators which is closed on exception, or through the closing of the final merged iterator
<span class="fc" id="L701">                UnfilteredRowIterator iter = memtable.rowIterator(partitionKey(), filter.getSlices(metadata()), columnFilter(), filter.isReversed(), metricsCollector);</span>
<span class="fc bfc" id="L702" title="All 2 branches covered.">                if (iter == null)</span>
<span class="fc" id="L703">                    continue;</span>

<span class="pc bpc" id="L705" title="1 of 2 branches missed.">                if (memtable.getMinTimestamp() != Memtable.NO_MIN_TIMESTAMP)</span>
<span class="fc" id="L706">                    minTimestamp = Math.min(minTimestamp, memtable.getMinTimestamp());</span>

                // Memtable data is always considered unrepaired
<span class="fc" id="L709">                controller.updateMinOldestUnrepairedTombstone(memtable.getMinLocalDeletionTime());</span>
<span class="fc" id="L710">                inputCollector.addMemtableIterator(RTBoundValidator.validate(iter, RTBoundValidator.Stage.MEMTABLE, false));</span>

<span class="fc" id="L712">                mostRecentPartitionTombstone = Math.max(mostRecentPartitionTombstone,</span>
<span class="fc" id="L713">                                                        iter.partitionLevelDeletion().markedForDeleteAt());</span>
<span class="fc" id="L714">            }</span>

            /*
             * We can't eliminate full sstables based on the timestamp of what we've already read like
             * in collectTimeOrderedData, but we still want to eliminate sstable whose maxTimestamp &lt; mostRecentTombstone
             * we've read. We still rely on the sstable ordering by maxTimestamp since if
             *   maxTimestamp_s1 &lt; maxTimestamp_s0,
             * we're guaranteed that s1 cannot have a row tombstone such that
             *   timestamp(tombstone) &gt; maxTimestamp_s0
             * since we necessarily have
             *   timestamp(tombstone) &lt;= maxTimestamp_s1
             * In other words, iterating in descending maxTimestamp order allow to do our mostRecentPartitionTombstone
             * elimination in one pass, and minimize the number of sstables for which we read a partition tombstone.
            */
<span class="fc" id="L728">            view.sstables.sort(SSTableReader.maxTimestampDescending);</span>
<span class="fc" id="L729">            int nonIntersectingSSTables = 0;</span>
<span class="fc" id="L730">            int includedDueToTombstones = 0;</span>

<span class="pc bpc" id="L732" title="1 of 2 branches missed.">            if (controller.isTrackingRepairedStatus())</span>
<span class="nc" id="L733">                Tracing.trace(&quot;Collecting data from sstables and tracking repaired status&quot;);</span>

<span class="fc bfc" id="L735" title="All 2 branches covered.">            for (SSTableReader sstable : view.sstables)</span>
            {
                // if we've already seen a partition tombstone with a timestamp greater
                // than the most recent update to this sstable, we can skip it
                // if we're tracking repaired status, we mark the repaired digest inconclusive
                // as other replicas may not have seen this partition delete and so could include
                // data from this sstable (or others) in their digests
<span class="pc bpc" id="L742" title="1 of 2 branches missed.">                if (sstable.getMaxTimestamp() &lt; mostRecentPartitionTombstone)</span>
                {
<span class="nc" id="L744">                    inputCollector.markInconclusive();</span>
<span class="nc" id="L745">                    break;</span>
                }

<span class="fc" id="L748">                boolean intersects = intersects(sstable);</span>
<span class="fc" id="L749">                boolean hasRequiredStatics = hasRequiredStatics(sstable);</span>
<span class="fc" id="L750">                boolean hasPartitionLevelDeletions = hasPartitionLevelDeletions(sstable);</span>

<span class="pc bpc" id="L752" title="1 of 6 branches missed.">                if (!intersects &amp;&amp; !hasRequiredStatics &amp;&amp; !hasPartitionLevelDeletions)</span>
                {
<span class="fc" id="L754">                    nonIntersectingSSTables++;</span>
<span class="fc" id="L755">                    continue;</span>
                }

<span class="pc bpc" id="L758" title="1 of 4 branches missed.">                if (intersects || hasRequiredStatics)</span>
                {
<span class="pc bpc" id="L760" title="1 of 2 branches missed.">                    if (!sstable.isRepaired())</span>
<span class="fc" id="L761">                        controller.updateMinOldestUnrepairedTombstone(sstable.getMinLocalDeletionTime());</span>

                    // 'iter' is added to iterators which is closed on exception, or through the closing of the final merged iterator
                    @SuppressWarnings(&quot;resource&quot;)
<span class="pc bpc" id="L765" title="1 of 2 branches missed.">                    UnfilteredRowIterator iter = intersects ? makeRowIteratorWithLowerBound(cfs, sstable, metricsCollector)</span>
<span class="pc" id="L766">                                                            : makeRowIteratorWithSkippedNonStaticContent(cfs, sstable, metricsCollector);</span>

<span class="fc" id="L768">                    inputCollector.addSSTableIterator(sstable, iter);</span>
<span class="fc" id="L769">                    mostRecentPartitionTombstone = Math.max(mostRecentPartitionTombstone,</span>
<span class="fc" id="L770">                                                            iter.partitionLevelDeletion().markedForDeleteAt());</span>
<span class="fc" id="L771">                }</span>
                else
                {
<span class="fc" id="L774">                    nonIntersectingSSTables++;</span>

                    // if the sstable contained range or cell tombstones, it would intersect; since we are here, it means
                    // that there are no cell or range tombstones we are interested in (due to the filter)
                    // however, we know that there are partition level deletions in this sstable and we need to make
                    // an iterator figure out that (see `StatsMetadata.hasPartitionLevelDeletions`)

                    // 'iter' is added to iterators which is closed on exception, or through the closing of the final merged iterator
                    @SuppressWarnings(&quot;resource&quot;)
<span class="fc" id="L783">                    UnfilteredRowIterator iter = makeRowIteratorWithSkippedNonStaticContent(cfs, sstable, metricsCollector);</span>

                    // if the sstable contains a partition delete, then we must include it regardless of whether it
                    // shadows any other data seen locally as we can't guarantee that other replicas have seen it
<span class="pc bpc" id="L787" title="1 of 2 branches missed.">                    if (!iter.partitionLevelDeletion().isLive())</span>
                    {
<span class="nc bnc" id="L789" title="All 2 branches missed.">                        if (!sstable.isRepaired())</span>
<span class="nc" id="L790">                            controller.updateMinOldestUnrepairedTombstone(sstable.getMinLocalDeletionTime());</span>
<span class="nc" id="L791">                        inputCollector.addSSTableIterator(sstable, iter);</span>
<span class="nc" id="L792">                        includedDueToTombstones++;</span>
<span class="nc" id="L793">                        mostRecentPartitionTombstone = Math.max(mostRecentPartitionTombstone,</span>
<span class="nc" id="L794">                                                                iter.partitionLevelDeletion().markedForDeleteAt());</span>
                    }
                    else
                    {
<span class="fc" id="L798">                        iter.close();</span>
                    }
                }
<span class="fc" id="L801">            }</span>

<span class="pc bpc" id="L803" title="1 of 2 branches missed.">            if (Tracing.isTracing())</span>
<span class="nc" id="L804">                Tracing.trace(&quot;Skipped {}/{} non-slice-intersecting sstables, included {} due to tombstones&quot;,</span>
<span class="nc" id="L805">                               nonIntersectingSSTables, view.sstables.size(), includedDueToTombstones);</span>

<span class="fc bfc" id="L807" title="All 2 branches covered.">            if (inputCollector.isEmpty())</span>
<span class="fc" id="L808">                return EmptyIterators.unfilteredRow(cfs.metadata(), partitionKey(), filter.isReversed());</span>

<span class="fc" id="L810">            StorageHook.instance.reportRead(cfs.metadata().id, partitionKey());</span>

<span class="fc" id="L812">            List&lt;UnfilteredRowIterator&gt; iterators = inputCollector.finalizeIterators(cfs, nowInSec(), controller.oldestUnrepairedTombstone());</span>
<span class="fc" id="L813">            return withSSTablesIterated(iterators, cfs.metric, metricsCollector);</span>
        }
<span class="nc" id="L815">        catch (RuntimeException | Error e)</span>
        {
            try
            {
<span class="nc" id="L819">                inputCollector.close();</span>
            }
<span class="nc" id="L821">            catch (Exception e1)</span>
            {
<span class="nc" id="L823">                e.addSuppressed(e1);</span>
<span class="nc" id="L824">            }</span>
<span class="nc" id="L825">            throw e;</span>
        }
    }

    @Override
    protected boolean intersects(SSTableReader sstable)
    {
<span class="fc" id="L832">        return clusteringIndexFilter().intersects(sstable.metadata().comparator, sstable.getSSTableMetadata().coveredClustering);</span>
    }

    private UnfilteredRowIteratorWithLowerBound makeRowIteratorWithLowerBound(ColumnFamilyStore cfs,
                                                                              SSTableReader sstable,
                                                                              SSTableReadsListener listener)
    {
<span class="fc" id="L839">        return StorageHook.instance.makeRowIteratorWithLowerBound(cfs,</span>
                                                                  sstable,
<span class="fc" id="L841">                                                                  partitionKey(),</span>
<span class="fc" id="L842">                                                                  clusteringIndexFilter(),</span>
<span class="fc" id="L843">                                                                  columnFilter(),</span>
                                                                  listener);

    }

    private UnfilteredRowIterator makeRowIterator(ColumnFamilyStore cfs,
                                                  SSTableReader sstable,
                                                  ClusteringIndexNamesFilter clusteringIndexFilter,
                                                  SSTableReadsListener listener)
    {
<span class="fc" id="L853">        return StorageHook.instance.makeRowIterator(cfs,</span>
                                                    sstable,
<span class="fc" id="L855">                                                    partitionKey(),</span>
<span class="fc" id="L856">                                                    clusteringIndexFilter.getSlices(cfs.metadata()),</span>
<span class="fc" id="L857">                                                    columnFilter(),</span>
<span class="fc" id="L858">                                                    clusteringIndexFilter.isReversed(),</span>
                                                    listener);
    }

    private UnfilteredRowIterator makeRowIteratorWithSkippedNonStaticContent(ColumnFamilyStore cfs,
                                                                             SSTableReader sstable,
                                                                             SSTableReadsListener listener)
    {
<span class="fc" id="L866">        return StorageHook.instance.makeRowIterator(cfs,</span>
                                                    sstable,
<span class="fc" id="L868">                                                    partitionKey(),</span>
                                                    Slices.NONE,
<span class="fc" id="L870">                                                    columnFilter(),</span>
<span class="fc" id="L871">                                                    clusteringIndexFilter().isReversed(),</span>
                                                    listener);
    }

    /**
     * Return a wrapped iterator that when closed will update the sstables iterated and READ sample metrics.
     * Note that we cannot use the Transformations framework because they greedily get the static row, which
     * would cause all iterators to be initialized and hence all sstables to be accessed.
     */
    @SuppressWarnings(&quot;resource&quot;)
    private UnfilteredRowIterator withSSTablesIterated(List&lt;UnfilteredRowIterator&gt; iterators,
                                                       TableMetrics metrics,
                                                       SSTableReadMetricsCollector metricsCollector)
    {
        @SuppressWarnings(&quot;resource&quot;) //  Closed through the closing of the result of the caller method.
<span class="fc" id="L886">        UnfilteredRowIterator merged = UnfilteredRowIterators.merge(iterators);</span>

<span class="fc bfc" id="L888" title="All 2 branches covered.">        if (!merged.isEmpty())</span>
        {
<span class="fc" id="L890">            DecoratedKey key = merged.partitionKey();</span>
<span class="fc" id="L891">            metrics.topReadPartitionFrequency.addSample(key.getKey(), 1);</span>
<span class="fc" id="L892">            metrics.topReadPartitionSSTableCount.addSample(key.getKey(), metricsCollector.getMergedSSTables());</span>
        }

<span class="fc" id="L895">        class UpdateSstablesIterated extends Transformation&lt;UnfilteredRowIterator&gt;</span>
        {
           public void onPartitionClose()
           {
<span class="fc" id="L899">               int mergedSSTablesIterated = metricsCollector.getMergedSSTables();</span>
<span class="fc" id="L900">               metrics.updateSSTableIterated(mergedSSTablesIterated);</span>
<span class="fc" id="L901">               Tracing.trace(&quot;Merged data from memtables and {} sstables&quot;, mergedSSTablesIterated);</span>
<span class="fc" id="L902">           }</span>
        }
<span class="fc" id="L904">        return Transformation.apply(merged, new UpdateSstablesIterated());</span>
    }

    private boolean queriesMulticellType()
    {
<span class="fc bfc" id="L909" title="All 2 branches covered.">        for (ColumnMetadata column : columnFilter().queriedColumns())</span>
        {
<span class="fc bfc" id="L911" title="All 2 branches covered.">            if (column.type.isMultiCell())</span>
<span class="fc" id="L912">                return true;</span>
<span class="fc" id="L913">        }</span>
<span class="fc" id="L914">        return false;</span>
    }

    /**
     * Do a read by querying the memtable(s) first, and then each relevant sstables sequentially by order of the sstable
     * max timestamp.
     *
     * This is used for names query in the hope of only having to query the 1 or 2 most recent query and then knowing nothing
     * more recent could be in the older sstables (which we can only guarantee if we know exactly which row we queries, and if
     * no collection or counters are included).
     * This method assumes the filter is a {@code ClusteringIndexNamesFilter}.
     */
    private UnfilteredRowIterator queryMemtableAndSSTablesInTimestampOrder(ColumnFamilyStore cfs, ClusteringIndexNamesFilter filter, ReadExecutionController controller)
    {
<span class="fc" id="L928">        Tracing.trace(&quot;Acquiring sstable references&quot;);</span>
<span class="fc" id="L929">        ColumnFamilyStore.ViewFragment view = cfs.select(View.select(SSTableSet.LIVE, partitionKey()));</span>

<span class="fc" id="L931">        ImmutableBTreePartition result = null;</span>
<span class="fc" id="L932">        SSTableReadMetricsCollector metricsCollector = new SSTableReadMetricsCollector();</span>

<span class="fc" id="L934">        Tracing.trace(&quot;Merging memtable contents&quot;);</span>
<span class="fc bfc" id="L935" title="All 2 branches covered.">        for (Memtable memtable : view.memtables)</span>
        {
<span class="fc" id="L937">            try (UnfilteredRowIterator iter = memtable.rowIterator(partitionKey, filter.getSlices(metadata()), columnFilter(), isReversed(), metricsCollector))</span>
            {
<span class="fc bfc" id="L939" title="All 2 branches covered.">                if (iter == null)</span>
                    continue;

<span class="fc" id="L942">                result = add(RTBoundValidator.validate(iter, RTBoundValidator.Stage.MEMTABLE, false),</span>
                             result,
                             filter,
                             false,
                             controller);
<span class="pc bpc" id="L947" title="1 of 2 branches missed.">            }</span>
<span class="fc" id="L948">        }</span>

        /* add the SSTables on disk */
<span class="fc" id="L951">        view.sstables.sort(SSTableReader.maxTimestampDescending);</span>
        // read sorted sstables
<span class="fc bfc" id="L953" title="All 2 branches covered.">        for (SSTableReader sstable : view.sstables)</span>
        {
            // if we've already seen a partition tombstone with a timestamp greater
            // than the most recent update to this sstable, we're done, since the rest of the sstables
            // will also be older
<span class="pc bpc" id="L958" title="1 of 4 branches missed.">            if (result != null &amp;&amp; sstable.getMaxTimestamp() &lt; result.partitionLevelDeletion().markedForDeleteAt())</span>
<span class="nc" id="L959">                break;</span>

<span class="fc" id="L961">            long currentMaxTs = sstable.getMaxTimestamp();</span>
<span class="fc" id="L962">            filter = reduceFilter(filter, result, currentMaxTs);</span>

<span class="fc bfc" id="L964" title="All 2 branches covered.">            if (filter == null)</span>
<span class="fc" id="L965">                break;</span>

<span class="fc" id="L967">            boolean intersects = intersects(sstable);</span>
<span class="fc" id="L968">            boolean hasRequiredStatics = hasRequiredStatics(sstable);</span>
<span class="fc" id="L969">            boolean hasPartitionLevelDeletions = hasPartitionLevelDeletions(sstable);</span>

<span class="pc bpc" id="L971" title="1 of 4 branches missed.">            if (!intersects &amp;&amp; !hasRequiredStatics)</span>
            {
                // This mean that nothing queried by the filter can be in the sstable. One exception is the top-level partition deletion
                // however: if it is set, it impacts everything and must be included. Getting that top-level partition deletion costs us
                // some seek in general however (unless the partition is indexed and is in the key cache), so we first check if the sstable
                // has any tombstone at all as a shortcut.
<span class="fc bfc" id="L977" title="All 2 branches covered.">                if (!hasPartitionLevelDeletions)</span>
<span class="fc" id="L978">                    continue; // no tombstone at all, we can skip that sstable</span>

                // We need to get the partition deletion and include it if it's live. In any case though, we're done with that sstable.
<span class="fc" id="L981">                try (UnfilteredRowIterator iter = makeRowIteratorWithSkippedNonStaticContent(cfs, sstable, metricsCollector))</span>
                {
<span class="pc bpc" id="L983" title="1 of 2 branches missed.">                    if (!iter.partitionLevelDeletion().isLive())</span>
                    {
<span class="nc" id="L985">                        result = add(UnfilteredRowIterators.noRowsIterator(iter.metadata(),</span>
<span class="nc" id="L986">                                                                           iter.partitionKey(),</span>
                                                                           Rows.EMPTY_STATIC_ROW,
<span class="nc" id="L988">                                                                           iter.partitionLevelDeletion(),</span>
<span class="nc" id="L989">                                                                           filter.isReversed()),</span>
                                     result,
                                     filter,
<span class="nc" id="L992">                                     sstable.isRepaired(),</span>
                                     controller);
                    }
                    else
                    {
<span class="fc" id="L997">                        result = add(RTBoundValidator.validate(iter, RTBoundValidator.Stage.SSTABLE, false),</span>
                                     result,
                                     filter,
<span class="fc" id="L1000">                                     sstable.isRepaired(),</span>
                                     controller);
                    }
                }

<span class="fc" id="L1005">                continue;</span>
            }

<span class="fc" id="L1008">            try (UnfilteredRowIterator iter = makeRowIterator(cfs, sstable, filter, metricsCollector))</span>
            {
<span class="fc bfc" id="L1010" title="All 2 branches covered.">                if (iter.isEmpty())</span>
                    continue;

<span class="fc" id="L1013">                result = add(RTBoundValidator.validate(iter, RTBoundValidator.Stage.SSTABLE, false),</span>
                             result,
                             filter,
<span class="fc" id="L1016">                             sstable.isRepaired(),</span>
                             controller);
<span class="pc bpc" id="L1018" title="1 of 2 branches missed.">            }</span>
<span class="fc" id="L1019">        }</span>

<span class="fc" id="L1021">        cfs.metric.updateSSTableIterated(metricsCollector.getMergedSSTables());</span>

<span class="fc bfc" id="L1023" title="All 4 branches covered.">        if (result == null || result.isEmpty())</span>
<span class="fc" id="L1024">            return EmptyIterators.unfilteredRow(metadata(), partitionKey(), false);</span>

<span class="fc" id="L1026">        DecoratedKey key = result.partitionKey();</span>
<span class="fc" id="L1027">        cfs.metric.topReadPartitionFrequency.addSample(key.getKey(), 1);</span>
<span class="fc" id="L1028">        cfs.metric.topReadPartitionSSTableCount.addSample(key.getKey(), metricsCollector.getMergedSSTables());</span>
<span class="fc" id="L1029">        StorageHook.instance.reportRead(cfs.metadata.id, partitionKey());</span>

<span class="fc" id="L1031">        return result.unfilteredIterator(columnFilter(), Slices.ALL, clusteringIndexFilter().isReversed());</span>
    }

    private ImmutableBTreePartition add(UnfilteredRowIterator iter, ImmutableBTreePartition result, ClusteringIndexNamesFilter filter, boolean isRepaired, ReadExecutionController controller)
    {
<span class="pc bpc" id="L1036" title="1 of 2 branches missed.">        if (!isRepaired)</span>
<span class="fc" id="L1037">            controller.updateMinOldestUnrepairedTombstone(iter.stats().minLocalDeletionTime);</span>

<span class="fc" id="L1039">        int maxRows = Math.max(filter.requestedRows().size(), 1);</span>
<span class="fc bfc" id="L1040" title="All 2 branches covered.">        if (result == null)</span>
<span class="fc" id="L1041">            return ImmutableBTreePartition.create(iter, maxRows);</span>

<span class="fc" id="L1043">        try (UnfilteredRowIterator merged = UnfilteredRowIterators.merge(Arrays.asList(iter, result.unfilteredIterator(columnFilter(), Slices.ALL, filter.isReversed()))))</span>
        {
<span class="fc" id="L1045">            return ImmutableBTreePartition.create(merged, maxRows);</span>
        }
    }

    private ClusteringIndexNamesFilter reduceFilter(ClusteringIndexNamesFilter filter, ImmutableBTreePartition result, long sstableTimestamp)
    {
<span class="fc bfc" id="L1051" title="All 2 branches covered.">        if (result == null)</span>
<span class="fc" id="L1052">            return filter;</span>

        // According to the CQL semantics a row exists if at least one of its columns is not null (including the primary key columns).
        // Having the queried columns not null is unfortunately not enough to prove that a row exists as some column deletion
        // for the queried columns can exist on another node.
        // For CQL tables it is enough to have the primary key liveness and the queried columns as the primary key liveness prove that
        // the row exists even if all the other columns are deleted.
        // COMPACT tables do not have primary key liveness and by consequence we are forced to get  all the fetched columns to ensure that
        // we can return the correct result if the queried columns are deleted on another node but one of the non-queried columns is not.
<span class="pc bpc" id="L1061" title="1 of 2 branches missed.">        RegularAndStaticColumns columns = metadata().isCompactTable() ? columnFilter().fetchedColumns() : columnFilter().queriedColumns();</span>

<span class="fc" id="L1063">        NavigableSet&lt;Clustering&lt;?&gt;&gt; clusterings = filter.requestedRows();</span>

        // We want to remove rows for which we have values for all requested columns. We have to deal with both static and regular rows.

<span class="fc" id="L1067">        boolean removeStatic = false;</span>
<span class="pc bpc" id="L1068" title="1 of 2 branches missed.">        if (!columns.statics.isEmpty())</span>
        {
<span class="nc" id="L1070">            Row staticRow = result.getRow(Clustering.STATIC_CLUSTERING);</span>
<span class="nc bnc" id="L1071" title="All 4 branches missed.">            removeStatic = staticRow != null &amp;&amp; isRowComplete(staticRow, columns.statics, sstableTimestamp);</span>
        }

<span class="fc" id="L1074">        NavigableSet&lt;Clustering&lt;?&gt;&gt; toRemove = null;</span>

<span class="fc" id="L1076">        DeletionInfo deletionInfo = result.deletionInfo();</span>

<span class="pc bpc" id="L1078" title="1 of 2 branches missed.">        if (deletionInfo.hasRanges())</span>
        {
<span class="nc bnc" id="L1080" title="All 2 branches missed.">            for (Clustering&lt;?&gt; clustering : clusterings)</span>
            {
<span class="nc" id="L1082">                RangeTombstone rt = deletionInfo.rangeCovering(clustering);</span>
<span class="nc bnc" id="L1083" title="All 4 branches missed.">                if (rt != null &amp;&amp; rt.deletionTime().deletes(sstableTimestamp))</span>
                {
<span class="nc bnc" id="L1085" title="All 2 branches missed.">                    if (toRemove == null)</span>
<span class="nc" id="L1086">                        toRemove = new TreeSet&lt;&gt;(result.metadata().comparator);</span>
<span class="nc" id="L1087">                    toRemove.add(clustering);</span>
                }
<span class="nc" id="L1089">            }</span>
        }

<span class="fc" id="L1092">        try (UnfilteredRowIterator iterator = result.unfilteredIterator(columnFilter(), clusterings, false))</span>
        {
<span class="fc bfc" id="L1094" title="All 2 branches covered.">            while (iterator.hasNext())</span>
            {
<span class="fc" id="L1096">                Unfiltered unfiltered = iterator.next();</span>
<span class="pc bpc" id="L1097" title="2 of 4 branches missed.">                if (unfiltered == null || !unfiltered.isRow())</span>
<span class="nc" id="L1098">                    continue;</span>

<span class="fc" id="L1100">                Row row = (Row) unfiltered;</span>
<span class="fc bfc" id="L1101" title="All 2 branches covered.">                if (!isRowComplete(row, columns.regulars, sstableTimestamp))</span>
<span class="fc" id="L1102">                    continue;</span>

<span class="pc bpc" id="L1104" title="1 of 2 branches missed.">                if (toRemove == null)</span>
<span class="fc" id="L1105">                    toRemove = new TreeSet&lt;&gt;(result.metadata().comparator);</span>
<span class="fc" id="L1106">                toRemove.add(row.clustering());</span>
<span class="fc" id="L1107">            }</span>
        }

<span class="pc bpc" id="L1110" title="1 of 4 branches missed.">        if (!removeStatic &amp;&amp; toRemove == null)</span>
<span class="fc" id="L1111">            return filter;</span>

        // Check if we have everything we need
<span class="pc bpc" id="L1114" title="3 of 4 branches missed.">        boolean hasNoMoreStatic = columns.statics.isEmpty() || removeStatic;</span>
<span class="pc bpc" id="L1115" title="3 of 6 branches missed.">        boolean hasNoMoreClusterings = clusterings.isEmpty() || (toRemove != null &amp;&amp; toRemove.size() == clusterings.size());</span>
<span class="pc bpc" id="L1116" title="2 of 4 branches missed.">        if (hasNoMoreStatic &amp;&amp; hasNoMoreClusterings)</span>
<span class="fc" id="L1117">            return null;</span>

<span class="nc bnc" id="L1119" title="All 2 branches missed.">        if (toRemove != null)</span>
        {
<span class="nc" id="L1121">            BTreeSet.Builder&lt;Clustering&lt;?&gt;&gt; newClusterings = BTreeSet.builder(result.metadata().comparator);</span>
<span class="nc" id="L1122">            newClusterings.addAll(Sets.difference(clusterings, toRemove));</span>
<span class="nc" id="L1123">            clusterings = newClusterings.build();</span>
        }
<span class="nc" id="L1125">        return new ClusteringIndexNamesFilter(clusterings, filter.isReversed());</span>
    }

    /**
     * We can stop reading row data from disk if what we've already read is more recent than the max timestamp
     * of the next newest SSTable that might have data for the query. We care about 1.) the row timestamp (since
     * every query cares if the row exists or not), 2.) the timestamps of the requested cells, and 3.) whether or
     * not any of the cells we've read have actual data.
     *
     * @param row a potentially incomplete {@link Row}
     * @param requestedColumns the columns requested by the query
     * @param sstableTimestamp the max timestamp of the next newest SSTable to read
     *
     * @return true if the supplied {@link Row} is complete and its data more recent than the supplied timestamp
     */
    private boolean isRowComplete(Row row, Columns requestedColumns, long sstableTimestamp)
    {
        // Static rows do not have row deletion or primary key liveness info
<span class="pc bpc" id="L1143" title="1 of 2 branches missed.">        if (!row.isStatic())</span>
        {
            // If the row has been deleted or is part of a range deletion we know that we have enough information and can
            // stop at this point.
            // Note that deleted rows in compact tables (non static) do not have a row deletion. Single column
            // cells are deleted instead. By consequence this check will not work for those, but the row will appear as complete later on
            // in the method.
<span class="pc bpc" id="L1150" title="1 of 4 branches missed.">            if (!row.deletion().isLive() &amp;&amp; row.deletion().time().deletes(sstableTimestamp))</span>
<span class="fc" id="L1151">                return true;</span>

            // Note that compact tables will always have an empty primary key liveness info.
<span class="pc bpc" id="L1154" title="2 of 6 branches missed.">            if (!metadata().isCompactTable() &amp;&amp; (row.primaryKeyLivenessInfo().isEmpty() || row.primaryKeyLivenessInfo().timestamp() &lt;= sstableTimestamp))</span>
<span class="fc" id="L1155">                return false;</span>
        }

<span class="fc bfc" id="L1158" title="All 2 branches covered.">        for (ColumnMetadata column : requestedColumns)</span>
        {
<span class="fc" id="L1160">            Cell&lt;?&gt; cell = row.getCell(column);</span>

<span class="pc bpc" id="L1162" title="1 of 4 branches missed.">            if (cell == null || cell.timestamp() &lt;= sstableTimestamp)</span>
<span class="fc" id="L1163">                return false;</span>
<span class="fc" id="L1164">        }</span>

<span class="fc" id="L1166">        return true;</span>
    }

    @Override
    public boolean selectsFullPartition()
    {
<span class="pc bpc" id="L1172" title="1 of 2 branches missed.">        if (metadata().isStaticCompactTable())</span>
<span class="nc" id="L1173">            return true;</span>

<span class="pc bpc" id="L1175" title="1 of 4 branches missed.">        return clusteringIndexFilter.selectsAllPartition() &amp;&amp; !rowFilter().hasExpressionOnClusteringOrRegularColumns();</span>
    }

    @Override
    public String toString()
    {
<span class="nc" id="L1181">        return String.format(&quot;Read(%s columns=%s rowFilter=%s limits=%s key=%s filter=%s, nowInSec=%d)&quot;,</span>
<span class="nc" id="L1182">                             metadata().toString(),</span>
<span class="nc" id="L1183">                             columnFilter(),</span>
<span class="nc" id="L1184">                             rowFilter(),</span>
<span class="nc" id="L1185">                             limits(),</span>
<span class="nc" id="L1186">                             metadata().partitionKeyType.getString(partitionKey().getKey()),</span>
<span class="nc" id="L1187">                             clusteringIndexFilter.toString(metadata()),</span>
<span class="nc" id="L1188">                             nowInSec());</span>
    }

    @Override
    public Verb verb()
    {
<span class="nc" id="L1194">        return Verb.READ_REQ;</span>
    }

    @Override
    protected void appendCQLWhereClause(StringBuilder sb)
    {
<span class="nc" id="L1200">        sb.append(&quot; WHERE &quot;).append(partitionKey().toCQLString(metadata()));</span>

<span class="nc" id="L1202">        String filterString = clusteringIndexFilter().toCQLString(metadata(), rowFilter());</span>
<span class="nc bnc" id="L1203" title="All 2 branches missed.">        if (!filterString.isEmpty())</span>
        {
<span class="nc bnc" id="L1205" title="All 4 branches missed.">            if (!clusteringIndexFilter().selectsAllPartition() || !rowFilter().isEmpty())</span>
<span class="nc" id="L1206">                sb.append(&quot; AND &quot;);</span>
<span class="nc" id="L1207">            sb.append(filterString);</span>
        }
<span class="nc" id="L1209">    }</span>

    @Override
    public String loggableTokens()
    {
<span class="nc" id="L1214">        return &quot;token=&quot; + partitionKey.getToken().toString();</span>
    }

    protected void serializeSelection(DataOutputPlus out, int version) throws IOException
    {
<span class="nc" id="L1219">        metadata().partitionKeyType.writeValue(partitionKey().getKey(), out);</span>
<span class="nc" id="L1220">        ClusteringIndexFilter.serializer.serialize(clusteringIndexFilter(), out, version);</span>
<span class="nc" id="L1221">    }</span>

    protected long selectionSerializedSize(int version)
    {
<span class="nc" id="L1225">        return metadata().partitionKeyType.writtenLength(partitionKey().getKey())</span>
<span class="nc" id="L1226">             + ClusteringIndexFilter.serializer.serializedSize(clusteringIndexFilter(), version);</span>
    }

    public boolean isLimitedToOnePartition()
    {
<span class="nc" id="L1231">        return true;</span>
    }

    public boolean isRangeRequest()
    {
<span class="fc" id="L1236">        return false;</span>
    }

    /**
     * Groups multiple single partition read commands.
     */
    public static class Group extends SinglePartitionReadQuery.Group&lt;SinglePartitionReadCommand&gt;
    {
        public static Group create(TableMetadata metadata,
                                   long nowInSec,
                                   ColumnFilter columnFilter,
                                   RowFilter rowFilter,
                                   DataLimits limits,
                                   List&lt;DecoratedKey&gt; partitionKeys,
                                   ClusteringIndexFilter clusteringIndexFilter)
        {
<span class="fc" id="L1252">            List&lt;SinglePartitionReadCommand&gt; commands = new ArrayList&lt;&gt;(partitionKeys.size());</span>
<span class="fc bfc" id="L1253" title="All 2 branches covered.">            for (DecoratedKey partitionKey : partitionKeys)</span>
            {
<span class="fc" id="L1255">                commands.add(SinglePartitionReadCommand.create(metadata,</span>
                                                               nowInSec,
                                                               columnFilter,
                                                               rowFilter,
                                                               limits,
                                                               partitionKey,
                                                               clusteringIndexFilter));
<span class="fc" id="L1262">            }</span>

<span class="fc" id="L1264">            return create(commands, limits);</span>
        }

        private Group(List&lt;SinglePartitionReadCommand&gt; commands, DataLimits limits)
        {
<span class="fc" id="L1269">            super(commands, limits);</span>
<span class="fc" id="L1270">        }</span>

        public static Group one(SinglePartitionReadCommand command)
        {
<span class="fc" id="L1274">            return create(Collections.singletonList(command), command.limits());</span>
        }

        public static Group create(List&lt;SinglePartitionReadCommand&gt; commands, DataLimits limits)
        {
<span class="fc bfc" id="L1279" title="All 2 branches covered.">            return commands.get(0).metadata().isVirtual() ?</span>
<span class="fc" id="L1280">                   new VirtualTableGroup(commands, limits) :</span>
<span class="fc" id="L1281">                   new Group(commands, limits);</span>
        }

        public PartitionIterator execute(ConsistencyLevel consistency, ClientState state, long queryStartNanoTime) throws RequestExecutionException
        {
<span class="fc" id="L1286">            return StorageProxy.read(this, consistency, queryStartNanoTime);</span>
        }
    }

    public static class VirtualTableGroup extends Group
    {
        public VirtualTableGroup(List&lt;SinglePartitionReadCommand&gt; commands, DataLimits limits)
        {
<span class="fc" id="L1294">            super(commands, limits);</span>
<span class="fc" id="L1295">        }</span>

        @Override
        public PartitionIterator execute(ConsistencyLevel consistency, ClientState state, long queryStartNanoTime) throws RequestExecutionException
        {
<span class="pc bpc" id="L1300" title="1 of 2 branches missed.">            if (queries.size() == 1)</span>
<span class="fc" id="L1301">                return queries.get(0).execute(consistency, state, queryStartNanoTime);</span>

<span class="nc" id="L1303">            return PartitionIterators.concat(queries.stream()</span>
<span class="nc" id="L1304">                                                    .map(q -&gt; q.execute(consistency, state, queryStartNanoTime))</span>
<span class="nc" id="L1305">                                                    .collect(Collectors.toList()));</span>
        }
    }

    private static class Deserializer extends SelectionDeserializer
    {
        public ReadCommand deserialize(DataInputPlus in,
                                       int version,
                                       boolean isDigest,
                                       int digestVersion,
                                       boolean acceptsTransient,
                                       TableMetadata metadata,
                                       long nowInSec,
                                       ColumnFilter columnFilter,
                                       RowFilter rowFilter,
                                       DataLimits limits,
                                       Index.QueryPlan indexQueryPlan)
        throws IOException
        {
<span class="nc" id="L1324">            DecoratedKey key = metadata.partitioner.decorateKey(metadata.partitionKeyType.readBuffer(in, DatabaseDescriptor.getMaxValueSize()));</span>
<span class="nc" id="L1325">            ClusteringIndexFilter filter = ClusteringIndexFilter.serializer.deserialize(in, version, metadata);</span>
<span class="nc" id="L1326">            return SinglePartitionReadCommand.create(isDigest, digestVersion, acceptsTransient, metadata, nowInSec, columnFilter, rowFilter, limits, key, filter, indexQueryPlan, false);</span>
        }
    }

    /**
     * {@code SSTableReaderListener} used to collect metrics about SSTable read access.
     */
    private static final class SSTableReadMetricsCollector implements SSTableReadsListener
    {
        /**
         * The number of SSTables that need to be merged. This counter is only updated for single partition queries
         * since this has been the behavior so far.
         */
        private int mergedSSTables;

        @Override
        public void onSSTableSelected(SSTableReader sstable, SelectionReason reason)
        {
<span class="fc" id="L1344">            sstable.incrementReadCount();</span>
<span class="fc" id="L1345">            mergedSSTables++;</span>
<span class="fc" id="L1346">        }</span>

        /**
         * Returns the number of SSTables that need to be merged.
         * @return the number of SSTables that need to be merged.
         */
        public int getMergedSSTables()
        {
<span class="fc" id="L1354">            return mergedSSTables;</span>
        }
    }

    public static class VirtualTableSinglePartitionReadCommand extends SinglePartitionReadCommand
    {
        protected VirtualTableSinglePartitionReadCommand(boolean isDigest,
                                                         int digestVersion,
                                                         boolean acceptsTransient,
                                                         TableMetadata metadata,
                                                         long nowInSec,
                                                         ColumnFilter columnFilter,
                                                         RowFilter rowFilter,
                                                         DataLimits limits,
                                                         DecoratedKey partitionKey,
                                                         ClusteringIndexFilter clusteringIndexFilter,
                                                         Index.QueryPlan indexQueryPlan,
                                                         boolean trackWarnings)
        {
<span class="fc" id="L1373">            super(isDigest, digestVersion, acceptsTransient, metadata, nowInSec, columnFilter, rowFilter, limits, partitionKey, clusteringIndexFilter, indexQueryPlan, trackWarnings);</span>
<span class="fc" id="L1374">        }</span>

        @Override
        public PartitionIterator execute(ConsistencyLevel consistency, ClientState state, long queryStartNanoTime) throws RequestExecutionException
        {
<span class="fc" id="L1379">            return executeInternal(executionController());</span>
        }

        @Override
        @SuppressWarnings(&quot;resource&quot;)
        public UnfilteredPartitionIterator executeLocally(ReadExecutionController executionController)
        {
<span class="fc" id="L1386">            VirtualTable view = VirtualKeyspaceRegistry.instance.getTableNullable(metadata().id);</span>
<span class="fc" id="L1387">            UnfilteredPartitionIterator resultIterator = view.select(partitionKey, clusteringIndexFilter, columnFilter());</span>
<span class="fc" id="L1388">            return limits().filter(rowFilter().filter(resultIterator, nowInSec()), nowInSec(), selectsFullPartition());</span>
        }

        @Override
        public ReadExecutionController executionController()
        {
<span class="fc" id="L1394">            return ReadExecutionController.empty();</span>
        }

        @Override
        public ReadExecutionController executionController(boolean trackRepairedStatus)
        {
<span class="nc" id="L1400">            return executionController();</span>
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>