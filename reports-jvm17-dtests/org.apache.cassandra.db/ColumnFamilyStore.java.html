<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ColumnFamilyStore.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Cassandara Coverage Report</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.db</a> &gt; <span class="el_source">ColumnFamilyStore.java</span></div><h1>ColumnFamilyStore.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.cassandra.db;

import java.io.IOException;
import java.io.PrintStream;
import java.lang.reflect.Constructor;
import java.lang.reflect.InvocationTargetException;
import java.nio.ByteBuffer;
import java.time.Instant;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Set;
import java.util.concurrent.Callable;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicReference;
import java.util.function.Consumer;
import java.util.function.Supplier;
import java.util.regex.Pattern;
import java.util.stream.Collectors;
import javax.management.MalformedObjectNameException;
import javax.management.ObjectName;
import javax.management.openmbean.CompositeData;
import javax.management.openmbean.CompositeDataSupport;
import javax.management.openmbean.CompositeType;
import javax.management.openmbean.OpenDataException;
import javax.management.openmbean.OpenType;
import javax.management.openmbean.SimpleType;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Function;
import com.google.common.base.Joiner;
import com.google.common.base.Predicate;
import com.google.common.base.Predicates;
import com.google.common.base.Strings;
import com.google.common.base.Throwables;
import com.google.common.collect.ImmutableSet;
import com.google.common.collect.Iterables;
import com.google.common.collect.Lists;
import com.google.common.collect.Sets;
import com.google.common.util.concurrent.RateLimiter;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.cassandra.cache.CounterCacheKey;
import org.apache.cassandra.cache.IRowCacheEntry;
import org.apache.cassandra.cache.RowCacheKey;
import org.apache.cassandra.cache.RowCacheSentinel;
import org.apache.cassandra.concurrent.ExecutorPlus;
import org.apache.cassandra.concurrent.FutureTask;
import org.apache.cassandra.config.DatabaseDescriptor;
import org.apache.cassandra.config.DurationSpec;
import org.apache.cassandra.db.commitlog.CommitLog;
import org.apache.cassandra.db.commitlog.CommitLogPosition;
import org.apache.cassandra.db.commitlog.IntervalSet;
import org.apache.cassandra.db.compaction.AbstractCompactionStrategy;
import org.apache.cassandra.db.compaction.CompactionInfo;
import org.apache.cassandra.db.compaction.CompactionManager;
import org.apache.cassandra.db.compaction.CompactionStrategyManager;
import org.apache.cassandra.db.compaction.OperationType;
import org.apache.cassandra.db.filter.ClusteringIndexFilter;
import org.apache.cassandra.db.filter.DataLimits;
import org.apache.cassandra.db.lifecycle.LifecycleNewTracker;
import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
import org.apache.cassandra.db.lifecycle.SSTableSet;
import org.apache.cassandra.db.lifecycle.Tracker;
import org.apache.cassandra.db.lifecycle.View;
import org.apache.cassandra.db.memtable.Flushing;
import org.apache.cassandra.db.memtable.Memtable;
import org.apache.cassandra.db.memtable.ShardBoundaries;
import org.apache.cassandra.db.partitions.CachedPartition;
import org.apache.cassandra.db.partitions.PartitionUpdate;
import org.apache.cassandra.db.repair.CassandraTableRepairManager;
import org.apache.cassandra.db.rows.CellPath;
import org.apache.cassandra.db.streaming.CassandraStreamManager;
import org.apache.cassandra.db.view.TableViews;
import org.apache.cassandra.dht.AbstractBounds;
import org.apache.cassandra.dht.Bounds;
import org.apache.cassandra.dht.IPartitioner;
import org.apache.cassandra.dht.Range;
import org.apache.cassandra.dht.Splitter;
import org.apache.cassandra.dht.Token;
import org.apache.cassandra.exceptions.ConfigurationException;
import org.apache.cassandra.exceptions.StartupException;
import org.apache.cassandra.index.SecondaryIndexManager;
import org.apache.cassandra.index.internal.CassandraIndex;
import org.apache.cassandra.index.transactions.UpdateTransaction;
import org.apache.cassandra.io.FSReadError;
import org.apache.cassandra.io.FSWriteError;
import org.apache.cassandra.io.sstable.Component;
import org.apache.cassandra.io.sstable.Descriptor;
import org.apache.cassandra.io.sstable.IScrubber;
import org.apache.cassandra.io.sstable.IVerifier;
import org.apache.cassandra.io.sstable.SSTable;
import org.apache.cassandra.io.sstable.SSTableId;
import org.apache.cassandra.io.sstable.SSTableIdFactory;
import org.apache.cassandra.io.sstable.SSTableMultiWriter;
import org.apache.cassandra.io.sstable.format.SSTableFormat;
import org.apache.cassandra.io.sstable.format.SSTableFormat.Components;
import org.apache.cassandra.io.sstable.format.SSTableReader;
import org.apache.cassandra.io.sstable.format.Version;
import org.apache.cassandra.io.util.File;
import org.apache.cassandra.io.util.FileOutputStreamPlus;
import org.apache.cassandra.metrics.Sampler;
import org.apache.cassandra.metrics.Sampler.Sample;
import org.apache.cassandra.metrics.Sampler.SamplerType;
import org.apache.cassandra.metrics.TableMetrics;
import org.apache.cassandra.metrics.TopPartitionTracker;
import org.apache.cassandra.repair.TableRepairManager;
import org.apache.cassandra.repair.consistent.admin.CleanupSummary;
import org.apache.cassandra.repair.consistent.admin.PendingStat;
import org.apache.cassandra.schema.ColumnMetadata;
import org.apache.cassandra.schema.CompactionParams;
import org.apache.cassandra.schema.CompactionParams.TombstoneOption;
import org.apache.cassandra.schema.CompressionParams;
import org.apache.cassandra.schema.IndexMetadata;
import org.apache.cassandra.schema.Schema;
import org.apache.cassandra.schema.SchemaConstants;
import org.apache.cassandra.schema.TableId;
import org.apache.cassandra.schema.TableMetadata;
import org.apache.cassandra.schema.TableMetadataRef;
import org.apache.cassandra.schema.TableParams;
import org.apache.cassandra.service.ActiveRepairService;
import org.apache.cassandra.service.CacheService;
import org.apache.cassandra.service.StorageService;
import org.apache.cassandra.service.paxos.Ballot;
import org.apache.cassandra.service.paxos.PaxosRepairHistory;
import org.apache.cassandra.service.paxos.TablePaxosRepairHistory;
import org.apache.cassandra.service.snapshot.SnapshotLoader;
import org.apache.cassandra.service.snapshot.SnapshotManifest;
import org.apache.cassandra.service.snapshot.TableSnapshot;
import org.apache.cassandra.streaming.TableStreamManager;
import org.apache.cassandra.utils.ByteBufferUtil;
import org.apache.cassandra.utils.DefaultValue;
import org.apache.cassandra.utils.ExecutorUtils;
import org.apache.cassandra.utils.FBUtilities;
import org.apache.cassandra.utils.JVMStabilityInspector;
import org.apache.cassandra.utils.JsonUtils;
import org.apache.cassandra.utils.MBeanWrapper;
import org.apache.cassandra.utils.NoSpamLogger;
import org.apache.cassandra.utils.Pair;
import org.apache.cassandra.utils.TimeUUID;
import org.apache.cassandra.utils.WrappedRunnable;
import org.apache.cassandra.utils.concurrent.CountDownLatch;
import org.apache.cassandra.utils.concurrent.Future;
import org.apache.cassandra.utils.concurrent.OpOrder;
import org.apache.cassandra.utils.concurrent.Refs;
import org.apache.cassandra.utils.concurrent.UncheckedInterruptedException;

import static org.apache.cassandra.concurrent.ExecutorFactory.Global.executorFactory;
import static org.apache.cassandra.config.DatabaseDescriptor.getFlushWriters;
import static org.apache.cassandra.db.commitlog.CommitLogPosition.NONE;
import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
import static org.apache.cassandra.utils.Clock.Global.nanoTime;
import static org.apache.cassandra.utils.FBUtilities.now;
import static org.apache.cassandra.utils.Throwables.maybeFail;
import static org.apache.cassandra.utils.Throwables.merge;
import static org.apache.cassandra.utils.concurrent.CountDownLatch.newCountDownLatch;

public class ColumnFamilyStore implements ColumnFamilyStoreMBean, Memtable.Owner, SSTable.Owner
{
<span class="fc" id="L192">    private static final Logger logger = LoggerFactory.getLogger(ColumnFamilyStore.class);</span>

    /*
    We keep a pool of threads for each data directory, size of each pool is memtable_flush_writers.
    When flushing we start a Flush runnable in the flushExecutor. Flush calculates how to split the
    memtable ranges over the existing data directories and creates a FlushRunnable for each of the directories.
    The FlushRunnables are executed in the perDiskflushExecutors and the Flush will block until all FlushRunnables
    are finished. By having flushExecutor size the same size as each of the perDiskflushExecutors we make sure we can
    have that many flushes going at the same time.
    */
<span class="fc" id="L202">    private static final ExecutorPlus flushExecutor = executorFactory()</span>
<span class="fc" id="L203">            .withJmxInternal()</span>
<span class="fc" id="L204">            .pooled(&quot;MemtableFlushWriter&quot;, getFlushWriters());</span>

    // post-flush executor is single threaded to provide guarantee that any flush Future on a CF will never return until prior flushes have completed
<span class="fc" id="L207">    private static final ExecutorPlus postFlushExecutor = executorFactory()</span>
<span class="fc" id="L208">            .withJmxInternal()</span>
<span class="fc" id="L209">            .sequential(&quot;MemtablePostFlush&quot;);</span>

<span class="fc" id="L211">    private static final ExecutorPlus reclaimExecutor = executorFactory()</span>
<span class="fc" id="L212">            .withJmxInternal()</span>
<span class="fc" id="L213">            .sequential(&quot;MemtableReclaimMemory&quot;);</span>

<span class="fc" id="L215">    private static final PerDiskFlushExecutors perDiskflushExecutors = new PerDiskFlushExecutors(DatabaseDescriptor.getFlushWriters(),</span>
<span class="fc" id="L216">                                                                                                 DatabaseDescriptor.getNonLocalSystemKeyspacesDataFileLocations(),</span>
<span class="fc" id="L217">                                                                                                 DatabaseDescriptor.useSpecificLocationForLocalSystemData());</span>

    /**
     * Reason for initiating a memtable flush.
     */
<span class="fc" id="L222">    public enum FlushReason</span>
    {
<span class="fc" id="L224">        COMMITLOG_DIRTY,</span>
<span class="fc" id="L225">        MEMTABLE_LIMIT,</span>
<span class="fc" id="L226">        MEMTABLE_PERIOD_EXPIRED,</span>
<span class="fc" id="L227">        INDEX_BUILD_STARTED,</span>
<span class="fc" id="L228">        INDEX_BUILD_COMPLETED,</span>
<span class="fc" id="L229">        INDEX_REMOVED,</span>
<span class="fc" id="L230">        INDEX_TABLE_FLUSH,</span>
<span class="fc" id="L231">        VIEW_BUILD_STARTED,</span>
<span class="fc" id="L232">        INTERNALLY_FORCED,  // explicitly requested flush, necessary for the operation of an internal table</span>
<span class="fc" id="L233">        USER_FORCED, // flush explicitly requested by the user (e.g. nodetool flush)</span>
<span class="fc" id="L234">        STARTUP,</span>
<span class="fc" id="L235">        DRAIN,</span>
<span class="fc" id="L236">        SNAPSHOT,</span>
<span class="fc" id="L237">        TRUNCATE,</span>
<span class="fc" id="L238">        DROP,</span>
<span class="fc" id="L239">        STREAMING,</span>
<span class="fc" id="L240">        STREAMS_RECEIVED,</span>
<span class="fc" id="L241">        VALIDATION,</span>
<span class="fc" id="L242">        ANTICOMPACTION,</span>
<span class="fc" id="L243">        SCHEMA_CHANGE,</span>
<span class="fc" id="L244">        OWNED_RANGES_CHANGE,</span>
<span class="fc" id="L245">        UNIT_TESTS // explicitly requested flush needed for a test</span>
    }

<span class="fc" id="L248">    private static final String[] COUNTER_NAMES = new String[]{&quot;table&quot;, &quot;count&quot;, &quot;error&quot;, &quot;value&quot;};</span>
<span class="fc" id="L249">    private static final String[] COUNTER_DESCS = new String[]</span>
    { &quot;keyspace.tablename&quot;,
      &quot;number of occurances&quot;,
      &quot;error bounds&quot;,
      &quot;value&quot; };
    private static final CompositeType COUNTER_COMPOSITE_TYPE;

    private static final String SAMPLING_RESULTS_NAME = &quot;SAMPLING_RESULTS&quot;;

    public static final String SNAPSHOT_TRUNCATE_PREFIX = &quot;truncated&quot;;
    public static final String SNAPSHOT_DROP_PREFIX = &quot;dropped&quot;;
    static final String TOKEN_DELIMITER = &quot;:&quot;;

    /** Special values used when the local ranges are not changed with ring changes (e.g. local tables). */
    public static final int RING_VERSION_IRRELEVANT = -1;

    static
    {
        try
        {
<span class="fc" id="L269">            OpenType&lt;?&gt;[] counterTypes = new OpenType[] { SimpleType.STRING, SimpleType.LONG, SimpleType.LONG, SimpleType.STRING };</span>
<span class="fc" id="L270">            COUNTER_COMPOSITE_TYPE = new CompositeType(SAMPLING_RESULTS_NAME, SAMPLING_RESULTS_NAME, COUNTER_NAMES, COUNTER_DESCS, counterTypes);</span>
<span class="nc" id="L271">        } catch (OpenDataException e)</span>
        {
<span class="nc" id="L273">            throw new RuntimeException(e);</span>
<span class="fc" id="L274">        }</span>
    }

    public final Keyspace keyspace;
    public final String name;
    public final TableMetadataRef metadata;
    private final String mbeanName;
    @Deprecated
    private final String oldMBeanName;
<span class="fc" id="L283">    private volatile boolean valid = true;</span>

    private volatile Memtable.Factory memtableFactory;

    /**
     * Memtables and SSTables on disk for this column family.
     *
     * We synchronize on the Tracker to ensure isolation when we want to make sure
     * that the memtable we're acting on doesn't change out from under us.  I.e., flush
     * syncronizes on it to make sure it can submit on both executors atomically,
     * so anyone else who wants to make sure flush doesn't interfere should as well.
     */
    private final Tracker data;

    /* The read order, used to track accesses to off-heap memtable storage */
<span class="fc" id="L298">    public final OpOrder readOrdering = new OpOrder();</span>

    /* This is used to generate the next index for a SSTable */
    private final Supplier&lt;? extends SSTableId&gt; sstableIdGenerator;

    public final SecondaryIndexManager indexManager;
    public final TableViews viewManager;

    /* These are locally held copies to be changed from the config during runtime */
    private volatile DefaultValue&lt;Integer&gt; minCompactionThreshold;
    private volatile DefaultValue&lt;Integer&gt; maxCompactionThreshold;
    private volatile DefaultValue&lt;Double&gt; crcCheckChance;

    private final CompactionStrategyManager compactionStrategyManager;

    private final Directories directories;

    public final TableMetrics metric;
    public volatile long sampleReadLatencyMicros;
    public volatile long additionalWriteLatencyMicros;

    private final CassandraTableWriteHandler writeHandler;
    private final CassandraStreamManager streamManager;

    private final TableRepairManager repairManager;
    public final TopPartitionTracker topPartitions;

    private final SSTableImporter sstableImporter;

<span class="fc" id="L327">    private volatile boolean compactionSpaceCheck = true;</span>

    // Tombtone partitions that ignore the gc_grace_seconds during compaction
<span class="fc" id="L330">    private final Set&lt;DecoratedKey&gt; partitionKeySetIgnoreGcGrace = ConcurrentHashMap.newKeySet();</span>

<span class="fc" id="L332">    @VisibleForTesting</span>
    final DiskBoundaryManager diskBoundaryManager = new DiskBoundaryManager();
<span class="fc" id="L334">    private volatile ShardBoundaries cachedShardBoundaries = null;</span>

<span class="fc" id="L336">    private volatile boolean neverPurgeTombstones = false;</span>

<span class="fc" id="L338">    private class PaxosRepairHistoryLoader</span>
    {
        private TablePaxosRepairHistory history;

        TablePaxosRepairHistory get()
        {
<span class="fc bfc" id="L344" title="All 2 branches covered.">            if (history != null)</span>
<span class="fc" id="L345">                return history;</span>

<span class="fc" id="L347">            synchronized (this)</span>
            {
<span class="pc bpc" id="L349" title="1 of 2 branches missed.">                if (history != null)</span>
<span class="nc" id="L350">                    return history;</span>

<span class="fc" id="L352">                history = TablePaxosRepairHistory.load(getKeyspaceName(), name);</span>
<span class="fc" id="L353">                return history;</span>
            }
        }

    }

<span class="fc" id="L359">    private final PaxosRepairHistoryLoader paxosRepairHistory = new PaxosRepairHistoryLoader();</span>

    public static void shutdownPostFlushExecutor() throws InterruptedException
    {
<span class="nc" id="L363">        postFlushExecutor.shutdown();</span>
<span class="nc" id="L364">        postFlushExecutor.awaitTermination(60, TimeUnit.SECONDS);</span>
<span class="nc" id="L365">    }</span>

    public static void shutdownExecutorsAndWait(long timeout, TimeUnit unit) throws InterruptedException, TimeoutException
    {
<span class="fc" id="L369">        List&lt;ExecutorService&gt; executors = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L370">        Collections.addAll(executors, reclaimExecutor, postFlushExecutor, flushExecutor);</span>
<span class="fc" id="L371">        perDiskflushExecutors.appendAllExecutors(executors);</span>
<span class="fc" id="L372">        ExecutorUtils.shutdownAndWait(timeout, unit, executors);</span>
<span class="fc" id="L373">    }</span>

    public void reload()
    {
        // metadata object has been mutated directly. make all the members jibe with new settings.

        // only update these runtime-modifiable settings if they have not been modified.
<span class="pc bpc" id="L380" title="1 of 2 branches missed.">        if (!minCompactionThreshold.isModified())</span>
<span class="fc bfc" id="L381" title="All 2 branches covered.">            for (ColumnFamilyStore cfs : concatWithIndexes())</span>
<span class="fc" id="L382">                cfs.minCompactionThreshold = new DefaultValue(metadata().params.compaction.minCompactionThreshold());</span>
<span class="pc bpc" id="L383" title="1 of 2 branches missed.">        if (!maxCompactionThreshold.isModified())</span>
<span class="fc bfc" id="L384" title="All 2 branches covered.">            for (ColumnFamilyStore cfs : concatWithIndexes())</span>
<span class="fc" id="L385">                cfs.maxCompactionThreshold = new DefaultValue(metadata().params.compaction.maxCompactionThreshold());</span>
<span class="pc bpc" id="L386" title="1 of 2 branches missed.">        if (!crcCheckChance.isModified())</span>
<span class="fc bfc" id="L387" title="All 2 branches covered.">            for (ColumnFamilyStore cfs : concatWithIndexes())</span>
<span class="fc" id="L388">                cfs.crcCheckChance = new DefaultValue(metadata().params.crcCheckChance);</span>

<span class="fc" id="L390">        compactionStrategyManager.maybeReloadParamsFromSchema(metadata().params.compaction);</span>

<span class="fc" id="L392">        indexManager.reload();</span>

<span class="fc" id="L394">        memtableFactory = metadata().params.memtable.factory();</span>
<span class="fc" id="L395">        switchMemtableOrNotify(FlushReason.SCHEMA_CHANGE, Memtable::metadataUpdated);</span>
<span class="fc" id="L396">    }</span>

    public static Runnable getBackgroundCompactionTaskSubmitter()
    {
<span class="nc" id="L400">        return () -&gt; {</span>
<span class="nc bnc" id="L401" title="All 2 branches missed.">            for (Keyspace keyspace : Keyspace.all())</span>
<span class="nc bnc" id="L402" title="All 2 branches missed.">                for (ColumnFamilyStore cfs : keyspace.getColumnFamilyStores())</span>
<span class="nc" id="L403">                    CompactionManager.instance.submitBackground(cfs);</span>
<span class="nc" id="L404">        };</span>
    }

    public Map&lt;String, String&gt; getCompactionParameters()
    {
<span class="fc" id="L409">        return compactionStrategyManager.getCompactionParams().asMap();</span>
    }

    public String getCompactionParametersJson()
    {
<span class="fc" id="L414">        return JsonUtils.writeAsJsonString(getCompactionParameters());</span>
    }

    public void setCompactionParameters(Map&lt;String, String&gt; options)
    {
        try
        {
<span class="nc" id="L421">            CompactionParams compactionParams = CompactionParams.fromMap(options);</span>
<span class="nc" id="L422">            compactionParams.validate();</span>
<span class="nc" id="L423">            compactionStrategyManager.overrideLocalParams(compactionParams);</span>
        }
<span class="nc" id="L425">        catch (Throwable t)</span>
        {
<span class="nc" id="L427">            logger.error(&quot;Could not set new local compaction strategy&quot;, t);</span>
            // dont propagate the ConfigurationException over jmx, user will only see a ClassNotFoundException
<span class="nc" id="L429">            throw new IllegalArgumentException(&quot;Could not set new local compaction strategy: &quot;+t.getMessage());</span>
<span class="nc" id="L430">        }</span>
<span class="nc" id="L431">    }</span>

    public void setCompactionParametersJson(String options)
    {
<span class="nc" id="L435">        setCompactionParameters(JsonUtils.fromJsonMap(options));</span>
<span class="nc" id="L436">    }</span>

    public Map&lt;String,String&gt; getCompressionParameters()
    {
<span class="fc" id="L440">        return metadata.getLocal().params.compression.asMap();</span>
    }

    public String getCompressionParametersJson()
    {
<span class="fc" id="L445">        return JsonUtils.writeAsJsonString(getCompressionParameters());</span>
    }

    public void setCompressionParameters(Map&lt;String,String&gt; opts)
    {
        try
        {
<span class="fc" id="L452">            CompressionParams params = CompressionParams.fromMap(opts);</span>
<span class="fc" id="L453">            params.validate();</span>
<span class="fc" id="L454">            metadata.setLocalOverrides(metadata().unbuild().compression(params).build());</span>
        }
<span class="nc" id="L456">        catch (ConfigurationException e)</span>
        {
<span class="nc" id="L458">            throw new IllegalArgumentException(e.getMessage());</span>
<span class="fc" id="L459">        }</span>
<span class="fc" id="L460">    }</span>

    public void setCompressionParametersJson(String options)
    {
<span class="fc" id="L464">        setCompressionParameters(JsonUtils.fromJsonMap(options));</span>
<span class="fc" id="L465">    }</span>

    @VisibleForTesting
    public ColumnFamilyStore(Keyspace keyspace,
                             String columnFamilyName,
                             Supplier&lt;? extends SSTableId&gt; sstableIdGenerator,
                             TableMetadataRef metadata,
                             Directories directories,
                             boolean loadSSTables,
                             boolean registerBookeeping,
                             boolean offline)
<span class="fc" id="L476">    {</span>
<span class="pc bpc" id="L477" title="1 of 2 branches missed.">        assert directories != null;</span>
<span class="pc bpc" id="L478" title="1 of 2 branches missed.">        assert metadata != null : &quot;null metadata for &quot; + keyspace + ':' + columnFamilyName;</span>

<span class="fc" id="L480">        this.keyspace = keyspace;</span>
<span class="fc" id="L481">        this.metadata = metadata;</span>
<span class="fc" id="L482">        this.directories = directories;</span>
<span class="fc" id="L483">        name = columnFamilyName;</span>
<span class="fc" id="L484">        minCompactionThreshold = new DefaultValue&lt;&gt;(metadata.get().params.compaction.minCompactionThreshold());</span>
<span class="fc" id="L485">        maxCompactionThreshold = new DefaultValue&lt;&gt;(metadata.get().params.compaction.maxCompactionThreshold());</span>
<span class="fc" id="L486">        crcCheckChance = new DefaultValue&lt;&gt;(metadata.get().params.crcCheckChance);</span>
<span class="fc" id="L487">        viewManager = keyspace.viewManager.forTable(metadata.id);</span>
<span class="fc" id="L488">        this.sstableIdGenerator = sstableIdGenerator;</span>
<span class="fc" id="L489">        sampleReadLatencyMicros = DatabaseDescriptor.getReadRpcTimeout(TimeUnit.MICROSECONDS) / 2;</span>
<span class="fc" id="L490">        additionalWriteLatencyMicros = DatabaseDescriptor.getWriteRpcTimeout(TimeUnit.MICROSECONDS) / 2;</span>
<span class="fc" id="L491">        memtableFactory = metadata.get().params.memtable.factory();</span>

<span class="fc" id="L493">        logger.info(&quot;Initializing {}.{}&quot;, getKeyspaceName(), name);</span>

        // Create Memtable and its metrics object only on online
<span class="fc" id="L496">        Memtable initialMemtable = null;</span>
<span class="fc" id="L497">        TableMetrics.ReleasableMetric memtableMetrics = null;</span>
<span class="pc bpc" id="L498" title="1 of 2 branches missed.">        if (DatabaseDescriptor.isDaemonInitialized())</span>
        {
<span class="fc" id="L500">            initialMemtable = createMemtable(new AtomicReference&lt;&gt;(CommitLog.instance.getCurrentPosition()));</span>
<span class="fc" id="L501">            memtableMetrics = memtableFactory.createMemtableMetrics(metadata);</span>
        }
<span class="fc" id="L503">        data = new Tracker(this, initialMemtable, loadSSTables);</span>

        // Note that this needs to happen before we load the first sstables, or the global sstable tracker will not
        // be notified on the initial loading.
<span class="fc" id="L507">        data.subscribe(StorageService.instance.sstablesTracker);</span>

<span class="fc" id="L509">        Collection&lt;SSTableReader&gt; sstables = null;</span>
        // scan for sstables corresponding to this cf and load them
<span class="pc bpc" id="L511" title="1 of 2 branches missed.">        if (data.loadsstables)</span>
        {
<span class="fc" id="L513">            Directories.SSTableLister sstableFiles = directories.sstableLister(Directories.OnTxnErr.IGNORE).skipTemporary(true);</span>
<span class="fc" id="L514">            sstables = SSTableReader.openAll(this, sstableFiles.list().entrySet(), metadata);</span>
<span class="fc" id="L515">            data.addInitialSSTablesWithoutUpdatingSize(sstables);</span>
        }

        // compaction strategy should be created after the CFS has been prepared
<span class="fc" id="L519">        compactionStrategyManager = new CompactionStrategyManager(this);</span>

<span class="pc bpc" id="L521" title="2 of 4 branches missed.">        if (maxCompactionThreshold.value() &lt;= 0 || minCompactionThreshold.value() &lt;=0)</span>
        {
<span class="nc" id="L523">            logger.warn(&quot;Disabling compaction strategy by setting compaction thresholds to 0 is deprecated, set the compaction option 'enabled' to 'false' instead.&quot;);</span>
<span class="nc" id="L524">            this.compactionStrategyManager.disable();</span>
        }

        // create the private ColumnFamilyStores for the secondary column indexes
<span class="fc" id="L528">        indexManager = new SecondaryIndexManager(this);</span>
<span class="fc bfc" id="L529" title="All 2 branches covered.">        for (IndexMetadata info : metadata.get().indexes)</span>
        {
<span class="fc" id="L531">            indexManager.addIndex(info, true);</span>
<span class="fc" id="L532">        }</span>

<span class="fc" id="L534">        metric = new TableMetrics(this, memtableMetrics);</span>

<span class="pc bpc" id="L536" title="1 of 2 branches missed.">        if (data.loadsstables)</span>
        {
<span class="fc" id="L538">            data.updateInitialSSTableSize(sstables);</span>
        }

<span class="pc bpc" id="L541" title="1 of 2 branches missed.">        if (registerBookeeping)</span>
        {
            // register the mbean
<span class="fc" id="L544">            mbeanName = getTableMBeanName(getKeyspaceName(), name, isIndex());</span>
<span class="fc" id="L545">            oldMBeanName = getColumnFamilieMBeanName(getKeyspaceName(), name, isIndex());</span>

<span class="fc" id="L547">            String[] objectNames = {mbeanName, oldMBeanName};</span>
<span class="fc bfc" id="L548" title="All 2 branches covered.">            for (String objectName : objectNames)</span>
<span class="fc" id="L549">                MBeanWrapper.instance.registerMBean(this, objectName);</span>
<span class="fc" id="L550">        }</span>
        else
        {
<span class="nc" id="L553">            mbeanName = null;</span>
<span class="nc" id="L554">            oldMBeanName= null;</span>
        }
<span class="fc" id="L556">        writeHandler = new CassandraTableWriteHandler(this);</span>
<span class="fc" id="L557">        streamManager = new CassandraStreamManager(this);</span>
<span class="fc" id="L558">        repairManager = new CassandraTableRepairManager(this);</span>
<span class="fc" id="L559">        sstableImporter = new SSTableImporter(this);</span>

<span class="pc bpc" id="L561" title="1 of 4 branches missed.">        if (DatabaseDescriptor.isClientOrToolInitialized() || SchemaConstants.isSystemKeyspace(getKeyspaceName()))</span>
<span class="fc" id="L562">            topPartitions = null;</span>
        else
<span class="fc" id="L564">            topPartitions = new TopPartitionTracker(metadata());</span>
<span class="fc" id="L565">    }</span>

    public static String getTableMBeanName(String ks, String name, boolean isIndex)
    {
<span class="fc" id="L569">        return String.format(&quot;org.apache.cassandra.db:type=%s,keyspace=%s,table=%s&quot;,</span>
<span class="fc bfc" id="L570" title="All 2 branches covered.">                      isIndex ? &quot;IndexTables&quot; : &quot;Tables&quot;,</span>
                      ks, name);
    }

    public static String getColumnFamilieMBeanName(String ks, String name, boolean isIndex)
    {
<span class="fc" id="L576">       return String.format(&quot;org.apache.cassandra.db:type=%s,keyspace=%s,columnfamily=%s&quot;,</span>
<span class="fc bfc" id="L577" title="All 2 branches covered.">                            isIndex ? &quot;IndexColumnFamilies&quot; : &quot;ColumnFamilies&quot;,</span>
                            ks, name);
    }

    public void updateSpeculationThreshold()
    {
        try
        {
<span class="fc" id="L585">            sampleReadLatencyMicros = metadata().params.speculativeRetry.calculateThreshold(metric.coordinatorReadLatency, sampleReadLatencyMicros);</span>
<span class="fc" id="L586">            additionalWriteLatencyMicros = metadata().params.additionalWritePolicy.calculateThreshold(metric.coordinatorWriteLatency, additionalWriteLatencyMicros);</span>
        }
<span class="nc" id="L588">        catch (Throwable e)</span>
        {
<span class="nc" id="L590">            logger.error(&quot;Exception caught while calculating speculative retry threshold for {}: {}&quot;, metadata(), e);</span>
<span class="fc" id="L591">        }</span>
<span class="fc" id="L592">    }</span>

    public TableWriteHandler getWriteHandler()
    {
<span class="fc" id="L596">        return writeHandler;</span>
    }

    public TableStreamManager getStreamManager()
    {
<span class="fc" id="L601">        return streamManager;</span>
    }

    public TableRepairManager getRepairManager()
    {
<span class="fc" id="L606">        return repairManager;</span>
    }

    public TableMetadata metadata()
    {
<span class="fc" id="L611">        return metadata.get();</span>
    }

    public Directories getDirectories()
    {
<span class="fc" id="L616">        return directories;</span>
    }

    @Override
    public List&lt;String&gt; getDataPaths() throws IOException
    {
<span class="fc" id="L622">        List&lt;String&gt; dataPaths = new ArrayList&lt;&gt;();</span>
<span class="fc bfc" id="L623" title="All 2 branches covered.">        for (File dataPath : directories.getCFDirectories())</span>
        {
<span class="fc" id="L625">            dataPaths.add(dataPath.canonicalPath());</span>
<span class="fc" id="L626">        }</span>

<span class="fc" id="L628">        return dataPaths;</span>
    }

    public boolean writesShouldSkipCommitLog()
    {
<span class="nc" id="L633">        return memtableFactory.writesShouldSkipCommitLog();</span>
    }

    public boolean memtableWritesAreDurable()
    {
<span class="fc" id="L638">        return memtableFactory.writesAreDurable();</span>
    }

    public boolean streamToMemtable()
    {
<span class="fc" id="L643">        return memtableFactory.streamToMemtable();</span>
    }

    public boolean streamFromMemtable()
    {
<span class="fc" id="L648">        return memtableFactory.streamFromMemtable();</span>
    }

    public SSTableMultiWriter createSSTableMultiWriter(Descriptor descriptor, long keyCount, long repairedAt, TimeUUID pendingRepair, boolean isTransient, SerializationHeader header, LifecycleNewTracker lifecycleNewTracker)
    {
<span class="nc" id="L653">        return createSSTableMultiWriter(descriptor, keyCount, repairedAt, pendingRepair, isTransient, null, 0, header, lifecycleNewTracker);</span>
    }

    public SSTableMultiWriter createSSTableMultiWriter(Descriptor descriptor, long keyCount, long repairedAt, TimeUUID pendingRepair, boolean isTransient, IntervalSet&lt;CommitLogPosition&gt; commitLogPositions, SerializationHeader header, LifecycleNewTracker lifecycleNewTracker)
    {
<span class="fc" id="L658">        return createSSTableMultiWriter(descriptor, keyCount, repairedAt, pendingRepair, isTransient, commitLogPositions, 0, header, lifecycleNewTracker);</span>
    }

    public SSTableMultiWriter createSSTableMultiWriter(Descriptor descriptor, long keyCount, long repairedAt, TimeUUID pendingRepair, boolean isTransient, IntervalSet&lt;CommitLogPosition&gt; commitLogPositions, int sstableLevel, SerializationHeader header, LifecycleNewTracker lifecycleNewTracker)
    {
<span class="fc" id="L663">        return getCompactionStrategyManager().createSSTableMultiWriter(descriptor, keyCount, repairedAt, pendingRepair, isTransient, commitLogPositions, sstableLevel, header, indexManager.listIndexGroups(), lifecycleNewTracker);</span>
    }

    public boolean supportsEarlyOpen()
    {
<span class="fc" id="L668">        return compactionStrategyManager.supportsEarlyOpen();</span>
    }

    /** call when dropping or renaming a CF. Performs mbean housekeeping and invalidates CFS to other operations */
    public void invalidate()
    {
<span class="fc" id="L674">        invalidate(true, true);</span>
<span class="fc" id="L675">    }</span>

    public void invalidate(boolean expectMBean)
    {
<span class="nc" id="L679">        invalidate(expectMBean, true);</span>
<span class="nc" id="L680">    }</span>

    public void invalidate(boolean expectMBean, boolean dropData)
    {
        // disable and cancel in-progress compactions before invalidating
<span class="fc" id="L685">        valid = false;</span>

        try
        {
<span class="fc" id="L689">            unregisterMBean();</span>
        }
<span class="nc" id="L691">        catch (Exception e)</span>
        {
<span class="nc bnc" id="L693" title="All 2 branches missed.">            if (expectMBean)</span>
            {
<span class="nc" id="L695">                JVMStabilityInspector.inspectThrowable(e);</span>
                // this shouldn't block anything.
<span class="nc" id="L697">                logger.warn(&quot;Failed unregistering mbean: {}&quot;, mbeanName, e);</span>
            }
<span class="fc" id="L699">        }</span>

<span class="fc" id="L701">        compactionStrategyManager.shutdown();</span>

        // Do not remove truncation records for index CFs, given they have the same ID as their backing/base tables.
<span class="fc bfc" id="L704" title="All 2 branches covered.">        if (!metadata.get().isIndex())</span>
<span class="fc" id="L705">            SystemKeyspace.removeTruncationRecord(metadata.id);</span>

<span class="pc bpc" id="L707" title="1 of 2 branches missed.">        if (dropData)</span>
        {
<span class="fc" id="L709">            data.dropSSTables();</span>
<span class="fc" id="L710">            LifecycleTransaction.waitForDeletions();</span>
        }
<span class="fc" id="L712">        indexManager.dropAllIndexes(dropData);</span>

<span class="fc" id="L714">        invalidateCaches();</span>
<span class="pc bpc" id="L715" title="1 of 2 branches missed.">        if (topPartitions != null)</span>
<span class="fc" id="L716">            topPartitions.close();</span>
<span class="fc" id="L717">    }</span>

    /**
     * Removes every SSTable in the directory from the Tracker's view.
     * @param directory the unreadable directory, possibly with SSTables in it, but not necessarily.
     */
    void maybeRemoveUnreadableSSTables(File directory)
    {
<span class="fc" id="L725">        data.removeUnreadableSSTables(directory);</span>
<span class="fc" id="L726">    }</span>

    void unregisterMBean() throws MalformedObjectNameException
    {
<span class="fc" id="L730">        ObjectName[] objectNames = {new ObjectName(mbeanName), new ObjectName(oldMBeanName)};</span>
<span class="fc bfc" id="L731" title="All 2 branches covered.">        for (ObjectName objectName : objectNames)</span>
        {
<span class="fc bfc" id="L733" title="All 2 branches covered.">            if (MBeanWrapper.instance.isRegistered(objectName))</span>
<span class="fc" id="L734">                MBeanWrapper.instance.unregisterMBean(objectName);</span>
        }

        // unregister metrics
<span class="fc" id="L738">        metric.release();</span>
<span class="fc" id="L739">    }</span>


    public static ColumnFamilyStore createColumnFamilyStore(Keyspace keyspace, TableMetadataRef metadata, boolean loadSSTables)
    {
<span class="fc" id="L744">        return createColumnFamilyStore(keyspace, metadata.name, metadata, loadSSTables);</span>
    }

    public static ColumnFamilyStore createColumnFamilyStore(Keyspace keyspace,
                                                                         String columnFamily,
                                                                         TableMetadataRef metadata,
                                                                         boolean loadSSTables)
    {
<span class="fc" id="L752">        Directories directories = new Directories(metadata.get());</span>
<span class="fc" id="L753">        return createColumnFamilyStore(keyspace, columnFamily, metadata, directories, loadSSTables, true, false);</span>
    }

    /** This is only directly used by offline tools */
    public static synchronized ColumnFamilyStore createColumnFamilyStore(Keyspace keyspace,
                                                                         String columnFamily,
                                                                         TableMetadataRef metadata,
                                                                         Directories directories,
                                                                         boolean loadSSTables,
                                                                         boolean registerBookkeeping,
                                                                         boolean offline)
    {
<span class="fc" id="L765">        return new ColumnFamilyStore(keyspace, columnFamily,</span>
<span class="fc" id="L766">                                     directories.getUIDGenerator(SSTableIdFactory.instance.defaultBuilder()),</span>
                                     metadata, directories, loadSSTables, registerBookkeeping, offline);
    }

    /**
     * Removes unnecessary files from the cf directory at startup: these include temp files, orphans, zero-length files
     * and compacted sstables. Files that cannot be recognized will be ignored.
     */
    public static void  scrubDataDirectories(TableMetadata metadata) throws StartupException
    {
<span class="fc" id="L776">        Directories directories = new Directories(metadata);</span>
<span class="fc" id="L777">        Set&lt;File&gt; cleanedDirectories = new HashSet&lt;&gt;();</span>

        // clear ephemeral snapshots that were not properly cleared last session (CASSANDRA-7357)
<span class="fc" id="L780">        clearEphemeralSnapshots(directories);</span>

<span class="fc" id="L782">        directories.removeTemporaryDirectories();</span>

<span class="fc" id="L784">        logger.trace(&quot;Removing temporary or obsoleted files from unfinished operations for table {}&quot;, metadata.name);</span>
<span class="pc bpc" id="L785" title="1 of 2 branches missed.">        if (!LifecycleTransaction.removeUnfinishedLeftovers(metadata))</span>
<span class="nc" id="L786">            throw new StartupException(StartupException.ERR_WRONG_DISK_STATE,</span>
<span class="nc" id="L787">                                       String.format(&quot;Cannot remove temporary or obsoleted files for %s due to a problem with transaction &quot; +</span>
                                                     &quot;log files. Please check records with problems in the log messages above and fix them. &quot; +
                                                     &quot;Refer to the 3.0 upgrading instructions in NEWS.txt &quot; +
<span class="nc" id="L790">                                                     &quot;for a description of transaction log files.&quot;, metadata.toString()));</span>

<span class="fc" id="L792">        logger.trace(&quot;Further extra check for orphan sstable files for {}&quot;, metadata.name);</span>
<span class="fc bfc" id="L793" title="All 2 branches covered.">        for (Map.Entry&lt;Descriptor,Set&lt;Component&gt;&gt; sstableFiles : directories.sstableLister(Directories.OnTxnErr.IGNORE).list().entrySet())</span>
        {
<span class="fc" id="L795">            Descriptor desc = sstableFiles.getKey();</span>
<span class="fc" id="L796">            File directory = desc.directory;</span>
<span class="fc" id="L797">            Set&lt;Component&gt; components = sstableFiles.getValue();</span>

<span class="fc bfc" id="L799" title="All 2 branches covered.">            if (!cleanedDirectories.contains(directory))</span>
            {
<span class="fc" id="L801">                cleanedDirectories.add(directory);</span>
<span class="pc bpc" id="L802" title="1 of 2 branches missed.">                for (File tmpFile : desc.getTemporaryFiles())</span>
                {
<span class="nc" id="L804">                    logger.info(&quot;Removing unfinished temporary file {}&quot;, tmpFile);</span>
<span class="nc" id="L805">                    tmpFile.tryDelete();</span>
<span class="nc" id="L806">                }</span>
            }

<span class="fc" id="L809">            desc.getFormat().deleteOrphanedComponents(desc, components);</span>
<span class="fc" id="L810">        }</span>

        // cleanup incomplete saved caches
<span class="fc" id="L813">        Pattern tmpCacheFilePattern = Pattern.compile(metadata.keyspace + '-' + metadata.name + &quot;-(Key|Row)Cache.*\\.tmp$&quot;);</span>
<span class="fc" id="L814">        File dir = new File(DatabaseDescriptor.getSavedCachesLocation());</span>

<span class="pc bpc" id="L816" title="1 of 2 branches missed.">        if (dir.exists())</span>
        {
<span class="pc bpc" id="L818" title="1 of 2 branches missed.">            assert dir.isDirectory();</span>
<span class="pc bpc" id="L819" title="1 of 2 branches missed.">            for (File file : dir.tryList())</span>
<span class="nc bnc" id="L820" title="All 2 branches missed.">                if (tmpCacheFilePattern.matcher(file.name()).matches())</span>
<span class="nc bnc" id="L821" title="All 2 branches missed.">                    if (!file.tryDelete())</span>
<span class="nc" id="L822">                        logger.warn(&quot;could not delete {}&quot;, file.absolutePath());</span>
        }

        // also clean out any index leftovers.
<span class="fc bfc" id="L826" title="All 2 branches covered.">        for (IndexMetadata index : metadata.indexes)</span>
<span class="pc bpc" id="L827" title="1 of 2 branches missed.">            if (!index.isCustom())</span>
            {
<span class="nc" id="L829">                TableMetadata indexMetadata = CassandraIndex.indexCfsMetadata(metadata, index);</span>
<span class="nc" id="L830">                scrubDataDirectories(indexMetadata);</span>
            }
<span class="fc" id="L832">    }</span>

    /**
     * See #{@code StorageService.importNewSSTables} for more info
     *
     * @param ksName The keyspace name
     * @param cfName The columnFamily name
     */
    public static void loadNewSSTables(String ksName, String cfName)
    {
        /* ks/cf existence checks will be done by open and getCFS methods for us */
<span class="fc" id="L843">        Keyspace keyspace = Keyspace.open(ksName);</span>
<span class="fc" id="L844">        keyspace.getColumnFamilyStore(cfName).loadNewSSTables();</span>
<span class="fc" id="L845">    }</span>

    @Deprecated
    public void loadNewSSTables()
    {

<span class="fc" id="L851">        SSTableImporter.Options options = SSTableImporter.Options.options().resetLevel(true).build();</span>
<span class="fc" id="L852">        sstableImporter.importNewSSTables(options);</span>
<span class="fc" id="L853">    }</span>

    /**
     * #{@inheritDoc}
     */
    public synchronized List&lt;String&gt; importNewSSTables(Set&lt;String&gt; srcPaths, boolean resetLevel, boolean clearRepaired, boolean verifySSTables, boolean verifyTokens, boolean invalidateCaches, boolean extendedVerify, boolean copyData)
    {
<span class="fc" id="L860">        SSTableImporter.Options options = SSTableImporter.Options.options(srcPaths)</span>
<span class="fc" id="L861">                                                                 .resetLevel(resetLevel)</span>
<span class="fc" id="L862">                                                                 .clearRepaired(clearRepaired)</span>
<span class="fc" id="L863">                                                                 .verifySSTables(verifySSTables)</span>
<span class="fc" id="L864">                                                                 .verifyTokens(verifyTokens)</span>
<span class="fc" id="L865">                                                                 .invalidateCaches(invalidateCaches)</span>
<span class="fc" id="L866">                                                                 .extendedVerify(extendedVerify)</span>
<span class="fc" id="L867">                                                                 .copyData(copyData).build();</span>

<span class="fc" id="L869">        return sstableImporter.importNewSSTables(options);</span>
    }

    public List&lt;String&gt; importNewSSTables(Set&lt;String&gt; srcPaths, boolean resetLevel, boolean clearRepaired, boolean verifySSTables, boolean verifyTokens, boolean invalidateCaches, boolean extendedVerify)
    {
<span class="nc" id="L874">        return importNewSSTables(srcPaths, resetLevel, clearRepaired, verifySSTables, verifyTokens, invalidateCaches, extendedVerify, false);</span>
    }

    Descriptor getUniqueDescriptorFor(Descriptor descriptor, File targetDirectory)
    {
        Descriptor newDescriptor;
        do
        {
<span class="fc" id="L882">            newDescriptor = new Descriptor(descriptor.version,</span>
                                           targetDirectory,
                                           descriptor.ksname,
                                           descriptor.cfname,
                                           // Increment the generation until we find a filename that doesn't exist. This is needed because the new
                                           // SSTables that are being loaded might already use these generation numbers.
<span class="fc" id="L888">                                           sstableIdGenerator.get());</span>
        }
<span class="pc bpc" id="L890" title="1 of 2 branches missed.">        while (newDescriptor.fileFor(Components.DATA).exists());</span>
<span class="fc" id="L891">        return newDescriptor;</span>
    }

    public void rebuildSecondaryIndex(String idxName)
    {
<span class="nc" id="L896">        rebuildSecondaryIndex(getKeyspaceName(), metadata.name, idxName);</span>
<span class="nc" id="L897">    }</span>

    public static void rebuildSecondaryIndex(String ksName, String cfName, String... idxNames)
    {
<span class="nc" id="L901">        ColumnFamilyStore cfs = Keyspace.open(ksName).getColumnFamilyStore(cfName);</span>

<span class="nc" id="L903">        logger.info(&quot;User Requested secondary index re-build for {}/{} indexes: {}&quot;, ksName, cfName, Joiner.on(',').join(idxNames));</span>
<span class="nc" id="L904">        cfs.indexManager.rebuildIndexesBlocking(Sets.newHashSet(Arrays.asList(idxNames)));</span>
<span class="nc" id="L905">    }</span>

    public AbstractCompactionStrategy createCompactionStrategyInstance(CompactionParams compactionParams)
    {
        try
        {
<span class="fc" id="L911">            Constructor&lt;? extends AbstractCompactionStrategy&gt; constructor =</span>
<span class="fc" id="L912">                compactionParams.klass().getConstructor(ColumnFamilyStore.class, Map.class);</span>
<span class="fc" id="L913">            return constructor.newInstance(this, compactionParams.options());</span>
        }
<span class="nc" id="L915">        catch (NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e)</span>
        {
<span class="nc" id="L917">            throw new RuntimeException(e);</span>
        }
    }

    @Deprecated
    public String getColumnFamilyName()
    {
<span class="fc" id="L924">        return getTableName();</span>
    }

    public String getTableName()
    {
<span class="fc" id="L929">        return name;</span>
    }

    public String getKeyspaceName()
    {
<span class="fc" id="L934">        return keyspace.getName();</span>
    }

    public Descriptor newSSTableDescriptor(File directory)
    {
<span class="fc" id="L939">        return newSSTableDescriptor(directory, DatabaseDescriptor.getSelectedSSTableFormat().getLatestVersion());</span>
    }

    public Descriptor newSSTableDescriptor(File directory, SSTableFormat&lt;?, ?&gt; format)
    {
<span class="fc" id="L944">        return newSSTableDescriptor(directory, format.getLatestVersion());</span>
    }

    public Descriptor newSSTableDescriptor(File directory, Version version)
    {
<span class="fc" id="L949">        Descriptor newDescriptor = new Descriptor(version,</span>
                                                  directory,
<span class="fc" id="L951">                                                  getKeyspaceName(),</span>
                                                  name,
<span class="fc" id="L953">                                                  sstableIdGenerator.get());</span>
<span class="pc bpc" id="L954" title="1 of 2 branches missed.">        assert !newDescriptor.fileFor(Components.DATA).exists();</span>
<span class="fc" id="L955">        return newDescriptor;</span>
    }

    /**
     * Checks with the memtable if it should be switched for the given reason, and if not, calls the specified
     * notification method.
     */
    private void switchMemtableOrNotify(FlushReason reason, Consumer&lt;Memtable&gt; elseNotify)
    {
<span class="fc" id="L964">        Memtable currentMemtable = data.getView().getCurrentMemtable();</span>
<span class="fc bfc" id="L965" title="All 2 branches covered.">        if (currentMemtable.shouldSwitch(reason))</span>
<span class="fc" id="L966">            switchMemtableIfCurrent(currentMemtable, reason);</span>
        else
<span class="fc" id="L968">            elseNotify.accept(currentMemtable);</span>
<span class="fc" id="L969">    }</span>

    /**
     * Switches the memtable iff the live memtable is the one provided
     *
     * @param memtable
     */
    public Future&lt;CommitLogPosition&gt; switchMemtableIfCurrent(Memtable memtable, FlushReason reason)
    {
<span class="fc" id="L978">        synchronized (data)</span>
        {
<span class="pc bpc" id="L980" title="1 of 2 branches missed.">            if (data.getView().getCurrentMemtable() == memtable)</span>
<span class="fc" id="L981">                return switchMemtable(reason);</span>
<span class="nc" id="L982">        }</span>
<span class="nc" id="L983">        logger.debug(&quot;Memtable is no longer current, returning future that completes when current flushing operation completes&quot;);</span>
<span class="nc" id="L984">        return waitForFlushes();</span>
    }

    /*
     * switchMemtable puts Memtable.getSortedContents on the writer executor.  When the write is complete,
     * we turn the writer into an SSTableReader and add it to ssTables where it is available for reads.
     * This method does not block except for synchronizing on Tracker, but the Future it returns will
     * not complete until the Memtable (and all prior Memtables) have been successfully flushed, and the CL
     * marked clean up to the position owned by the Memtable.
     */
    @VisibleForTesting
    public Future&lt;CommitLogPosition&gt; switchMemtable(FlushReason reason)
    {
<span class="fc" id="L997">        synchronized (data)</span>
        {
<span class="fc" id="L999">            logFlush(reason);</span>
<span class="fc" id="L1000">            Flush flush = new Flush(false);</span>
<span class="fc" id="L1001">            flushExecutor.execute(flush);</span>
<span class="fc" id="L1002">            postFlushExecutor.execute(flush.postFlushTask);</span>
<span class="fc" id="L1003">            return flush.postFlushTask;</span>
        }
    }

    // print out size of all memtables we're enqueuing
    private void logFlush(FlushReason reason)
    {
        // reclaiming includes that which we are GC-ing;
<span class="fc" id="L1011">        Memtable.MemoryUsage usage = Memtable.newMemoryUsage();</span>
<span class="fc" id="L1012">        getTracker().getView().getCurrentMemtable().addMemoryUsageTo(usage);</span>

<span class="fc bfc" id="L1014" title="All 2 branches covered.">        for (ColumnFamilyStore indexCfs : indexManager.getAllIndexColumnFamilyStores())</span>
<span class="fc" id="L1015">            indexCfs.getTracker().getView().getCurrentMemtable().addMemoryUsageTo(usage);</span>

<span class="fc" id="L1017">        logger.info(&quot;Enqueuing flush of {}.{}, Reason: {}, Usage: {}&quot;, getKeyspaceName(), name, reason, usage);</span>
<span class="fc" id="L1018">    }</span>


    /**
     * Flush if there is unflushed data in the memtables
     *
     * @return a Future yielding the commit log position that can be guaranteed to have been successfully written
     *         to sstables for this table once the future completes
     */
    public Future&lt;CommitLogPosition&gt; forceFlush(FlushReason reason)
    {
<span class="fc" id="L1029">        synchronized (data)</span>
        {
<span class="fc" id="L1031">            Memtable current = data.getView().getCurrentMemtable();</span>
<span class="fc bfc" id="L1032" title="All 2 branches covered.">            for (ColumnFamilyStore cfs : concatWithIndexes())</span>
<span class="fc bfc" id="L1033" title="All 2 branches covered.">                if (!cfs.data.getView().getCurrentMemtable().isClean())</span>
<span class="fc" id="L1034">                    return flushMemtable(current, reason);</span>
<span class="fc" id="L1035">            return waitForFlushes();</span>
        }
    }

    /**
     * Flush if there is unflushed data that was written to the CommitLog before @param flushIfDirtyBefore
     * (inclusive).
     *
     * @return a Future yielding the commit log position that can be guaranteed to have been successfully written
     *         to sstables for this table once the future completes
     */
    public Future&lt;?&gt; forceFlush(CommitLogPosition flushIfDirtyBefore)
    {
        // we don't loop through the remaining memtables since here we only care about commit log dirtiness
        // and this does not vary between a table and its table-backed indexes
<span class="nc" id="L1050">        Memtable current = data.getView().getCurrentMemtable();</span>
<span class="nc bnc" id="L1051" title="All 2 branches missed.">        if (current.mayContainDataBefore(flushIfDirtyBefore))</span>
<span class="nc" id="L1052">            return flushMemtable(current, FlushReason.COMMITLOG_DIRTY);</span>
<span class="nc" id="L1053">        return waitForFlushes();</span>
    }

    private Future&lt;CommitLogPosition&gt; flushMemtable(Memtable current, FlushReason reason)
    {
<span class="pc bpc" id="L1058" title="1 of 2 branches missed.">        if (current.shouldSwitch(reason))</span>
<span class="fc" id="L1059">            return switchMemtableIfCurrent(current, reason);</span>
        else
<span class="nc" id="L1061">            return waitForFlushes();</span>
    }

    /**
     * @return a Future yielding the commit log position that can be guaranteed to have been successfully written
     *         to sstables for this table once the future completes
     */
    private Future&lt;CommitLogPosition&gt; waitForFlushes()
    {
        // we grab the current memtable; once any preceding memtables have flushed, we know its
        // commitLogLowerBound has been set (as this it is set with the upper bound of the preceding memtable)
<span class="fc" id="L1072">        final Memtable current = data.getView().getCurrentMemtable();</span>
<span class="fc" id="L1073">        return postFlushExecutor.submit(current::getCommitLogLowerBound);</span>
    }

    public CommitLogPosition forceBlockingFlush(FlushReason reason)
    {
<span class="fc" id="L1078">        return FBUtilities.waitOnFuture(forceFlush(reason));</span>
    }

    /**
     * Both synchronises custom secondary indexes and provides ordering guarantees for futures on switchMemtable/flush
     * etc, which expect to be able to wait until the flush (and all prior flushes) requested have completed.
     */
    private final class PostFlush implements Callable&lt;CommitLogPosition&gt;
    {
<span class="fc" id="L1087">        final CountDownLatch latch = newCountDownLatch(1);</span>
        final Memtable mainMemtable;
<span class="fc" id="L1089">        volatile Throwable flushFailure = null;</span>

        private PostFlush(Memtable mainMemtable)
<span class="fc" id="L1092">        {</span>
<span class="fc" id="L1093">            this.mainMemtable = mainMemtable;</span>
<span class="fc" id="L1094">        }</span>

        public CommitLogPosition call()
        {
            try
            {
                // we wait on the latch for the commitLogUpperBound to be set, and so that waiters
                // on this task can rely on all prior flushes being complete
<span class="fc" id="L1102">                latch.await();</span>
            }
<span class="nc" id="L1104">            catch (InterruptedException e)</span>
            {
<span class="nc" id="L1106">                throw new UncheckedInterruptedException(e);</span>
<span class="fc" id="L1107">            }</span>

<span class="fc" id="L1109">            CommitLogPosition commitLogUpperBound = NONE;</span>
            // If a flush errored out but the error was ignored, make sure we don't discard the commit log.
<span class="pc bpc" id="L1111" title="1 of 4 branches missed.">            if (flushFailure == null &amp;&amp; mainMemtable != null)</span>
            {
<span class="fc" id="L1113">                commitLogUpperBound = mainMemtable.getFinalCommitLogUpperBound();</span>
<span class="fc" id="L1114">                CommitLog.instance.discardCompletedSegments(metadata.id, mainMemtable.getCommitLogLowerBound(), commitLogUpperBound);</span>
            }

<span class="fc" id="L1117">            metric.pendingFlushes.dec();</span>

<span class="fc bfc" id="L1119" title="All 2 branches covered.">            if (flushFailure != null)</span>
            {
<span class="nc" id="L1121">                Throwables.throwIfUnchecked(flushFailure);</span>
<span class="nc" id="L1122">                throw new RuntimeException(flushFailure);</span>
            }

<span class="fc" id="L1125">            return commitLogUpperBound;</span>
        }
    }

    /**
     * Should only be constructed/used from switchMemtable() or truncate(), with ownership of the Tracker monitor.
     * In the constructor the current memtable(s) are swapped, and a barrier on outstanding writes is issued;
     * when run by the flushWriter the barrier is waited on to ensure all outstanding writes have completed
     * before all memtables are immediately written, and the CL is either immediately marked clean or, if
     * there are custom secondary indexes, the post flush clean up is left to update those indexes and mark
     * the CL clean
     */
    private final class Flush implements Runnable
    {
        final OpOrder.Barrier writeBarrier;
        final Map&lt;ColumnFamilyStore, Memtable&gt; memtables;
        final FutureTask&lt;CommitLogPosition&gt; postFlushTask;
        final PostFlush postFlush;
        final boolean truncate;

        private Flush(boolean truncate)
<span class="fc" id="L1146">        {</span>
<span class="pc bpc" id="L1147" title="1 of 2 branches missed.">            if (logger.isTraceEnabled())</span>
<span class="nc" id="L1148">                logger.trace(&quot;Creating flush task {}@{}&quot;, hashCode(), name);</span>
            // if true, we won't flush, we'll just wait for any outstanding writes, switch the memtable, and discard
<span class="fc" id="L1150">            this.truncate = truncate;</span>

<span class="fc" id="L1152">            metric.pendingFlushes.inc();</span>
            /*
             * To ensure correctness of switch without blocking writes, run() needs to wait for all write operations
             * started prior to the switch to complete. We do this by creating a Barrier on the writeOrdering
             * that all write operations register themselves with, and assigning this barrier to the memtables,
             * after which we *.issue()* the barrier. This barrier is used to direct write operations started prior
             * to the barrier.issue() into the memtable we have switched out, and any started after to its replacement.
             * In doing so it also tells the write operations to update the commitLogUpperBound of the memtable, so
             * that we know the CL position we are dirty to, which can be marked clean when we complete.
             */
<span class="fc" id="L1162">            writeBarrier = Keyspace.writeOrder.newBarrier();</span>

<span class="fc" id="L1164">            memtables = new LinkedHashMap&lt;&gt;();</span>

            // submit flushes for the memtable for any indexed sub-cfses, and our own
<span class="fc" id="L1167">            AtomicReference&lt;CommitLogPosition&gt; commitLogUpperBound = new AtomicReference&lt;&gt;();</span>
<span class="fc bfc" id="L1168" title="All 2 branches covered.">            for (ColumnFamilyStore cfs : concatWithIndexes())</span>
            {
                // switch all memtables, regardless of their dirty status, setting the barrier
                // so that we can reach a coordinated decision about cleanliness once they
                // are no longer possible to be modified
<span class="fc" id="L1173">                Memtable newMemtable = cfs.createMemtable(commitLogUpperBound);</span>
<span class="fc" id="L1174">                Memtable oldMemtable = cfs.data.switchMemtable(truncate, newMemtable);</span>
<span class="fc" id="L1175">                oldMemtable.switchOut(writeBarrier, commitLogUpperBound);</span>
<span class="fc" id="L1176">                memtables.put(cfs, oldMemtable);</span>
<span class="fc" id="L1177">            }</span>

            // we then ensure an atomic decision is made about the upper bound of the continuous range of commit log
            // records owned by this memtable
<span class="fc" id="L1181">            setCommitLogUpperBound(commitLogUpperBound);</span>

            // we then issue the barrier; this lets us wait for all operations started prior to the barrier to complete;
            // since this happens after wiring up the commitLogUpperBound, we also know all operations with earlier
            // commit log segment position have also completed, i.e. the memtables are done and ready to flush
<span class="fc" id="L1186">            writeBarrier.issue();</span>
<span class="fc" id="L1187">            postFlush = new PostFlush(Iterables.get(memtables.values(), 0, null));</span>
<span class="fc" id="L1188">            postFlushTask = new FutureTask&lt;&gt;(postFlush);</span>
<span class="fc" id="L1189">        }</span>

        public void run()
        {
<span class="pc bpc" id="L1193" title="1 of 2 branches missed.">            if (logger.isTraceEnabled())</span>
<span class="nc" id="L1194">                logger.trace(&quot;Flush task {}@{} starts executing, waiting on barrier&quot;, hashCode(), name);</span>

<span class="fc" id="L1196">            long start = nanoTime();</span>

            // mark writes older than the barrier as blocking progress, permitting them to exceed our memory limit
            // if they are stuck waiting on it, then wait for them all to complete
<span class="fc" id="L1200">            writeBarrier.markBlocking();</span>
<span class="fc" id="L1201">            writeBarrier.await();</span>

<span class="pc bpc" id="L1203" title="1 of 2 branches missed.">            if (logger.isTraceEnabled())</span>
<span class="nc" id="L1204">                logger.trace(&quot;Flush task for task {}@{} waited {} ms at the barrier&quot;, hashCode(), name, TimeUnit.NANOSECONDS.toMillis(nanoTime() - start));</span>

            // mark all memtables as flushing, removing them from the live memtable list
<span class="fc bfc" id="L1207" title="All 2 branches covered.">            for (Map.Entry&lt;ColumnFamilyStore, Memtable&gt; entry : memtables.entrySet())</span>
<span class="fc" id="L1208">                entry.getKey().data.markFlushing(entry.getValue());</span>

<span class="fc" id="L1210">            metric.memtableSwitchCount.inc();</span>

            try
            {
<span class="fc" id="L1214">                boolean first = true;</span>
                // Flush &quot;data&quot; memtable with non-cf 2i first;
<span class="fc bfc" id="L1216" title="All 2 branches covered.">                for (Map.Entry&lt;ColumnFamilyStore, Memtable&gt; entry : memtables.entrySet())</span>
                {
<span class="fc" id="L1218">                    flushMemtable(entry.getKey(), entry.getValue(), first);</span>
<span class="fc" id="L1219">                    first = false;</span>
<span class="fc" id="L1220">                }</span>
            }
<span class="fc" id="L1222">            catch (Throwable t)</span>
            {
<span class="fc" id="L1224">                JVMStabilityInspector.inspectThrowable(t);</span>
<span class="fc" id="L1225">                postFlush.flushFailure = t;</span>
<span class="fc" id="L1226">            }</span>

<span class="pc bpc" id="L1228" title="1 of 2 branches missed.">            if (logger.isTraceEnabled())</span>
<span class="nc" id="L1229">                logger.trace(&quot;Flush task {}@{} signaling post flush task&quot;, hashCode(), name);</span>

            // signal the post-flush we've done our work
<span class="fc" id="L1232">            postFlush.latch.decrement();</span>

<span class="pc bpc" id="L1234" title="1 of 2 branches missed.">            if (logger.isTraceEnabled())</span>
<span class="nc" id="L1235">                logger.trace(&quot;Flush task task {}@{} finished&quot;, hashCode(), name);</span>
<span class="fc" id="L1236">        }</span>

        public Collection&lt;SSTableReader&gt; flushMemtable(ColumnFamilyStore cfs, Memtable memtable, boolean flushNonCf2i)
        {
<span class="pc bpc" id="L1240" title="1 of 2 branches missed.">            if (logger.isTraceEnabled())</span>
<span class="nc" id="L1241">                logger.trace(&quot;Flush task task {}@{} flushing memtable {}&quot;, hashCode(), name, memtable);</span>

<span class="fc bfc" id="L1243" title="All 4 branches covered.">            if (memtable.isClean() || truncate)</span>
            {
<span class="fc" id="L1245">                cfs.replaceFlushed(memtable, Collections.emptyList());</span>
<span class="fc" id="L1246">                reclaim(memtable);</span>
<span class="fc" id="L1247">                return Collections.emptyList();</span>
            }

<span class="fc" id="L1250">            List&lt;Future&lt;SSTableMultiWriter&gt;&gt; futures = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L1251">            long totalBytesOnDisk = 0;</span>
<span class="fc" id="L1252">            long maxBytesOnDisk = 0;</span>
<span class="fc" id="L1253">            long minBytesOnDisk = Long.MAX_VALUE;</span>
<span class="fc" id="L1254">            List&lt;SSTableReader&gt; sstables = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L1255">            try (LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.FLUSH))</span>
            {
<span class="fc" id="L1257">                List&lt;Flushing.FlushRunnable&gt; flushRunnables = null;</span>
<span class="fc" id="L1258">                List&lt;SSTableMultiWriter&gt; flushResults = null;</span>

                try
                {
                    // flush the memtable
<span class="fc" id="L1263">                    flushRunnables = Flushing.flushRunnables(cfs, memtable, txn);</span>
<span class="fc" id="L1264">                    ExecutorPlus[] executors = perDiskflushExecutors.getExecutorsFor(getKeyspaceName(), name);</span>

<span class="fc bfc" id="L1266" title="All 2 branches covered.">                    for (int i = 0; i &lt; flushRunnables.size(); i++)</span>
<span class="fc" id="L1267">                        futures.add(executors[i].submit(flushRunnables.get(i)));</span>

                    /**
                     * we can flush 2is as soon as the barrier completes, as they will be consistent with (or ahead of) the
                     * flushed memtables and CL position, which is as good as we can guarantee.
                     * TODO: SecondaryIndex should support setBarrier(), so custom implementations can co-ordinate exactly
                     * with CL as we do with memtables/CFS-backed SecondaryIndexes.
                     */
<span class="fc bfc" id="L1275" title="All 2 branches covered.">                    if (flushNonCf2i)</span>
<span class="fc" id="L1276">                        indexManager.flushAllNonCFSBackedIndexesBlocking(memtable);</span>

<span class="fc" id="L1278">                    flushResults = Lists.newArrayList(FBUtilities.waitOnFutures(futures));</span>
                }
<span class="fc" id="L1280">                catch (Throwable t)</span>
                {
<span class="fc" id="L1282">                    t = Flushing.abortRunnables(flushRunnables, t);</span>
<span class="fc" id="L1283">                    t = txn.abort(t);</span>
<span class="nc" id="L1284">                    Throwables.throwIfUnchecked(t);</span>
<span class="nc" id="L1285">                    throw new RuntimeException(t);</span>
<span class="fc" id="L1286">                }</span>

                try
                {
<span class="fc" id="L1290">                    Iterator&lt;SSTableMultiWriter&gt; writerIterator = flushResults.iterator();</span>
<span class="fc bfc" id="L1291" title="All 2 branches covered.">                    while (writerIterator.hasNext())</span>
                    {
                        @SuppressWarnings(&quot;resource&quot;)
<span class="fc" id="L1294">                        SSTableMultiWriter writer = writerIterator.next();</span>
<span class="fc bfc" id="L1295" title="All 2 branches covered.">                        if (writer.getBytesWritten() &gt; 0)</span>
                        {
<span class="fc" id="L1297">                            writer.setOpenResult(true).prepareToCommit();</span>
                        }
                        else
                        {
<span class="fc" id="L1301">                            maybeFail(writer.abort(null));</span>
<span class="fc" id="L1302">                            writerIterator.remove();</span>
                        }
<span class="fc" id="L1304">                    }</span>
                }
<span class="nc" id="L1306">                catch (Throwable t)</span>
                {
<span class="nc bnc" id="L1308" title="All 2 branches missed.">                    for (SSTableMultiWriter writer : flushResults)</span>
<span class="nc" id="L1309">                        t = writer.abort(t);</span>
<span class="nc" id="L1310">                    t = txn.abort(t);</span>
<span class="nc" id="L1311">                    Throwables.throwIfUnchecked(t);</span>
<span class="nc" id="L1312">                    throw new RuntimeException(t);</span>
<span class="fc" id="L1313">                }</span>

<span class="fc" id="L1315">                txn.prepareToCommit();</span>

<span class="fc" id="L1317">                Throwable accumulate = null;</span>
<span class="fc bfc" id="L1318" title="All 2 branches covered.">                for (SSTableMultiWriter writer : flushResults)</span>
                {
<span class="fc" id="L1320">                    accumulate = writer.commit(accumulate);</span>
<span class="fc" id="L1321">                    metric.flushSizeOnDisk.update(writer.getOnDiskBytesWritten());</span>
<span class="fc" id="L1322">                }</span>

<span class="fc" id="L1324">                maybeFail(txn.commit(accumulate));</span>

<span class="fc bfc" id="L1326" title="All 2 branches covered.">                for (SSTableMultiWriter writer : flushResults)</span>
                {
<span class="fc" id="L1328">                    Collection&lt;SSTableReader&gt; flushedSSTables = writer.finished();</span>
<span class="fc bfc" id="L1329" title="All 2 branches covered.">                    for (SSTableReader sstable : flushedSSTables)</span>
                    {
<span class="pc bpc" id="L1331" title="1 of 2 branches missed.">                        if (sstable != null)</span>
                        {
<span class="fc" id="L1333">                            sstables.add(sstable);</span>
<span class="fc" id="L1334">                            long size = sstable.bytesOnDisk();</span>
<span class="fc" id="L1335">                            totalBytesOnDisk += size;</span>
<span class="fc" id="L1336">                            maxBytesOnDisk = Math.max(maxBytesOnDisk, size);</span>
<span class="fc" id="L1337">                            minBytesOnDisk = Math.min(minBytesOnDisk, size);</span>
                        }
<span class="fc" id="L1339">                    }</span>
<span class="fc" id="L1340">                }</span>
            }
<span class="fc" id="L1342">            cfs.replaceFlushed(memtable, sstables);</span>
<span class="fc" id="L1343">            reclaim(memtable);</span>
<span class="fc" id="L1344">            cfs.compactionStrategyManager.compactionLogger.flush(sstables);</span>
<span class="fc" id="L1345">            logger.debug(&quot;Flushed to {} ({} sstables, {}), biggest {}, smallest {}&quot;,</span>
                         sstables,
<span class="fc" id="L1347">                         sstables.size(),</span>
<span class="fc" id="L1348">                         FBUtilities.prettyPrintMemory(totalBytesOnDisk),</span>
<span class="fc" id="L1349">                         FBUtilities.prettyPrintMemory(maxBytesOnDisk),</span>
<span class="fc" id="L1350">                         FBUtilities.prettyPrintMemory(minBytesOnDisk));</span>
<span class="fc" id="L1351">            return sstables;</span>
        }

        private void reclaim(final Memtable memtable)
        {
            // issue a read barrier for reclaiming the memory, and offload the wait to another thread
<span class="fc" id="L1357">            final OpOrder.Barrier readBarrier = readOrdering.newBarrier();</span>
<span class="fc" id="L1358">            readBarrier.issue();</span>
<span class="fc" id="L1359">            postFlushTask.addListener(new WrappedRunnable()</span>
<span class="fc" id="L1360">            {</span>
                public void runMayThrow()
                {
<span class="fc" id="L1363">                    readBarrier.await();</span>
<span class="fc" id="L1364">                    memtable.discard();</span>
<span class="fc" id="L1365">                }</span>
            }, reclaimExecutor);
<span class="fc" id="L1367">        }</span>

        @Override
        public String toString()
        {
<span class="nc" id="L1372">            return &quot;Flush &quot; + keyspace + '.' + name;</span>
        }
    }

    public Memtable createMemtable(AtomicReference&lt;CommitLogPosition&gt; commitLogUpperBound)
    {
<span class="fc" id="L1378">        return memtableFactory.create(commitLogUpperBound, metadata, this);</span>
    }

    // atomically set the upper bound for the commit log
    private static void setCommitLogUpperBound(AtomicReference&lt;CommitLogPosition&gt; commitLogUpperBound)
    {
        // we attempt to set the holder to the current commit log context. at the same time all writes to the memtables are
        // also maintaining this value, so if somebody sneaks ahead of us somehow (should be rare) we simply retry,
        // so that we know all operations prior to the position have not reached it yet
        CommitLogPosition lastReplayPosition;
        while (true)
        {
<span class="fc" id="L1390">            lastReplayPosition = new Memtable.LastCommitLogPosition((CommitLog.instance.getCurrentPosition()));</span>
<span class="fc" id="L1391">            CommitLogPosition currentLast = commitLogUpperBound.get();</span>
<span class="pc bpc" id="L1392" title="3 of 4 branches missed.">            if ((currentLast == null || currentLast.compareTo(lastReplayPosition) &lt;= 0)</span>
<span class="pc bpc" id="L1393" title="1 of 2 branches missed.">                &amp;&amp; commitLogUpperBound.compareAndSet(currentLast, lastReplayPosition))</span>
<span class="fc" id="L1394">                break;</span>
<span class="nc" id="L1395">        }</span>
<span class="fc" id="L1396">    }</span>

    @Override
    public Future&lt;CommitLogPosition&gt; signalFlushRequired(Memtable memtable, FlushReason reason)
    {
<span class="fc" id="L1401">        return switchMemtableIfCurrent(memtable, reason);</span>
    }

    @Override
    public Memtable getCurrentMemtable()
    {
<span class="nc" id="L1407">        return data.getView().getCurrentMemtable();</span>
    }

    public static Iterable&lt;Memtable&gt; activeMemtables()
    {
<span class="fc" id="L1412">        return Iterables.transform(ColumnFamilyStore.all(),</span>
<span class="fc" id="L1413">                                   cfs -&gt; cfs.getTracker().getView().getCurrentMemtable());</span>
    }

    @Override
    public Iterable&lt;Memtable&gt; getIndexMemtables()
    {
<span class="fc" id="L1419">        return Iterables.transform(indexManager.getAllIndexColumnFamilyStores(),</span>
<span class="nc" id="L1420">                                   cfs -&gt; cfs.getTracker().getView().getCurrentMemtable());</span>
    }

    /**
     * Insert/Update the column family for this key.
     * Caller is responsible for acquiring Keyspace.switchLock
     * @param update to be applied
     * @param context write context for current update
     * @param updateIndexes whether secondary indexes should be updated
     */
    @SuppressWarnings(&quot;resource&quot;) // opGroup
    public void apply(PartitionUpdate update, CassandraWriteContext context, boolean updateIndexes)

    {
<span class="fc" id="L1434">        long start = nanoTime();</span>
<span class="fc" id="L1435">        OpOrder.Group opGroup = context.getGroup();</span>
<span class="fc" id="L1436">        CommitLogPosition commitLogPosition = context.getPosition();</span>
        try
        {
<span class="fc" id="L1439">            Memtable mt = data.getMemtableFor(opGroup, commitLogPosition);</span>
<span class="fc" id="L1440">            UpdateTransaction indexer = newUpdateTransaction(update, context, updateIndexes, mt);</span>
<span class="fc" id="L1441">            long timeDelta = mt.put(update, indexer, opGroup);</span>
<span class="fc" id="L1442">            DecoratedKey key = update.partitionKey();</span>
<span class="fc" id="L1443">            invalidateCachedPartition(key);</span>
<span class="fc" id="L1444">            metric.topWritePartitionFrequency.addSample(key.getKey(), 1);</span>
<span class="fc bfc" id="L1445" title="All 2 branches covered.">            if (metric.topWritePartitionSize.isEnabled()) // dont compute datasize if not needed</span>
<span class="fc" id="L1446">                metric.topWritePartitionSize.addSample(key.getKey(), update.dataSize());</span>
<span class="fc" id="L1447">            StorageHook.instance.reportWrite(metadata.id, update);</span>
<span class="fc" id="L1448">            metric.writeLatency.addNano(nanoTime() - start);</span>
            // CASSANDRA-11117 - certain resolution paths on memtable put can result in very
            // large time deltas, either through a variety of sentinel timestamps (used for empty values, ensuring
            // a minimal write, etc). This limits the time delta to the max value the histogram
            // can bucket correctly. This also filters the Long.MAX_VALUE case where there was no previous value
            // to update.
<span class="fc bfc" id="L1454" title="All 2 branches covered.">            if(timeDelta &lt; Long.MAX_VALUE)</span>
<span class="fc" id="L1455">                metric.colUpdateTimeDeltaHistogram.update(Math.min(18165375903306L, timeDelta));</span>
        }
<span class="nc" id="L1457">        catch (RuntimeException e)</span>
        {
<span class="nc" id="L1459">            throw new RuntimeException(e.getMessage()</span>
                                       + &quot; for ks: &quot;
<span class="nc" id="L1461">                                       + getKeyspaceName() + &quot;, table: &quot; + name, e);</span>
<span class="fc" id="L1462">        }</span>
<span class="fc" id="L1463">    }</span>
    
    private UpdateTransaction newUpdateTransaction(PartitionUpdate update, CassandraWriteContext context, boolean updateIndexes, Memtable memtable)
    {
<span class="fc bfc" id="L1467" title="All 2 branches covered.">        return updateIndexes</span>
<span class="fc" id="L1468">               ? indexManager.newUpdateTransaction(update, context, FBUtilities.nowInSeconds(), memtable)</span>
<span class="fc" id="L1469">               : UpdateTransaction.NO_OP;</span>
    }

    public static class VersionedLocalRanges extends ArrayList&lt;Splitter.WeightedRange&gt;
    {
        public final long ringVersion;

        public VersionedLocalRanges(long ringVersion, int initialSize)
        {
<span class="fc" id="L1478">            super(initialSize);</span>
<span class="fc" id="L1479">            this.ringVersion = ringVersion;</span>
<span class="fc" id="L1480">        }</span>
    }

    public VersionedLocalRanges localRangesWeighted()
    {
<span class="pc bpc" id="L1485" title="1 of 2 branches missed.">        if (!SchemaConstants.isLocalSystemKeyspace(getKeyspaceName())</span>
<span class="pc bpc" id="L1486" title="1 of 2 branches missed.">            &amp;&amp; getPartitioner() == StorageService.instance.getTokenMetadata().partitioner)</span>
        {
<span class="fc" id="L1488">            DiskBoundaryManager.VersionedRangesAtEndpoint versionedLocalRanges = DiskBoundaryManager.getVersionedLocalRanges(this);</span>
<span class="fc" id="L1489">            Set&lt;Range&lt;Token&gt;&gt; localRanges = versionedLocalRanges.rangesAtEndpoint.ranges();</span>
<span class="fc" id="L1490">            long ringVersion = versionedLocalRanges.ringVersion;</span>

<span class="pc bpc" id="L1492" title="1 of 2 branches missed.">            if (!localRanges.isEmpty())</span>
            {
<span class="fc" id="L1494">                VersionedLocalRanges weightedRanges = new VersionedLocalRanges(ringVersion, localRanges.size());</span>
<span class="fc bfc" id="L1495" title="All 2 branches covered.">                for (Range&lt;Token&gt; r : localRanges)</span>
                {
                    // WeightedRange supports only unwrapped ranges as it relies
                    // on right - left == num tokens equality
<span class="fc bfc" id="L1499" title="All 2 branches covered.">                    for (Range&lt;Token&gt; u: r.unwrap())</span>
<span class="fc" id="L1500">                        weightedRanges.add(new Splitter.WeightedRange(1.0, u));</span>
<span class="fc" id="L1501">                }</span>
<span class="fc" id="L1502">                weightedRanges.sort(Comparator.comparing(Splitter.WeightedRange::left));</span>
<span class="fc" id="L1503">                return weightedRanges;</span>
            }
            else
            {
<span class="nc" id="L1507">                return fullWeightedRange(ringVersion, getPartitioner());</span>
            }
        }
        else
        {
            // Local tables need to cover the full token range and don't care about ring changes.
            // We also end up here if the table's partitioner is not the database's, which can happen in tests.
<span class="nc" id="L1514">            return fullWeightedRange(RING_VERSION_IRRELEVANT, getPartitioner());</span>
        }
    }

    @Override
    public ShardBoundaries localRangeSplits(int shardCount)
    {
<span class="nc bnc" id="L1521" title="All 4 branches missed.">        if (shardCount == 1 || !getPartitioner().splitter().isPresent())</span>
<span class="nc" id="L1522">            return ShardBoundaries.NONE;</span>

<span class="nc" id="L1524">        ShardBoundaries shardBoundaries = cachedShardBoundaries;</span>

<span class="nc bnc" id="L1526" title="All 2 branches missed.">        if (shardBoundaries == null ||</span>
<span class="nc bnc" id="L1527" title="All 4 branches missed.">            shardBoundaries.shardCount() != shardCount ||</span>
            (shardBoundaries.ringVersion != RING_VERSION_IRRELEVANT &amp;&amp;
<span class="nc bnc" id="L1529" title="All 2 branches missed.">             shardBoundaries.ringVersion != StorageService.instance.getTokenMetadata().getRingVersion()))</span>
        {
<span class="nc" id="L1531">            VersionedLocalRanges weightedRanges = localRangesWeighted();</span>

<span class="nc" id="L1533">            List&lt;Token&gt; boundaries = getPartitioner().splitter().get().splitOwnedRanges(shardCount, weightedRanges, false);</span>
<span class="nc" id="L1534">            shardBoundaries = new ShardBoundaries(boundaries.subList(0, boundaries.size() - 1),</span>
                                                  weightedRanges.ringVersion);
<span class="nc" id="L1536">            cachedShardBoundaries = shardBoundaries;</span>
<span class="nc" id="L1537">            logger.debug(&quot;Memtable shard boundaries for {}.{}: {}&quot;, getKeyspaceName(), getTableName(), boundaries);</span>
        }
<span class="nc" id="L1539">        return shardBoundaries;</span>
    }

    @VisibleForTesting
    public static VersionedLocalRanges fullWeightedRange(long ringVersion, IPartitioner partitioner)
    {
<span class="nc" id="L1545">        VersionedLocalRanges ranges = new VersionedLocalRanges(ringVersion, 1);</span>
<span class="nc" id="L1546">        ranges.add(new Splitter.WeightedRange(1.0, new Range&lt;&gt;(partitioner.getMinimumToken(), partitioner.getMinimumToken())));</span>
<span class="nc" id="L1547">        return ranges;</span>
    }

    /**
     * @param sstables
     * @return sstables whose key range overlaps with that of the given sstables, not including itself.
     * (The given sstables may or may not overlap with each other.)
     */
    public Collection&lt;SSTableReader&gt; getOverlappingLiveSSTables(Iterable&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L1557">        logger.trace(&quot;Checking for sstables overlapping {}&quot;, sstables);</span>

        // a normal compaction won't ever have an empty sstables list, but we create a skeleton
        // compaction controller for streaming, and that passes an empty list.
<span class="fc bfc" id="L1561" title="All 2 branches covered.">        if (!sstables.iterator().hasNext())</span>
<span class="fc" id="L1562">            return ImmutableSet.of();</span>

<span class="fc" id="L1564">        View view = data.getView();</span>

<span class="fc" id="L1566">        List&lt;SSTableReader&gt; sortedByFirst = Lists.newArrayList(sstables);</span>
<span class="fc" id="L1567">        sortedByFirst.sort(SSTableReader.firstKeyComparator);</span>

<span class="fc" id="L1569">        List&lt;AbstractBounds&lt;PartitionPosition&gt;&gt; bounds = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L1570">        DecoratedKey first = null, last = null;</span>
        /*
        normalize the intervals covered by the sstables
        assume we have sstables like this (brackets representing first/last key in the sstable);
        [   ] [   ]    [   ]   [  ]
           [   ]         [       ]
        then we can, instead of searching the interval tree 6 times, normalize the intervals and
        only query the tree 2 times, for these intervals;
        [         ]    [          ]
         */
<span class="fc bfc" id="L1580" title="All 2 branches covered.">        for (SSTableReader sstable : sortedByFirst)</span>
        {
<span class="fc bfc" id="L1582" title="All 2 branches covered.">            if (first == null)</span>
            {
<span class="fc" id="L1584">                first = sstable.getFirst();</span>
<span class="fc" id="L1585">                last = sstable.getLast();</span>
            }
            else
            {
<span class="fc bfc" id="L1589" title="All 2 branches covered.">                if (sstable.getFirst().compareTo(last) &lt;= 0) // we do overlap</span>
                {
<span class="fc bfc" id="L1591" title="All 2 branches covered.">                    if (sstable.getLast().compareTo(last) &gt; 0)</span>
<span class="fc" id="L1592">                        last = sstable.getLast();</span>
                }
                else
                {
<span class="fc" id="L1596">                    bounds.add(AbstractBounds.bounds(first, true, last, true));</span>
<span class="fc" id="L1597">                    first = sstable.getFirst();</span>
<span class="fc" id="L1598">                    last = sstable.getLast();</span>
                }
            }
<span class="fc" id="L1601">        }</span>
<span class="fc" id="L1602">        bounds.add(AbstractBounds.bounds(first, true, last, true));</span>
<span class="fc" id="L1603">        Set&lt;SSTableReader&gt; results = new HashSet&lt;&gt;();</span>

<span class="fc bfc" id="L1605" title="All 2 branches covered.">        for (AbstractBounds&lt;PartitionPosition&gt; bound : bounds)</span>
<span class="fc" id="L1606">            Iterables.addAll(results, view.liveSSTablesInBounds(bound.left, bound.right));</span>

<span class="fc" id="L1608">        return Sets.difference(results, ImmutableSet.copyOf(sstables));</span>
    }

    /**
     * like getOverlappingSSTables, but acquires references before returning
     */
    public Refs&lt;SSTableReader&gt; getAndReferenceOverlappingLiveSSTables(Iterable&lt;SSTableReader&gt; sstables)
    {
        while (true)
        {
<span class="fc" id="L1618">            Iterable&lt;SSTableReader&gt; overlapped = getOverlappingLiveSSTables(sstables);</span>
<span class="fc" id="L1619">            Refs&lt;SSTableReader&gt; refs = Refs.tryRef(overlapped);</span>
<span class="pc bpc" id="L1620" title="1 of 2 branches missed.">            if (refs != null)</span>
<span class="fc" id="L1621">                return refs;</span>
<span class="nc" id="L1622">        }</span>
    }

    /*
     * Called after a BinaryMemtable flushes its in-memory data, or we add a file
     * via bootstrap. This information is cached in the ColumnFamilyStore.
     * This is useful for reads because the ColumnFamilyStore first looks in
     * the in-memory store and the into the disk to find the key. If invoked
     * during recoveryMode the onMemtableFlush() need not be invoked.
     *
     * param @ filename - filename just flushed to disk
     */
    public void addSSTable(SSTableReader sstable)
    {
<span class="nc bnc" id="L1636" title="All 2 branches missed.">        assert sstable.getColumnFamilyName().equals(name);</span>
<span class="nc" id="L1637">        addSSTables(Collections.singletonList(sstable));</span>
<span class="nc" id="L1638">    }</span>

    public void addSSTables(Collection&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L1642">        data.addSSTables(sstables);</span>
<span class="fc" id="L1643">        CompactionManager.instance.submitBackground(this);</span>
<span class="fc" id="L1644">    }</span>

    /**
     * Calculate expected file size of SSTable after compaction.
     *
     * If operation type is {@code CLEANUP} and we're not dealing with an index sstable,
     * then we calculate expected file size with checking token range to be eliminated.
     *
     * Otherwise, we just add up all the files' size, which is the worst case file
     * size for compaction of all the list of files given.
     *
     * @param sstables SSTables to calculate expected compacted file size
     * @param operation Operation type
     * @return Expected file size of SSTable after compaction
     */
    public long getExpectedCompactedFileSize(Iterable&lt;SSTableReader&gt; sstables, OperationType operation)
    {
<span class="pc bpc" id="L1661" title="3 of 4 branches missed.">        if (operation != OperationType.CLEANUP || isIndex())</span>
        {
<span class="fc" id="L1663">            return SSTableReader.getTotalBytes(sstables);</span>
        }

        // cleanup size estimation only counts bytes for keys local to this node
<span class="nc" id="L1667">        long expectedFileSize = 0;</span>
<span class="nc" id="L1668">        Collection&lt;Range&lt;Token&gt;&gt; ranges = StorageService.instance.getLocalReplicas(getKeyspaceName()).ranges();</span>
<span class="nc bnc" id="L1669" title="All 2 branches missed.">        for (SSTableReader sstable : sstables)</span>
        {
<span class="nc" id="L1671">            List&lt;SSTableReader.PartitionPositionBounds&gt; positions = sstable.getPositionsForRanges(ranges);</span>
<span class="nc bnc" id="L1672" title="All 2 branches missed.">            for (SSTableReader.PartitionPositionBounds position : positions)</span>
<span class="nc" id="L1673">                expectedFileSize += position.upperPosition - position.lowerPosition;</span>
<span class="nc" id="L1674">        }</span>

<span class="nc" id="L1676">        double compressionRatio = metric.compressionRatio.getValue();</span>
<span class="nc bnc" id="L1677" title="All 2 branches missed.">        if (compressionRatio &gt; 0d)</span>
<span class="nc" id="L1678">            expectedFileSize *= compressionRatio;</span>

<span class="nc" id="L1680">        return expectedFileSize;</span>
    }

    /*
     *  Find the maximum size file in the list .
     */
    public SSTableReader getMaxSizeFile(Iterable&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L1688">        long maxSize = 0L;</span>
<span class="fc" id="L1689">        SSTableReader maxFile = null;</span>
<span class="fc bfc" id="L1690" title="All 2 branches covered.">        for (SSTableReader sstable : sstables)</span>
        {
<span class="fc bfc" id="L1692" title="All 2 branches covered.">            if (sstable.onDiskLength() &gt; maxSize)</span>
            {
<span class="fc" id="L1694">                maxSize = sstable.onDiskLength();</span>
<span class="fc" id="L1695">                maxFile = sstable;</span>
            }
<span class="fc" id="L1697">        }</span>
<span class="fc" id="L1698">        return maxFile;</span>
    }

    public CompactionManager.AllSSTableOpStatus forceCleanup(int jobs) throws ExecutionException, InterruptedException
    {
<span class="fc" id="L1703">        return CompactionManager.instance.performCleanup(ColumnFamilyStore.this, jobs);</span>
    }

    public CompactionManager.AllSSTableOpStatus scrub(boolean disableSnapshot, IScrubber.Options options, int jobs) throws ExecutionException, InterruptedException
    {
<span class="fc" id="L1708">        return scrub(disableSnapshot, false, options, jobs);</span>
    }

    @VisibleForTesting
    public CompactionManager.AllSSTableOpStatus scrub(boolean disableSnapshot, boolean alwaysFail, IScrubber.Options options, int jobs) throws ExecutionException, InterruptedException
    {
        // skip snapshot creation during scrub, SEE JIRA 5891
<span class="pc bpc" id="L1715" title="1 of 2 branches missed.">        if(!disableSnapshot)</span>
        {
<span class="fc" id="L1717">            Instant creationTime = now();</span>
<span class="fc" id="L1718">            String snapshotName = &quot;pre-scrub-&quot; + creationTime.toEpochMilli();</span>
<span class="fc" id="L1719">            snapshotWithoutMemtable(snapshotName, creationTime);</span>
        }

        try
        {
<span class="fc" id="L1724">            return CompactionManager.instance.performScrub(ColumnFamilyStore.this, options, jobs);</span>
        }
<span class="nc" id="L1726">        catch(Throwable t)</span>
        {
<span class="nc bnc" id="L1728" title="All 2 branches missed.">            if (!rebuildOnFailedScrub(t))</span>
<span class="nc" id="L1729">                throw t;</span>

<span class="nc bnc" id="L1731" title="All 2 branches missed.">            return alwaysFail ? CompactionManager.AllSSTableOpStatus.ABORTED : CompactionManager.AllSSTableOpStatus.SUCCESSFUL;</span>
        }
    }

    /**
     * CASSANDRA-5174 : For an index cfs we may be able to discard everything and just rebuild
     * the index when a scrub fails.
     *
     * @return true if we are an index cfs and we successfully rebuilt the index
     */
    public boolean rebuildOnFailedScrub(Throwable failure)
    {
<span class="nc bnc" id="L1743" title="All 4 branches missed.">        if (!isIndex() || !SecondaryIndexManager.isIndexColumnFamilyStore(this))</span>
<span class="nc" id="L1744">            return false;</span>

<span class="nc" id="L1746">        truncateBlocking();</span>

<span class="nc" id="L1748">        logger.warn(&quot;Rebuilding index for {} because of &lt;{}&gt;&quot;, name, failure.getMessage());</span>

<span class="nc" id="L1750">        ColumnFamilyStore parentCfs = SecondaryIndexManager.getParentCfs(this);</span>
<span class="nc bnc" id="L1751" title="All 2 branches missed.">        assert parentCfs.indexManager.getAllIndexColumnFamilyStores().contains(this);</span>

<span class="nc" id="L1753">        String indexName = SecondaryIndexManager.getIndexName(this);</span>

<span class="nc" id="L1755">        parentCfs.rebuildSecondaryIndex(indexName);</span>
<span class="nc" id="L1756">        return true;</span>
    }

    public CompactionManager.AllSSTableOpStatus verify(IVerifier.Options options) throws ExecutionException, InterruptedException
    {
<span class="nc" id="L1761">        return CompactionManager.instance.performVerify(ColumnFamilyStore.this, options);</span>
    }

    /**
     * Rewrites all SSTables according to specified parameters
     *
     * @param skipIfCurrentVersion - if {@link true}, will rewrite only SSTables that have version older than the current one ({@link SSTableFormat#getLatestVersion()})
     * @param skipIfNewerThanTimestamp - max timestamp (local creation time) for SSTable; SSTables created _after_ this timestamp will be excluded from compaction
     * @param skipIfCompressionMatches - if {@link true}, will rewrite only SSTables whose compression parameters are different from {@link TableMetadata#params#getCompressionParameters()} ()}
     * @param jobs number of jobs for parallel execution
     */
    public CompactionManager.AllSSTableOpStatus sstablesRewrite(final boolean skipIfCurrentVersion,
                                                                final long skipIfNewerThanTimestamp,
                                                                final boolean skipIfCompressionMatches,
                                                                final int jobs) throws ExecutionException, InterruptedException
    {
<span class="fc" id="L1777">        return CompactionManager.instance.performSSTableRewrite(ColumnFamilyStore.this, skipIfCurrentVersion, skipIfNewerThanTimestamp, skipIfCompressionMatches, jobs);</span>
    }

    public CompactionManager.AllSSTableOpStatus relocateSSTables(int jobs) throws ExecutionException, InterruptedException
    {
<span class="fc" id="L1782">        return CompactionManager.instance.relocateSSTables(this, jobs);</span>
    }

    public CompactionManager.AllSSTableOpStatus garbageCollect(TombstoneOption tombstoneOption, int jobs) throws ExecutionException, InterruptedException
    {
<span class="nc" id="L1787">        return CompactionManager.instance.performGarbageCollection(this, tombstoneOption, jobs);</span>
    }

    public void markObsolete(Collection&lt;SSTableReader&gt; sstables, OperationType compactionType)
    {
<span class="pc bpc" id="L1792" title="1 of 2 branches missed.">        assert !sstables.isEmpty();</span>
<span class="fc" id="L1793">        maybeFail(data.dropSSTables(Predicates.in(sstables), compactionType, null));</span>
<span class="fc" id="L1794">    }</span>

    void replaceFlushed(Memtable memtable, Collection&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L1798">        data.replaceFlushed(memtable, sstables);</span>
<span class="pc bpc" id="L1799" title="1 of 4 branches missed.">        if (sstables != null &amp;&amp; !sstables.isEmpty())</span>
<span class="fc" id="L1800">            CompactionManager.instance.submitBackground(this);</span>
<span class="fc" id="L1801">    }</span>

    public boolean isValid()
    {
<span class="fc" id="L1805">        return valid;</span>
    }

    /**
     * Package protected for access from the CompactionManager.
     */
    public Tracker getTracker()
    {
<span class="fc" id="L1813">        return data;</span>
    }

    public Set&lt;SSTableReader&gt; getLiveSSTables()
    {
<span class="fc" id="L1818">        return data.getView().liveSSTables();</span>
    }

    public Iterable&lt;SSTableReader&gt; getSSTables(SSTableSet sstableSet)
    {
<span class="fc" id="L1823">        return data.getView().select(sstableSet);</span>
    }

    public Iterable&lt;SSTableReader&gt; getUncompactingSSTables()
    {
<span class="fc" id="L1828">        return data.getUncompacting();</span>
    }

    public Map&lt;TimeUUID, PendingStat&gt; getPendingRepairStats()
    {
<span class="nc" id="L1833">        Map&lt;TimeUUID, PendingStat.Builder&gt; builders = new HashMap&lt;&gt;();</span>
<span class="nc bnc" id="L1834" title="All 2 branches missed.">        for (SSTableReader sstable : getLiveSSTables())</span>
        {
<span class="nc" id="L1836">            TimeUUID session = sstable.getPendingRepair();</span>
<span class="nc bnc" id="L1837" title="All 2 branches missed.">            if (session == null)</span>
<span class="nc" id="L1838">                continue;</span>

<span class="nc bnc" id="L1840" title="All 2 branches missed.">            if (!builders.containsKey(session))</span>
<span class="nc" id="L1841">                builders.put(session, new PendingStat.Builder());</span>

<span class="nc" id="L1843">            builders.get(session).addSSTable(sstable);</span>
<span class="nc" id="L1844">        }</span>

<span class="nc" id="L1846">        Map&lt;TimeUUID, PendingStat&gt; stats = new HashMap&lt;&gt;();</span>
<span class="nc bnc" id="L1847" title="All 2 branches missed.">        for (Map.Entry&lt;TimeUUID, PendingStat.Builder&gt; entry : builders.entrySet())</span>
        {
<span class="nc" id="L1849">            stats.put(entry.getKey(), entry.getValue().build());</span>
<span class="nc" id="L1850">        }</span>
<span class="nc" id="L1851">        return stats;</span>
    }

    /**
     * promotes (or demotes) data attached to an incremental repair session that has either completed successfully,
     * or failed
     *
     * @return session ids whose data could not be released
     */
    public CleanupSummary releaseRepairData(Collection&lt;TimeUUID&gt; sessions, boolean force)
    {
<span class="nc bnc" id="L1862" title="All 2 branches missed.">        if (force)</span>
        {
<span class="nc" id="L1864">            Predicate&lt;SSTableReader&gt; predicate = sst -&gt; {</span>
<span class="nc" id="L1865">                TimeUUID session = sst.getPendingRepair();</span>
<span class="nc bnc" id="L1866" title="All 4 branches missed.">                return session != null &amp;&amp; sessions.contains(session);</span>
            };
<span class="nc" id="L1868">            return runWithCompactionsDisabled(() -&gt; compactionStrategyManager.releaseRepairData(sessions),</span>
                                              predicate, OperationType.STREAM, false, true, true);
        }
        else
        {
<span class="nc" id="L1873">            return compactionStrategyManager.releaseRepairData(sessions);</span>
        }
    }

    public boolean isFilterFullyCoveredBy(ClusteringIndexFilter filter,
                                          DataLimits limits,
                                          CachedPartition cached,
                                          long nowInSec,
                                          boolean enforceStrictLiveness)
    {
        // We can use the cached value only if we know that no data it doesn't contain could be covered
        // by the query filter, that is if:
        //   1) either the whole partition is cached
        //   2) or we can ensure than any data the filter selects is in the cached partition

        // We can guarantee that a partition is fully cached if the number of rows it contains is less than
        // what we're caching. Wen doing that, we should be careful about expiring cells: we should count
        // something expired that wasn't when the partition was cached, or we could decide that the whole
        // partition is cached when it's not. This is why we use CachedPartition#cachedLiveRows.
<span class="nc bnc" id="L1892" title="All 2 branches missed.">        if (cached.cachedLiveRows() &lt; metadata().params.caching.rowsPerPartitionToCache())</span>
<span class="nc" id="L1893">            return true;</span>

        // If the whole partition isn't cached, then we must guarantee that the filter cannot select data that
        // is not in the cache. We can guarantee that if either the filter is a &quot;head filter&quot; and the cached
        // partition has more live rows that queried (where live rows refers to the rows that are live now),
        // or if we can prove that everything the filter selects is in the cached partition based on its content.
<span class="nc bnc" id="L1899" title="All 4 branches missed.">        return (filter.isHeadFilter() &amp;&amp; limits.hasEnoughLiveData(cached,</span>
                                                                  nowInSec,
<span class="nc" id="L1901">                                                                  filter.selectsAllPartition(),</span>
                                                                  enforceStrictLiveness))
<span class="nc bnc" id="L1903" title="All 2 branches missed.">               || filter.isFullyCoveredBy(cached);</span>
    }

    public PaxosRepairHistory getPaxosRepairHistory()
    {
<span class="fc" id="L1908">        return paxosRepairHistory.get().getHistory();</span>
    }

    public PaxosRepairHistory getPaxosRepairHistoryForRanges(Collection&lt;Range&lt;Token&gt;&gt; ranges)
    {
<span class="fc" id="L1913">        return paxosRepairHistory.get().getHistoryForRanges(ranges);</span>
    }

    public void syncPaxosRepairHistory(PaxosRepairHistory sync, boolean flush)
    {
<span class="fc" id="L1918">        paxosRepairHistory.get().merge(sync, flush);</span>
<span class="fc" id="L1919">    }</span>

    public void onPaxosRepairComplete(Collection&lt;Range&lt;Token&gt;&gt; ranges, Ballot highBallot)
    {
<span class="fc" id="L1923">        paxosRepairHistory.get().add(ranges, highBallot, true);</span>
<span class="fc" id="L1924">    }</span>

    public Ballot getPaxosRepairLowBound(DecoratedKey key)
    {
<span class="fc" id="L1928">        return paxosRepairHistory.get().getBallotForToken(key.getToken());</span>
    }

    public long gcBefore(long nowInSec)
    {
<span class="fc" id="L1933">        return nowInSec - metadata().params.gcGraceSeconds;</span>
    }

    @SuppressWarnings(&quot;resource&quot;)
    public RefViewFragment selectAndReference(Function&lt;View, Iterable&lt;SSTableReader&gt;&gt; filter)
    {
<span class="fc" id="L1939">        long failingSince = -1L;</span>
        while (true)
        {
<span class="fc" id="L1942">            ViewFragment view = select(filter);</span>
<span class="fc" id="L1943">            Refs&lt;SSTableReader&gt; refs = Refs.tryRef(view.sstables);</span>
<span class="pc bpc" id="L1944" title="1 of 2 branches missed.">            if (refs != null)</span>
<span class="fc" id="L1945">                return new RefViewFragment(view.sstables, view.memtables, refs);</span>
<span class="nc bnc" id="L1946" title="All 2 branches missed.">            if (failingSince &lt;= 0)</span>
            {
<span class="nc" id="L1948">                failingSince = nanoTime();</span>
            }
<span class="nc bnc" id="L1950" title="All 2 branches missed.">            else if (nanoTime() - failingSince &gt; TimeUnit.MILLISECONDS.toNanos(100))</span>
            {
<span class="nc" id="L1952">                List&lt;SSTableReader&gt; released = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L1953" title="All 2 branches missed.">                for (SSTableReader reader : view.sstables)</span>
<span class="nc bnc" id="L1954" title="All 2 branches missed.">                    if (reader.selfRef().globalCount() == 0)</span>
<span class="nc" id="L1955">                        released.add(reader);</span>
<span class="nc" id="L1956">                NoSpamLogger.log(logger, NoSpamLogger.Level.WARN, 1, TimeUnit.SECONDS,</span>
                                 &quot;Spinning trying to capture readers {}, released: {}, &quot;, view.sstables, released);
<span class="nc" id="L1958">                failingSince = nanoTime();</span>
            }
<span class="nc" id="L1960">        }</span>
    }

    public ViewFragment select(Function&lt;View, Iterable&lt;SSTableReader&gt;&gt; filter)
    {
<span class="fc" id="L1965">        View view = data.getView();</span>
<span class="fc" id="L1966">        List&lt;SSTableReader&gt; sstables = Lists.newArrayList(Objects.requireNonNull(filter.apply(view)));</span>
<span class="fc" id="L1967">        return new ViewFragment(sstables, view.getAllMemtables());</span>
    }

    // WARNING: this returns the set of LIVE sstables only, which may be only partially written
    public List&lt;String&gt; getSSTablesForKey(String key)
    {
<span class="nc" id="L1973">        return getSSTablesForKey(key, false);</span>
    }

    public List&lt;String&gt; getSSTablesForKey(String key, boolean hexFormat)
    {
<span class="fc" id="L1978">        return withSSTablesForKey(key, hexFormat, SSTableReader::getFilename);</span>
    }

    public Map&lt;Integer, Set&lt;String&gt;&gt; getSSTablesForKeyWithLevel(String key, boolean hexFormat)
    {
<span class="nc" id="L1983">        List&lt;Pair&lt;Integer, String&gt;&gt; ssts = withSSTablesForKey(key, hexFormat, sstr -&gt; Pair.create(sstr.getSSTableLevel(), sstr.getFilename()));</span>
<span class="nc" id="L1984">        HashMap&lt;Integer, Set&lt;String&gt;&gt; result = new HashMap&lt;&gt;();</span>
<span class="nc bnc" id="L1985" title="All 2 branches missed.">        for (Pair&lt;Integer, String&gt; sst : ssts)</span>
        {
<span class="nc" id="L1987">            Set&lt;String&gt; perLevel = result.get(sst.left);</span>
<span class="nc bnc" id="L1988" title="All 2 branches missed.">            if (perLevel == null)</span>
            {
<span class="nc" id="L1990">                perLevel = new HashSet&lt;&gt;();</span>
<span class="nc" id="L1991">                result.put(sst.left, perLevel);</span>
            }

<span class="nc" id="L1994">            perLevel.add(sst.right);</span>
<span class="nc" id="L1995">        }</span>

<span class="nc" id="L1997">        return result;</span>
    }

    public &lt;T&gt; List&lt;T&gt; withSSTablesForKey(String key, boolean hexFormat, Function&lt;SSTableReader, T&gt; mapper)
    {
<span class="pc bpc" id="L2002" title="1 of 2 branches missed.">        ByteBuffer keyBuffer = hexFormat ? ByteBufferUtil.hexToBytes(key) : metadata().partitionKeyType.fromString(key);</span>
<span class="fc" id="L2003">        DecoratedKey dk = decorateKey(keyBuffer);</span>
<span class="fc" id="L2004">        try (OpOrder.Group op = readOrdering.start())</span>
        {
<span class="fc" id="L2006">            List&lt;T&gt; mapped = new ArrayList&lt;&gt;();</span>
<span class="pc bpc" id="L2007" title="1 of 2 branches missed.">            for (SSTableReader sstr : select(View.select(SSTableSet.LIVE, dk)).sstables)</span>
            {
                // check if the key actually exists in this sstable, without updating cache and stats
<span class="nc bnc" id="L2010" title="All 2 branches missed.">                if (sstr.getPosition(dk, SSTableReader.Operator.EQ, false) &gt;= 0)</span>
<span class="nc" id="L2011">                    mapped.add(mapper.apply(sstr));</span>
<span class="nc" id="L2012">            }</span>
<span class="fc" id="L2013">            return mapped;</span>
        }
    }

    @Override
    public void beginLocalSampling(String sampler, int capacity, int durationMillis)
    {
<span class="fc" id="L2020">        metric.samplers.get(SamplerType.valueOf(sampler)).beginSampling(capacity, durationMillis);</span>
<span class="fc" id="L2021">    }</span>

    @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })
    @Override
    public List&lt;CompositeData&gt; finishLocalSampling(String sampler, int count) throws OpenDataException
    {
<span class="fc" id="L2027">        Sampler samplerImpl = metric.samplers.get(SamplerType.valueOf(sampler));</span>
<span class="fc" id="L2028">        List&lt;Sample&gt; samplerResults = samplerImpl.finishSampling(count);</span>
<span class="fc" id="L2029">        List&lt;CompositeData&gt; result = new ArrayList&lt;&gt;(count);</span>
<span class="fc bfc" id="L2030" title="All 2 branches covered.">        for (Sample counter : samplerResults)</span>
        {
            //Not duplicating the buffer for safety because AbstractSerializer and ByteBufferUtil.bytesToHex
            //don't modify position or limit
<span class="fc" id="L2034">            result.add(new CompositeDataSupport(COUNTER_COMPOSITE_TYPE, COUNTER_NAMES, new Object[] {</span>
<span class="fc" id="L2035">                    getKeyspaceName() + &quot;.&quot; + name,</span>
<span class="fc" id="L2036">                    counter.count,</span>
<span class="fc" id="L2037">                    counter.error,</span>
<span class="fc" id="L2038">                    samplerImpl.toString(counter.value) })); // string</span>
<span class="fc" id="L2039">        }</span>
<span class="fc" id="L2040">        return result;</span>
    }

    @Override
    public boolean isCompactionDiskSpaceCheckEnabled()
    {
<span class="fc" id="L2046">        return compactionSpaceCheck;</span>
    }

    @Override
    public void compactionDiskSpaceCheck(boolean enable)
    {
<span class="nc" id="L2052">        compactionSpaceCheck = enable;</span>
<span class="nc" id="L2053">    }</span>

    public void cleanupCache()
    {
<span class="nc" id="L2057">        Collection&lt;Range&lt;Token&gt;&gt; ranges = StorageService.instance.getLocalReplicas(getKeyspaceName()).ranges();</span>

<span class="nc" id="L2059">        for (Iterator&lt;RowCacheKey&gt; keyIter = CacheService.instance.rowCache.keyIterator();</span>
<span class="nc bnc" id="L2060" title="All 2 branches missed.">             keyIter.hasNext(); )</span>
        {
<span class="nc" id="L2062">            RowCacheKey key = keyIter.next();</span>
<span class="nc" id="L2063">            DecoratedKey dk = decorateKey(ByteBuffer.wrap(key.key));</span>
<span class="nc bnc" id="L2064" title="All 4 branches missed.">            if (key.sameTable(metadata()) &amp;&amp; !Range.isInRanges(dk.getToken(), ranges))</span>
<span class="nc" id="L2065">                invalidateCachedPartition(dk);</span>
<span class="nc" id="L2066">        }</span>

<span class="nc bnc" id="L2068" title="All 2 branches missed.">        if (metadata().isCounter())</span>
        {
<span class="nc" id="L2070">            for (Iterator&lt;CounterCacheKey&gt; keyIter = CacheService.instance.counterCache.keyIterator();</span>
<span class="nc bnc" id="L2071" title="All 2 branches missed.">                 keyIter.hasNext(); )</span>
            {
<span class="nc" id="L2073">                CounterCacheKey key = keyIter.next();</span>
<span class="nc" id="L2074">                DecoratedKey dk = decorateKey(key.partitionKey());</span>
<span class="nc bnc" id="L2075" title="All 4 branches missed.">                if (key.sameTable(metadata()) &amp;&amp; !Range.isInRanges(dk.getToken(), ranges))</span>
<span class="nc" id="L2076">                    CacheService.instance.counterCache.remove(key);</span>
<span class="nc" id="L2077">            }</span>
        }
<span class="nc" id="L2079">    }</span>

    public ClusteringComparator getComparator()
    {
<span class="fc" id="L2083">        return metadata().comparator;</span>
    }

    public TableSnapshot snapshotWithoutMemtable(String snapshotName)
    {
<span class="nc" id="L2088">        return snapshotWithoutMemtable(snapshotName, now());</span>
    }

    public TableSnapshot snapshotWithoutMemtable(String snapshotName, Instant creationTime)
    {
<span class="fc" id="L2093">        return snapshotWithoutMemtable(snapshotName, null, false, null, null, creationTime);</span>
    }

    /**
     * @param ephemeral If this flag is set to true, the snapshot will be cleaned during next startup
     */
    public TableSnapshot snapshotWithoutMemtable(String snapshotName, Predicate&lt;SSTableReader&gt; predicate, boolean ephemeral, DurationSpec.IntSecondsBound ttl, RateLimiter rateLimiter, Instant creationTime)
    {
<span class="pc bpc" id="L2101" title="1 of 4 branches missed.">        if (ephemeral &amp;&amp; ttl != null)</span>
        {
<span class="nc" id="L2103">            throw new IllegalStateException(String.format(&quot;can not take ephemeral snapshot (%s) while ttl is specified too&quot;, snapshotName));</span>
        }

<span class="fc bfc" id="L2106" title="All 2 branches covered.">        if (rateLimiter == null)</span>
<span class="fc" id="L2107">            rateLimiter = DatabaseDescriptor.getSnapshotRateLimiter();</span>

<span class="fc" id="L2109">        Set&lt;SSTableReader&gt; snapshottedSSTables = new LinkedHashSet&lt;&gt;();</span>
<span class="fc bfc" id="L2110" title="All 2 branches covered.">        for (ColumnFamilyStore cfs : concatWithIndexes())</span>
        {
<span class="fc bfc" id="L2112" title="All 4 branches covered.">            try (RefViewFragment currentView = cfs.selectAndReference(View.select(SSTableSet.CANONICAL, (x) -&gt; predicate == null || predicate.apply(x))))</span>
            {
<span class="fc bfc" id="L2114" title="All 2 branches covered.">                for (SSTableReader ssTable : currentView.sstables)</span>
                {
<span class="fc" id="L2116">                    File snapshotDirectory = Directories.getSnapshotDirectory(ssTable.descriptor, snapshotName);</span>
<span class="fc" id="L2117">                    ssTable.createLinks(snapshotDirectory.path(), rateLimiter); // hard links</span>
<span class="pc bpc" id="L2118" title="1 of 2 branches missed.">                    if (logger.isTraceEnabled())</span>
<span class="nc" id="L2119">                        logger.trace(&quot;Snapshot for {} keyspace data file {} created in {}&quot;, keyspace, ssTable.getFilename(), snapshotDirectory);</span>
<span class="fc" id="L2120">                    snapshottedSSTables.add(ssTable);</span>
<span class="fc" id="L2121">                }</span>
            }
<span class="fc" id="L2123">        }</span>

<span class="fc" id="L2125">        return createSnapshot(snapshotName, ephemeral, ttl, snapshottedSSTables, creationTime);</span>
    }

    protected TableSnapshot createSnapshot(String tag, boolean ephemeral, DurationSpec.IntSecondsBound ttl, Set&lt;SSTableReader&gt; sstables, Instant creationTime) {
<span class="fc" id="L2129">        Set&lt;File&gt; snapshotDirs = sstables.stream()</span>
<span class="fc" id="L2130">                                         .map(s -&gt; Directories.getSnapshotDirectory(s.descriptor, tag).toAbsolute())</span>
<span class="fc bfc" id="L2131" title="All 2 branches covered.">                                         .filter(dir -&gt; !Directories.isSecondaryIndexFolder(dir)) // Remove secondary index subdirectory</span>
<span class="fc" id="L2132">                                         .collect(Collectors.toCollection(HashSet::new));</span>

        // Create and write snapshot manifest
<span class="fc" id="L2135">        SnapshotManifest manifest = new SnapshotManifest(mapToDataFilenames(sstables), ttl, creationTime, ephemeral);</span>
<span class="fc" id="L2136">        File manifestFile = getDirectories().getSnapshotManifestFile(tag);</span>
<span class="fc" id="L2137">        writeSnapshotManifest(manifest, manifestFile);</span>
<span class="fc" id="L2138">        snapshotDirs.add(manifestFile.parent().toAbsolute()); // manifest may create empty snapshot dir</span>

        // Write snapshot schema
<span class="fc bfc" id="L2141" title="All 4 branches covered.">        if (!SchemaConstants.isLocalSystemKeyspace(metadata.keyspace) &amp;&amp; !SchemaConstants.isReplicatedSystemKeyspace(metadata.keyspace))</span>
        {
<span class="fc" id="L2143">            File schemaFile = getDirectories().getSnapshotSchemaFile(tag);</span>
<span class="fc" id="L2144">            writeSnapshotSchema(schemaFile);</span>
<span class="fc" id="L2145">            snapshotDirs.add(schemaFile.parent().toAbsolute()); // schema may create empty snapshot dir</span>
        }

<span class="fc" id="L2148">        TableSnapshot snapshot = new TableSnapshot(metadata.keyspace, metadata.name, metadata.id.asUUID(),</span>
                                                   tag, manifest.createdAt, manifest.expiresAt, snapshotDirs,
                                                   manifest.ephemeral);

<span class="fc" id="L2152">        StorageService.instance.addSnapshot(snapshot);</span>
<span class="fc" id="L2153">        return snapshot;</span>
    }

    private SnapshotManifest writeSnapshotManifest(SnapshotManifest manifest, File manifestFile)
    {
        try
        {
<span class="fc" id="L2160">            manifestFile.parent().tryCreateDirectories();</span>
<span class="fc" id="L2161">            manifest.serializeToJsonFile(manifestFile);</span>
<span class="fc" id="L2162">            return manifest;</span>
        }
<span class="nc" id="L2164">        catch (IOException e)</span>
        {
<span class="nc" id="L2166">            throw new FSWriteError(e, manifestFile);</span>
        }
    }

    private List&lt;String&gt; mapToDataFilenames(Collection&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L2172">        return sstables.stream().map(s -&gt; s.descriptor.relativeFilenameFor(Components.DATA)).collect(Collectors.toList());</span>
    }

    private void writeSnapshotSchema(File schemaFile)
    {
        try
        {
<span class="pc bpc" id="L2179" title="1 of 2 branches missed.">            if (!schemaFile.parent().exists())</span>
<span class="nc" id="L2180">                schemaFile.parent().tryCreateDirectories();</span>

<span class="fc" id="L2182">            try (PrintStream out = new PrintStream(new FileOutputStreamPlus(schemaFile)))</span>
            {
<span class="fc" id="L2184">                SchemaCQLHelper.reCreateStatementsForSchemaCql(metadata(),</span>
<span class="fc" id="L2185">                                                               keyspace.getMetadata())</span>
<span class="fc" id="L2186">                               .forEach(out::println);</span>
            }
        }
<span class="nc" id="L2189">        catch (IOException e)</span>
        {
<span class="nc" id="L2191">            throw new FSWriteError(e, schemaFile);</span>
<span class="fc" id="L2192">        }</span>
<span class="fc" id="L2193">    }</span>

    protected static void clearEphemeralSnapshots(Directories directories)
    {
<span class="fc" id="L2197">        RateLimiter clearSnapshotRateLimiter = DatabaseDescriptor.getSnapshotRateLimiter();</span>

<span class="fc" id="L2199">        List&lt;TableSnapshot&gt; ephemeralSnapshots = new SnapshotLoader(directories).loadSnapshots()</span>
<span class="fc" id="L2200">                                                                                .stream()</span>
<span class="fc" id="L2201">                                                                                .filter(TableSnapshot::isEphemeral)</span>
<span class="fc" id="L2202">                                                                                .collect(Collectors.toList());</span>

<span class="fc bfc" id="L2204" title="All 2 branches covered.">        for (TableSnapshot ephemeralSnapshot : ephemeralSnapshots)</span>
        {
<span class="fc" id="L2206">            logger.trace(&quot;Clearing ephemeral snapshot {} leftover from previous session.&quot;, ephemeralSnapshot.getId());</span>
<span class="fc" id="L2207">            Directories.clearSnapshot(ephemeralSnapshot.getTag(), directories.getCFDirectories(), clearSnapshotRateLimiter);</span>
<span class="fc" id="L2208">        }</span>
<span class="fc" id="L2209">    }</span>

    public Refs&lt;SSTableReader&gt; getSnapshotSSTableReaders(String tag) throws IOException
    {
<span class="fc" id="L2213">        Map&lt;SSTableId, SSTableReader&gt; active = new HashMap&lt;&gt;();</span>
<span class="fc bfc" id="L2214" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.CANONICAL))</span>
<span class="fc" id="L2215">            active.put(sstable.descriptor.id, sstable);</span>
<span class="fc" id="L2216">        Map&lt;Descriptor, Set&lt;Component&gt;&gt; snapshots = getDirectories().sstableLister(Directories.OnTxnErr.IGNORE).snapshots(tag).list();</span>
<span class="fc" id="L2217">        Refs&lt;SSTableReader&gt; refs = new Refs&lt;&gt;();</span>
        try
        {
<span class="fc bfc" id="L2220" title="All 2 branches covered.">            for (Map.Entry&lt;Descriptor, Set&lt;Component&gt;&gt; entries : snapshots.entrySet())</span>
            {
                // Try acquire reference to an active sstable instead of snapshot if it exists,
                // to avoid opening new sstables. If it fails, use the snapshot reference instead.
<span class="fc" id="L2224">                SSTableReader sstable = active.get(entries.getKey().id);</span>
<span class="pc bpc" id="L2225" title="2 of 4 branches missed.">                if (sstable == null || !refs.tryRef(sstable))</span>
                {
<span class="nc bnc" id="L2227" title="All 2 branches missed.">                    if (logger.isTraceEnabled())</span>
<span class="nc" id="L2228">                        logger.trace(&quot;using snapshot sstable {}&quot;, entries.getKey());</span>
                    // open offline so we don't modify components or track hotness.
<span class="nc" id="L2230">                    sstable = SSTableReader.open(this, entries.getKey(), entries.getValue(), metadata, true, true);</span>
<span class="nc" id="L2231">                    refs.tryRef(sstable);</span>
                    // release the self ref as we never add the snapshot sstable to DataTracker where it is otherwise released
<span class="nc" id="L2233">                    sstable.selfRef().release();</span>
                }
<span class="pc bpc" id="L2235" title="1 of 2 branches missed.">                else if (logger.isTraceEnabled())</span>
                {
<span class="nc" id="L2237">                    logger.trace(&quot;using active sstable {}&quot;, entries.getKey());</span>
                }
<span class="fc" id="L2239">            }</span>
        }
<span class="nc" id="L2241">        catch (FSReadError | RuntimeException e)</span>
        {
            // In case one of the snapshot sstables fails to open,
            // we must release the references to the ones we opened so far
<span class="nc" id="L2245">            refs.release();</span>
<span class="nc" id="L2246">            throw e;</span>
<span class="fc" id="L2247">        }</span>
<span class="fc" id="L2248">        return refs;</span>
    }

    /**
     * Take a snap shot of this columnfamily store.
     *
     * @param snapshotName the name of the associated with the snapshot
     */
    public TableSnapshot snapshot(String snapshotName)
    {
<span class="fc" id="L2258">        return snapshot(snapshotName, null);</span>
    }

    public TableSnapshot snapshot(String snapshotName, DurationSpec.IntSecondsBound ttl)
    {
<span class="fc" id="L2263">        return snapshot(snapshotName, false, ttl, null, now());</span>
    }

    /**
     * Take a snap shot of this columnfamily store.
     *
     * @param snapshotName the name of the associated with the snapshot
     * @param skipMemtable Skip flushing the memtable
     * @param ttl duration after which the taken snapshot is removed automatically, if supplied with null, it will never be automatically removed
     * @param rateLimiter Rate limiter for hardlinks-per-second
     * @param creationTime time when this snapshot was taken
     */
    public TableSnapshot snapshot(String snapshotName, boolean skipMemtable, DurationSpec.IntSecondsBound ttl, RateLimiter rateLimiter, Instant creationTime)
    {
<span class="fc" id="L2277">        return snapshot(snapshotName, null, false, skipMemtable, ttl, rateLimiter, creationTime);</span>
    }


    /**
     * @param ephemeral If this flag is set to true, the snapshot will be cleaned up during next startup
     * @param skipMemtable Skip flushing the memtable
     */
    public TableSnapshot snapshot(String snapshotName, Predicate&lt;SSTableReader&gt; predicate, boolean ephemeral, boolean skipMemtable)
    {
<span class="fc" id="L2287">        return snapshot(snapshotName, predicate, ephemeral, skipMemtable, null, null, now());</span>
    }

    /**
     * @param ephemeral If this flag is set to true, the snapshot will be cleaned up during next startup
     * @param skipMemtable Skip flushing the memtable
     * @param ttl duration after which the taken snapshot is removed automatically, if supplied with null, it will never be automatically removed
     * @param rateLimiter Rate limiter for hardlinks-per-second
     * @param creationTime time when this snapshot was taken
     */
    public TableSnapshot snapshot(String snapshotName, Predicate&lt;SSTableReader&gt; predicate, boolean ephemeral, boolean skipMemtable, DurationSpec.IntSecondsBound ttl, RateLimiter rateLimiter, Instant creationTime)
    {
<span class="pc bpc" id="L2299" title="1 of 2 branches missed.">        if (!skipMemtable)</span>
        {
<span class="fc" id="L2301">            Memtable current = getTracker().getView().getCurrentMemtable();</span>
<span class="fc bfc" id="L2302" title="All 2 branches covered.">            if (!current.isClean())</span>
            {
<span class="pc bpc" id="L2304" title="1 of 2 branches missed.">                if (current.shouldSwitch(FlushReason.SNAPSHOT))</span>
<span class="fc" id="L2305">                    FBUtilities.waitOnFuture(switchMemtableIfCurrent(current, FlushReason.SNAPSHOT));</span>
                else
<span class="nc" id="L2307">                    current.performSnapshot(snapshotName);</span>
            }
        }
<span class="fc" id="L2310">        return snapshotWithoutMemtable(snapshotName, predicate, ephemeral, ttl, rateLimiter, creationTime);</span>
    }

    public boolean snapshotExists(String snapshotName)
    {
<span class="fc" id="L2315">        return getDirectories().snapshotExists(snapshotName);</span>
    }


    /**
     * Clear all the snapshots for a given column family.
     *
     * @param snapshotName the user supplied snapshot name. If left empty,
     *                     all the snapshots will be cleaned.
     */
    public void clearSnapshot(String snapshotName)
    {
<span class="fc" id="L2327">        RateLimiter clearSnapshotRateLimiter = DatabaseDescriptor.getSnapshotRateLimiter();</span>

<span class="fc" id="L2329">        List&lt;File&gt; snapshotDirs = getDirectories().getCFDirectories();</span>
<span class="fc" id="L2330">        Directories.clearSnapshot(snapshotName, snapshotDirs, clearSnapshotRateLimiter);</span>
<span class="fc" id="L2331">    }</span>
    /**
     *
     * @return  Return a map of all snapshots to space being used
     * The pair for a snapshot has true size and size on disk.
     */
    public Map&lt;String, TableSnapshot&gt; listSnapshots()
    {
<span class="fc" id="L2339">        return getDirectories().listSnapshots();</span>
    }

    /**
     * @return the cached partition for @param key if it is already present in the cache.
     * Not that this will not readAndCache the parition if it is not present, nor
     * are these calls counted in cache statistics.
     *
     * Note that this WILL cause deserialization of a SerializingCache partition, so if all you
     * need to know is whether a partition is present or not, use containsCachedParition instead.
     */
    public CachedPartition getRawCachedPartition(DecoratedKey key)
    {
<span class="pc bpc" id="L2352" title="1 of 2 branches missed.">        if (!isRowCacheEnabled())</span>
<span class="fc" id="L2353">            return null;</span>
<span class="nc" id="L2354">        IRowCacheEntry cached = CacheService.instance.rowCache.getInternal(new RowCacheKey(metadata(), key));</span>
<span class="nc bnc" id="L2355" title="All 4 branches missed.">        return cached == null || cached instanceof RowCacheSentinel ? null : (CachedPartition)cached;</span>
    }

    private void invalidateCaches()
    {
<span class="fc" id="L2360">        CacheService.instance.invalidateKeyCacheForCf(metadata());</span>
<span class="fc" id="L2361">        CacheService.instance.invalidateRowCacheForCf(metadata());</span>
<span class="pc bpc" id="L2362" title="1 of 2 branches missed.">        if (metadata().isCounter())</span>
<span class="nc" id="L2363">            CacheService.instance.invalidateCounterCacheForCf(metadata());</span>
<span class="fc" id="L2364">    }</span>

    public int invalidateRowCache(Collection&lt;Bounds&lt;Token&gt;&gt; boundsToInvalidate)
    {
<span class="nc" id="L2368">        int invalidatedKeys = 0;</span>
<span class="nc" id="L2369">        for (Iterator&lt;RowCacheKey&gt; keyIter = CacheService.instance.rowCache.keyIterator();</span>
<span class="nc bnc" id="L2370" title="All 2 branches missed.">             keyIter.hasNext(); )</span>
        {
<span class="nc" id="L2372">            RowCacheKey key = keyIter.next();</span>
<span class="nc" id="L2373">            DecoratedKey dk = decorateKey(ByteBuffer.wrap(key.key));</span>
<span class="nc bnc" id="L2374" title="All 4 branches missed.">            if (key.sameTable(metadata()) &amp;&amp; Bounds.isInBounds(dk.getToken(), boundsToInvalidate))</span>
            {
<span class="nc" id="L2376">                invalidateCachedPartition(dk);</span>
<span class="nc" id="L2377">                invalidatedKeys++;</span>
            }
<span class="nc" id="L2379">        }</span>
<span class="nc" id="L2380">        return invalidatedKeys;</span>
    }

    public int invalidateCounterCache(Collection&lt;Bounds&lt;Token&gt;&gt; boundsToInvalidate)
    {
<span class="nc" id="L2385">        int invalidatedKeys = 0;</span>
<span class="nc" id="L2386">        for (Iterator&lt;CounterCacheKey&gt; keyIter = CacheService.instance.counterCache.keyIterator();</span>
<span class="nc bnc" id="L2387" title="All 2 branches missed.">             keyIter.hasNext(); )</span>
        {
<span class="nc" id="L2389">            CounterCacheKey key = keyIter.next();</span>
<span class="nc" id="L2390">            DecoratedKey dk = decorateKey(key.partitionKey());</span>
<span class="nc bnc" id="L2391" title="All 4 branches missed.">            if (key.sameTable(metadata()) &amp;&amp; Bounds.isInBounds(dk.getToken(), boundsToInvalidate))</span>
            {
<span class="nc" id="L2393">                CacheService.instance.counterCache.remove(key);</span>
<span class="nc" id="L2394">                invalidatedKeys++;</span>
            }
<span class="nc" id="L2396">        }</span>
<span class="nc" id="L2397">        return invalidatedKeys;</span>
    }

    /**
     * @return true if @param key is contained in the row cache
     */
    public boolean containsCachedParition(DecoratedKey key)
    {
<span class="nc bnc" id="L2405" title="All 4 branches missed.">        return CacheService.instance.rowCache.getCapacity() != 0 &amp;&amp; CacheService.instance.rowCache.containsKey(new RowCacheKey(metadata(), key));</span>
    }

    public void invalidateCachedPartition(RowCacheKey key)
    {
<span class="nc" id="L2410">        CacheService.instance.rowCache.remove(key);</span>
<span class="nc" id="L2411">    }</span>

    public void invalidateCachedPartition(DecoratedKey key)
    {
<span class="pc bpc" id="L2415" title="1 of 2 branches missed.">        if (!isRowCacheEnabled())</span>
<span class="fc" id="L2416">            return;</span>

<span class="nc" id="L2418">        invalidateCachedPartition(new RowCacheKey(metadata(), key));</span>
<span class="nc" id="L2419">    }</span>

    public ClockAndCount getCachedCounter(ByteBuffer partitionKey, Clustering&lt;?&gt; clustering, ColumnMetadata column, CellPath path)
    {
<span class="pc bpc" id="L2423" title="1 of 2 branches missed.">        if (CacheService.instance.counterCache.getCapacity() == 0L) // counter cache disabled.</span>
<span class="nc" id="L2424">            return null;</span>
<span class="fc" id="L2425">        return CacheService.instance.counterCache.get(CounterCacheKey.create(metadata(), partitionKey, clustering, column, path));</span>
    }

    public void putCachedCounter(ByteBuffer partitionKey, Clustering&lt;?&gt; clustering, ColumnMetadata column, CellPath path, ClockAndCount clockAndCount)
    {
<span class="pc bpc" id="L2430" title="1 of 2 branches missed.">        if (CacheService.instance.counterCache.getCapacity() == 0L) // counter cache disabled.</span>
<span class="nc" id="L2431">            return;</span>
<span class="fc" id="L2432">        CacheService.instance.counterCache.put(CounterCacheKey.create(metadata(), partitionKey, clustering, column, path), clockAndCount);</span>
<span class="fc" id="L2433">    }</span>

    public void forceMajorCompaction()
    {
<span class="fc" id="L2437">        forceMajorCompaction(false);</span>
<span class="fc" id="L2438">    }</span>

    public void forceMajorCompaction(boolean splitOutput)
    {
<span class="fc" id="L2442">        CompactionManager.instance.performMaximal(this, splitOutput);</span>
<span class="fc" id="L2443">    }</span>

    @Override
    public void forceCompactionForTokenRange(Collection&lt;Range&lt;Token&gt;&gt; tokenRanges) throws ExecutionException, InterruptedException
    {
<span class="nc" id="L2448">        CompactionManager.instance.forceCompactionForTokenRange(this, tokenRanges);</span>
<span class="nc" id="L2449">    }</span>

    @Override
    public void forceCompactionForTokenRanges(String... strings)
    {
<span class="nc" id="L2454">        CompactionManager.instance.forceCompactionForTokenRange(this, toTokenRanges(DatabaseDescriptor.getPartitioner(), strings));</span>
<span class="nc" id="L2455">    }</span>

    static Set&lt;Range&lt;Token&gt;&gt; toTokenRanges(IPartitioner partitioner, String... strings)
    {
<span class="nc" id="L2459">        Token.TokenFactory tokenFactory = partitioner.getTokenFactory();</span>
<span class="nc" id="L2460">        Set&lt;Range&lt;Token&gt;&gt; tokenRanges = new HashSet&lt;&gt;();</span>
<span class="nc bnc" id="L2461" title="All 2 branches missed.">        for (String str : strings)</span>
        {
<span class="nc" id="L2463">            String[] splits = str.split(TOKEN_DELIMITER);</span>
<span class="nc bnc" id="L2464" title="All 2 branches missed.">            assert splits.length == 2 : String.format(&quot;Unable to parse token range %s; needs to have two tokens separated by %s&quot;, str, TOKEN_DELIMITER);</span>
<span class="nc" id="L2465">            String lhsStr = splits[0];</span>
<span class="nc bnc" id="L2466" title="All 2 branches missed.">            assert !Strings.isNullOrEmpty(lhsStr) : String.format(&quot;Unable to parse token range %s; left hand side of the token separater is empty&quot;, str);</span>
<span class="nc" id="L2467">            String rhsStr = splits[1];</span>
<span class="nc bnc" id="L2468" title="All 2 branches missed.">            assert !Strings.isNullOrEmpty(rhsStr) : String.format(&quot;Unable to parse token range %s; right hand side of the token separater is empty&quot;, str);</span>
<span class="nc" id="L2469">            Token lhs = tokenFactory.fromString(lhsStr);</span>
<span class="nc" id="L2470">            Token rhs = tokenFactory.fromString(rhsStr);</span>
<span class="nc" id="L2471">            tokenRanges.add(new Range&lt;&gt;(lhs, rhs));</span>
        }
<span class="nc" id="L2473">        return tokenRanges;</span>
    }

    public void forceCompactionForKey(DecoratedKey key)
    {
<span class="nc" id="L2478">        CompactionManager.instance.forceCompactionForKey(this, key);</span>
<span class="nc" id="L2479">    }</span>

    public void forceCompactionKeysIgnoringGcGrace(String... partitionKeysIgnoreGcGrace)
    {
<span class="nc" id="L2483">        List&lt;DecoratedKey&gt; decoratedKeys = new ArrayList&lt;&gt;();</span>
        try
        {
<span class="nc" id="L2486">            partitionKeySetIgnoreGcGrace.clear();</span>

<span class="nc bnc" id="L2488" title="All 2 branches missed.">            for (String key : partitionKeysIgnoreGcGrace) {</span>
<span class="nc" id="L2489">                DecoratedKey dk = decorateKey(metadata().partitionKeyType.fromString(key));</span>
<span class="nc" id="L2490">                partitionKeySetIgnoreGcGrace.add(dk);</span>
<span class="nc" id="L2491">                decoratedKeys.add(dk);</span>
            }

<span class="nc" id="L2494">            CompactionManager.instance.forceCompactionForKeys(this, decoratedKeys);</span>
        } finally
        {
<span class="nc" id="L2497">            partitionKeySetIgnoreGcGrace.clear();</span>
        }
<span class="nc" id="L2499">    }</span>

    public boolean shouldIgnoreGcGraceForKey(DecoratedKey dk)
    {
<span class="fc" id="L2503">        return partitionKeySetIgnoreGcGrace.contains(dk);</span>
    }

    public static Iterable&lt;ColumnFamilyStore&gt; all()
    {
<span class="fc" id="L2508">        List&lt;Iterable&lt;ColumnFamilyStore&gt;&gt; stores = new ArrayList&lt;&gt;(Schema.instance.getKeyspaces().size());</span>
<span class="fc bfc" id="L2509" title="All 2 branches covered.">        for (Keyspace keyspace : Keyspace.all())</span>
        {
<span class="fc" id="L2511">            stores.add(keyspace.getColumnFamilyStores());</span>
<span class="fc" id="L2512">        }</span>
<span class="fc" id="L2513">        return Iterables.concat(stores);</span>
    }

    public Iterable&lt;DecoratedKey&gt; keySamples(Range&lt;Token&gt; range)
    {
<span class="fc" id="L2518">        try (RefViewFragment view = selectAndReference(View.selectFunction(SSTableSet.CANONICAL)))</span>
        {
<span class="fc" id="L2520">            Iterable&lt;DecoratedKey&gt;[] samples = new Iterable[view.sstables.size()];</span>
<span class="fc" id="L2521">            int i = 0;</span>
<span class="pc bpc" id="L2522" title="1 of 2 branches missed.">            for (SSTableReader sstable: view.sstables)</span>
            {
<span class="nc" id="L2524">                samples[i++] = sstable.getKeySamples(range);</span>
<span class="nc" id="L2525">            }</span>
<span class="fc" id="L2526">            return Iterables.concat(samples);</span>
        }
    }

    public long estimatedKeysForRange(Range&lt;Token&gt; range)
    {
<span class="nc" id="L2532">        try (RefViewFragment view = selectAndReference(View.selectFunction(SSTableSet.CANONICAL)))</span>
        {
<span class="nc" id="L2534">            long count = 0;</span>
<span class="nc bnc" id="L2535" title="All 2 branches missed.">            for (SSTableReader sstable : view.sstables)</span>
<span class="nc" id="L2536">                count += sstable.estimatedKeysForRanges(Collections.singleton(range));</span>
<span class="nc" id="L2537">            return count;</span>
        }
    }

    public void writeAndAddMemtableRanges(TimeUUID repairSessionID,
                                          Supplier&lt;Collection&lt;Range&lt;PartitionPosition&gt;&gt;&gt; rangesSupplier,
                                          Refs&lt;SSTableReader&gt; placeIntoRefs)
    {
        @SuppressWarnings(&quot;resource&quot;) // closed by finish or on exception
<span class="fc" id="L2546">        SSTableMultiWriter memtableContent = writeMemtableRanges(rangesSupplier, repairSessionID);</span>
<span class="pc bpc" id="L2547" title="1 of 2 branches missed.">        if (memtableContent != null)</span>
        {
            try
            {
<span class="nc" id="L2551">                Collection&lt;SSTableReader&gt; sstables = memtableContent.finish(true);</span>
<span class="nc" id="L2552">                try (Refs sstableReferences = Refs.ref(sstables))</span>
                {
                    // This moves all references to placeIntoRefs, clearing sstableReferences
<span class="nc" id="L2555">                    placeIntoRefs.addAll(sstableReferences);</span>
                }

                // Release the reference any written sstables start with.
<span class="nc bnc" id="L2559" title="All 2 branches missed.">                for (SSTableReader rdr : sstables)</span>
                {
<span class="nc" id="L2561">                    rdr.selfRef().release();</span>
<span class="nc" id="L2562">                    logger.info(&quot;Memtable ranges (keys {} size {}) written in {}&quot;,</span>
<span class="nc" id="L2563">                                rdr.estimatedKeys(),</span>
<span class="nc" id="L2564">                                rdr.getDataChannel().size(),</span>
                                rdr);
<span class="nc" id="L2566">                }</span>
            }
<span class="nc" id="L2568">            catch (Throwable t)</span>
            {
<span class="nc" id="L2570">                memtableContent.close();</span>
<span class="nc" id="L2571">                Throwables.throwIfUnchecked(t);</span>
<span class="nc" id="L2572">                throw new RuntimeException(t);</span>
<span class="nc" id="L2573">            }</span>
        }
<span class="fc" id="L2575">    }</span>

    private SSTableMultiWriter writeMemtableRanges(Supplier&lt;Collection&lt;Range&lt;PartitionPosition&gt;&gt;&gt; rangesSupplier,
                                                   TimeUUID repairSessionID)
    {
<span class="pc bpc" id="L2580" title="1 of 2 branches missed.">        if (!streamFromMemtable())</span>
<span class="fc" id="L2581">            return null;</span>

<span class="nc" id="L2583">        Collection&lt;Range&lt;PartitionPosition&gt;&gt; ranges = rangesSupplier.get();</span>
<span class="nc" id="L2584">        Memtable current = getTracker().getView().getCurrentMemtable();</span>
<span class="nc bnc" id="L2585" title="All 2 branches missed.">        if (current.isClean())</span>
<span class="nc" id="L2586">            return null;</span>

<span class="nc" id="L2588">        List&lt;Memtable.FlushablePartitionSet&lt;?&gt;&gt; dataSets = new ArrayList&lt;&gt;(ranges.size());</span>
<span class="nc" id="L2589">        IntervalSet.Builder&lt;CommitLogPosition&gt; commitLogIntervals = new IntervalSet.Builder();</span>
<span class="nc" id="L2590">        long keys = 0;</span>
<span class="nc bnc" id="L2591" title="All 2 branches missed.">        for (Range&lt;PartitionPosition&gt; range : ranges)</span>
        {
<span class="nc" id="L2593">            Memtable.FlushablePartitionSet&lt;?&gt; dataSet = current.getFlushSet(range.left, range.right);</span>
<span class="nc" id="L2594">            dataSets.add(dataSet);</span>
<span class="nc" id="L2595">            commitLogIntervals.add(dataSet.commitLogLowerBound(), dataSet.commitLogUpperBound());</span>
<span class="nc" id="L2596">            keys += dataSet.partitionCount();</span>
<span class="nc" id="L2597">        }</span>
<span class="nc bnc" id="L2598" title="All 2 branches missed.">        if (keys == 0)</span>
<span class="nc" id="L2599">            return null;</span>

        // TODO: Can we write directly to stream, skipping disk?
<span class="nc" id="L2602">        Memtable.FlushablePartitionSet&lt;?&gt; firstDataSet = dataSets.get(0);</span>
<span class="nc" id="L2603">        SSTableMultiWriter writer = createSSTableMultiWriter(newSSTableDescriptor(directories.getDirectoryForNewSSTables()),</span>
                                                             keys,
                                                             0,
                                                             repairSessionID,
                                                             false,
<span class="nc" id="L2608">                                                             commitLogIntervals.build(),</span>
                                                             new SerializationHeader(true,
<span class="nc" id="L2610">                                                                                     firstDataSet.metadata(),</span>
<span class="nc" id="L2611">                                                                                     firstDataSet.columns(),</span>
<span class="nc" id="L2612">                                                                                     firstDataSet.encodingStats()),</span>
                                                             DO_NOT_TRACK);
        try
        {
<span class="nc bnc" id="L2616" title="All 2 branches missed.">            for (Memtable.FlushablePartitionSet&lt;?&gt; dataSet : dataSets)</span>
<span class="nc" id="L2617">                new Flushing.FlushRunnable(dataSet, writer, metric, false).call();  // executes on this thread</span>

<span class="nc" id="L2619">            return writer;</span>
        }
<span class="nc" id="L2621">        catch (Error | RuntimeException t)</span>
        {
<span class="nc" id="L2623">            writer.abort(t);</span>
<span class="nc" id="L2624">            throw t;</span>
        }
    }

<span class="fc" id="L2628">    private static final LifecycleNewTracker DO_NOT_TRACK = new LifecycleNewTracker()</span>
<span class="fc" id="L2629">    {</span>
        public void trackNew(SSTable table)
        {
            // not tracking
<span class="nc" id="L2633">        }</span>

        public void untrackNew(SSTable table)
        {
            // not tracking
<span class="nc" id="L2638">        }</span>

        public OperationType opType()
        {
<span class="nc" id="L2642">            return OperationType.FLUSH;</span>
        }
    };

    /**
     * For testing.  No effort is made to clear historical or even the current memtables, nor for
     * thread safety.  All we do is wipe the sstable containers clean, while leaving the actual
     * data files present on disk.  (This allows tests to easily call loadNewSSTables on them.)
     */
    @VisibleForTesting
    public void clearUnsafe()
    {
<span class="fc bfc" id="L2654" title="All 2 branches covered.">        for (final ColumnFamilyStore cfs : concatWithIndexes())</span>
        {
<span class="fc" id="L2656">            cfs.runWithCompactionsDisabled((Callable&lt;Void&gt;) () -&gt; {</span>
<span class="fc" id="L2657">                cfs.data.reset(memtableFactory.create(new AtomicReference&lt;&gt;(CommitLogPosition.NONE), cfs.metadata, cfs));</span>
<span class="fc" id="L2658">                return null;</span>
            }, OperationType.P0, true, false);
<span class="fc" id="L2660">        }</span>
<span class="fc" id="L2661">    }</span>

    public void truncateBlocking()
    {
<span class="fc" id="L2665">        truncateBlocking(false);</span>
<span class="fc" id="L2666">    }</span>

    public void truncateBlockingWithoutSnapshot()
    {
<span class="fc" id="L2670">        truncateBlocking(true);</span>
<span class="fc" id="L2671">    }</span>

    /**
     * Truncate deletes the entire column family's data with no expensive tombstone creation
     * @param noSnapshot if {@code true} no snapshot will be taken
     */
    private void truncateBlocking(boolean noSnapshot)
    {
        // We have two goals here:
        // - truncate should delete everything written before truncate was invoked
        // - but not delete anything that isn't part of the snapshot we create.
        // We accomplish this by first flushing manually, then snapshotting, and
        // recording the timestamp IN BETWEEN those actions. Any sstables created
        // with this timestamp or greater time, will not be marked for delete.
        //
        // Bonus complication: since we store commit log segment position in sstable metadata,
        // truncating those sstables means we will replay any CL segments from the
        // beginning if we restart before they [the CL segments] are discarded for
        // normal reasons post-truncate.  To prevent this, we store truncation
        // position in the System keyspace.
<span class="fc" id="L2691">        logger.info(&quot;Truncating {}.{}&quot;, getKeyspaceName(), name);</span>

<span class="fc" id="L2693">        viewManager.stopBuild();</span>

        final long truncatedAt;
        final CommitLogPosition replayAfter;

<span class="fc bfc" id="L2698" title="All 2 branches covered.">        if (!noSnapshot &amp;&amp;</span>
<span class="pc bpc" id="L2699" title="2 of 4 branches missed.">               ((keyspace.getMetadata().params.durableWrites &amp;&amp; !memtableWritesAreDurable())  // need to clear dirty regions</span>
<span class="nc bnc" id="L2700" title="All 2 branches missed.">               || isAutoSnapshotEnabled()))</span>
        {
<span class="fc" id="L2702">            replayAfter = forceBlockingFlush(FlushReason.TRUNCATE);</span>
<span class="fc" id="L2703">            viewManager.forceBlockingFlush(FlushReason.TRUNCATE);</span>
        }
        else
        {
            // just nuke the memtable data w/o writing to disk first
            // note: this does not wait for the switch to complete, but because the post-flush processing is serial,
            // the call below does.
<span class="fc" id="L2710">            viewManager.dumpMemtables();</span>
<span class="fc" id="L2711">            replayAfter = FBUtilities.waitOnFuture(dumpMemtable());</span>
        }

<span class="fc" id="L2714">        long now = currentTimeMillis();</span>
        // make sure none of our sstables are somehow in the future (clock drift, perhaps)
<span class="fc bfc" id="L2716" title="All 2 branches covered.">        for (ColumnFamilyStore cfs : concatWithIndexes())</span>
<span class="fc bfc" id="L2717" title="All 2 branches covered.">            for (SSTableReader sstable : cfs.getLiveSSTables())</span>
<span class="fc" id="L2718">                now = Math.max(now, sstable.maxDataAge);</span>
<span class="fc" id="L2719">        truncatedAt = now;</span>

<span class="fc" id="L2721">        Runnable truncateRunnable = new Runnable()</span>
<span class="fc" id="L2722">        {</span>
            public void run()
            {
<span class="fc" id="L2725">                logger.info(&quot;Truncating {}.{} with truncatedAt={}&quot;, getKeyspaceName(), getTableName(), truncatedAt);</span>
                // since truncation can happen at different times on different nodes, we need to make sure
                // that any repairs are aborted, otherwise we might clear the data on one node and then
                // stream in data that is actually supposed to have been deleted
<span class="fc" id="L2729">                ActiveRepairService.instance().abort((prs) -&gt; prs.getTableIds().contains(metadata.id),</span>
                                                   &quot;Stopping parent sessions {} due to truncation of tableId=&quot;+metadata.id);
<span class="fc" id="L2731">                data.notifyTruncated(truncatedAt);</span>

<span class="fc bfc" id="L2733" title="All 4 branches covered.">            if (!noSnapshot &amp;&amp; isAutoSnapshotEnabled())</span>
<span class="fc" id="L2734">                snapshot(Keyspace.getTimestampedSnapshotNameWithPrefix(name, SNAPSHOT_TRUNCATE_PREFIX), DatabaseDescriptor.getAutoSnapshotTtl());</span>

<span class="fc" id="L2736">            discardSSTables(truncatedAt);</span>

<span class="fc" id="L2738">            indexManager.truncateAllIndexesBlocking(truncatedAt);</span>
<span class="fc" id="L2739">            viewManager.truncateBlocking(replayAfter, truncatedAt);</span>

<span class="fc" id="L2741">                SystemKeyspace.saveTruncationRecord(ColumnFamilyStore.this, truncatedAt, replayAfter);</span>
<span class="fc" id="L2742">                logger.trace(&quot;cleaning out row cache&quot;);</span>
<span class="fc" id="L2743">                invalidateCaches();</span>

<span class="fc" id="L2745">            }</span>
        };

<span class="fc" id="L2748">        runWithCompactionsDisabled(FutureTask.callable(truncateRunnable), OperationType.P0, true, true);</span>

<span class="fc" id="L2750">        viewManager.build();</span>

<span class="fc" id="L2752">        logger.info(&quot;Truncate of {}.{} is complete&quot;, getKeyspaceName(), name);</span>
<span class="fc" id="L2753">    }</span>

    /**
     * Drops current memtable without flushing to disk. This should only be called when truncating a column family
     * that cannot have dirty intervals in the commit log (i.e. one which is not durable, or where the memtable itself
     * performs durable writes).
     */
    public Future&lt;CommitLogPosition&gt; dumpMemtable()
    {
<span class="fc" id="L2762">        synchronized (data)</span>
        {
<span class="fc" id="L2764">            final Flush flush = new Flush(true);</span>
<span class="fc" id="L2765">            flushExecutor.execute(flush);</span>
<span class="fc" id="L2766">            postFlushExecutor.execute(flush.postFlushTask);</span>
<span class="fc" id="L2767">            return flush.postFlushTask;</span>
        }
    }

    public void unloadCf()
    {
<span class="pc bpc" id="L2773" title="2 of 4 branches missed.">        if (keyspace.getMetadata().params.durableWrites &amp;&amp; !memtableWritesAreDurable())  // need to clear dirty regions</span>
<span class="fc" id="L2774">            forceBlockingFlush(ColumnFamilyStore.FlushReason.DROP);</span>
        else
<span class="nc" id="L2776">            FBUtilities.waitOnFuture(dumpMemtable());</span>
<span class="fc" id="L2777">    }</span>

    public &lt;V&gt; V runWithCompactionsDisabled(Callable&lt;V&gt; callable, OperationType operationType, boolean interruptValidation, boolean interruptViews)
    {
<span class="fc" id="L2781">        return runWithCompactionsDisabled(callable, (sstable) -&gt; true, operationType, interruptValidation, interruptViews, true);</span>
    }

    /**
     * Runs callable with compactions paused and compactions including sstables matching sstablePredicate stopped
     *
     * @param callable what to do when compactions are paused
     * @param sstablesPredicate which sstables should we cancel compactions for
     * @param interruptValidation if we should interrupt validation compactions
     * @param interruptViews if we should interrupt view compactions
     * @param interruptIndexes if we should interrupt compactions on indexes. NOTE: if you set this to true your sstablePredicate
     *                         must be able to handle LocalPartitioner sstables!
     */
    public &lt;V&gt; V runWithCompactionsDisabled(Callable&lt;V&gt; callable, Predicate&lt;SSTableReader&gt; sstablesPredicate, OperationType operationType, boolean interruptValidation, boolean interruptViews, boolean interruptIndexes)
    {
        // synchronize so that concurrent invocations don't re-enable compactions partway through unexpectedly,
        // and so we only run one major compaction at a time
<span class="fc" id="L2798">        synchronized (this)</span>
        {
<span class="fc" id="L2800">            logger.debug(&quot;Cancelling in-progress compactions for {}&quot;, metadata.name);</span>
<span class="fc bfc" id="L2801" title="All 2 branches covered.">            Iterable&lt;ColumnFamilyStore&gt; toInterruptFor = interruptIndexes</span>
<span class="fc" id="L2802">                                                         ? concatWithIndexes()</span>
<span class="fc" id="L2803">                                                         : Collections.singleton(this);</span>

<span class="fc bfc" id="L2805" title="All 2 branches covered.">            toInterruptFor = interruptViews</span>
<span class="fc" id="L2806">                             ? Iterables.concat(toInterruptFor, viewManager.allViewsCfs())</span>
<span class="fc" id="L2807">                             : toInterruptFor;</span>

<span class="fc" id="L2809">            Iterable&lt;TableMetadata&gt; toInterruptForMetadata = Iterables.transform(toInterruptFor, ColumnFamilyStore::metadata);</span>

<span class="fc" id="L2811">            try (CompactionManager.CompactionPauser pause = CompactionManager.instance.pauseGlobalCompaction();</span>
<span class="fc" id="L2812">                 CompactionManager.CompactionPauser pausedStrategies = pauseCompactionStrategies(toInterruptFor))</span>
            {
<span class="fc" id="L2814">                List&lt;CompactionInfo.Holder&gt; uninterruptibleTasks = CompactionManager.instance.getCompactionsMatching(toInterruptForMetadata,</span>
<span class="fc bfc" id="L2815" title="All 2 branches covered.">                                                                                                                     (info) -&gt; info.getTaskType().priority &lt;= operationType.priority);</span>
<span class="fc bfc" id="L2816" title="All 2 branches covered.">                if (!uninterruptibleTasks.isEmpty())</span>
                {
<span class="fc" id="L2818">                    logger.info(&quot;Unable to cancel in-progress compactions, since they're running with higher or same priority: {}. You can abort these operations using `nodetool stop`.&quot;,</span>
<span class="fc" id="L2819">                                uninterruptibleTasks.stream().map((compaction) -&gt; String.format(&quot;%s@%s (%s)&quot;,</span>
<span class="fc" id="L2820">                                                                                                compaction.getCompactionInfo().getTaskType(),</span>
<span class="fc" id="L2821">                                                                                                compaction.getCompactionInfo().getTable(),</span>
<span class="fc" id="L2822">                                                                                                compaction.getCompactionInfo().getTaskId()))</span>
<span class="fc" id="L2823">                                                    .collect(Collectors.joining(&quot;,&quot;)));</span>
<span class="fc" id="L2824">                    return null;</span>
                }

                // interrupt in-progress compactions
<span class="fc" id="L2828">                CompactionManager.instance.interruptCompactionForCFs(toInterruptFor, sstablesPredicate, interruptValidation);</span>
<span class="fc" id="L2829">                CompactionManager.instance.waitForCessation(toInterruptFor, sstablesPredicate);</span>

                // doublecheck that we finished, instead of timing out
<span class="fc bfc" id="L2832" title="All 2 branches covered.">                for (ColumnFamilyStore cfs : toInterruptFor)</span>
                {
<span class="pc bpc" id="L2834" title="1 of 2 branches missed.">                    if (cfs.getTracker().getCompacting().stream().anyMatch(sstablesPredicate))</span>
                    {
<span class="nc" id="L2836">                        logger.warn(&quot;Unable to cancel in-progress compactions for {}. &quot; +</span>
                                    &quot;Perhaps there is an unusually large row in progress somewhere, or the system is simply overloaded.&quot;,
                                    metadata.name);
<span class="nc" id="L2839">                        return null;</span>
                    }
<span class="fc" id="L2841">                }</span>
<span class="fc" id="L2842">                logger.trace(&quot;Compactions successfully cancelled&quot;);</span>

                // run our task
                try
                {
<span class="fc" id="L2847">                    return callable.call();</span>
                }
<span class="fc" id="L2849">                catch (Exception e)</span>
                {
<span class="fc" id="L2851">                    throw new RuntimeException(e);</span>
                }
<span class="pc bpc" id="L2853" title="6 of 8 branches missed.">            }</span>
        }
    }

    private static CompactionManager.CompactionPauser pauseCompactionStrategies(Iterable&lt;ColumnFamilyStore&gt; toPause)
    {
<span class="fc" id="L2859">        ArrayList&lt;ColumnFamilyStore&gt; successfullyPaused = new ArrayList&lt;&gt;();</span>
        try
        {
<span class="fc bfc" id="L2862" title="All 2 branches covered.">            for (ColumnFamilyStore cfs : toPause)</span>
            {
<span class="fc" id="L2864">                successfullyPaused.ensureCapacity(successfullyPaused.size() + 1); // to avoid OOM:ing after pausing the strategies</span>
<span class="fc" id="L2865">                cfs.getCompactionStrategyManager().pause();</span>
<span class="fc" id="L2866">                successfullyPaused.add(cfs);</span>
<span class="fc" id="L2867">            }</span>
<span class="fc" id="L2868">            return () -&gt; maybeFail(resumeAll(null, toPause));</span>
        }
<span class="nc" id="L2870">        catch (Throwable t)</span>
        {
<span class="nc" id="L2872">            resumeAll(t, successfullyPaused);</span>
<span class="nc" id="L2873">            throw t;</span>
        }
    }

    private static Throwable resumeAll(Throwable accumulate, Iterable&lt;ColumnFamilyStore&gt; cfss)
    {
<span class="fc bfc" id="L2879" title="All 2 branches covered.">        for (ColumnFamilyStore cfs : cfss)</span>
        {
            try
            {
<span class="fc" id="L2883">                cfs.getCompactionStrategyManager().resume();</span>
            }
<span class="nc" id="L2885">            catch (Throwable t)</span>
            {
<span class="nc" id="L2887">                accumulate = merge(accumulate, t);</span>
<span class="fc" id="L2888">            }</span>
<span class="fc" id="L2889">        }</span>
<span class="fc" id="L2890">        return accumulate;</span>
    }

    public &lt;T&gt; T withAllSSTables(final OperationType operationType, Function&lt;LifecycleTransaction, T&gt; op)
    {
<span class="fc" id="L2895">        Callable&lt;LifecycleTransaction&gt; callable = () -&gt; {</span>
<span class="pc bpc" id="L2896" title="1 of 2 branches missed.">            assert data.getCompacting().isEmpty() : data.getCompacting();</span>
<span class="fc" id="L2897">            Iterable&lt;SSTableReader&gt; sstables = getLiveSSTables();</span>
<span class="fc" id="L2898">            sstables = AbstractCompactionStrategy.filterSuspectSSTables(sstables);</span>
<span class="fc" id="L2899">            LifecycleTransaction modifier = data.tryModify(sstables, operationType);</span>
<span class="pc bpc" id="L2900" title="1 of 2 branches missed.">            assert modifier != null: &quot;something marked things compacting while compactions are disabled&quot;;</span>
<span class="fc" id="L2901">            return modifier;</span>
        };

<span class="fc" id="L2904">        try (LifecycleTransaction compacting = runWithCompactionsDisabled(callable, operationType, false, false))</span>
        {
<span class="fc" id="L2906">            return op.apply(compacting);</span>
        }
    }

    @Override
    public String toString()
    {
<span class="fc" id="L2913">        return &quot;CFS(&quot; +</span>
<span class="fc" id="L2914">               &quot;Keyspace='&quot; + getKeyspaceName() + '\'' +</span>
               &quot;, ColumnFamily='&quot; + name + '\'' +
               ')';
    }

    public void disableAutoCompaction()
    {
        // we don't use CompactionStrategy.pause since we don't want users flipping that on and off
        // during runWithCompactionsDisabled
<span class="fc" id="L2923">        compactionStrategyManager.disable();</span>
<span class="fc" id="L2924">    }</span>

    public void enableAutoCompaction()
    {
<span class="fc" id="L2928">        enableAutoCompaction(false);</span>
<span class="fc" id="L2929">    }</span>

    /**
     * used for tests - to be able to check things after a minor compaction
     * @param waitForFutures if we should block until autocompaction is done
     */
    @VisibleForTesting
    public void enableAutoCompaction(boolean waitForFutures)
    {
<span class="fc" id="L2938">        compactionStrategyManager.enable();</span>
<span class="fc" id="L2939">        List&lt;Future&lt;?&gt;&gt; futures = CompactionManager.instance.submitBackground(this);</span>
<span class="pc bpc" id="L2940" title="1 of 2 branches missed.">        if (waitForFutures)</span>
<span class="nc" id="L2941">            FBUtilities.waitOnFutures(futures);</span>
<span class="fc" id="L2942">    }</span>

    public boolean isAutoCompactionDisabled()
    {
<span class="fc bfc" id="L2946" title="All 2 branches covered.">        return !this.compactionStrategyManager.isEnabled();</span>
    }

    /*
     JMX getters and setters for the Default&lt;T&gt;s.
       - get/set minCompactionThreshold
       - get/set maxCompactionThreshold
       - get     memsize
       - get     memops
       - get/set memtime
     */

    public CompactionStrategyManager getCompactionStrategyManager()
    {
<span class="fc" id="L2960">        return compactionStrategyManager;</span>
    }

    public void setCrcCheckChance(double crcCheckChance)
    {
        try
        {
<span class="nc" id="L2967">            TableParams.builder().crcCheckChance(crcCheckChance).build().validate();</span>
<span class="nc bnc" id="L2968" title="All 2 branches missed.">            for (ColumnFamilyStore cfs : concatWithIndexes())</span>
            {
<span class="nc" id="L2970">                cfs.crcCheckChance.set(crcCheckChance);</span>
<span class="nc bnc" id="L2971" title="All 2 branches missed.">                for (SSTableReader sstable : cfs.getSSTables(SSTableSet.LIVE))</span>
<span class="nc" id="L2972">                    sstable.setCrcCheckChance(crcCheckChance);</span>
<span class="nc" id="L2973">            }</span>
        }
<span class="nc" id="L2975">        catch (ConfigurationException e)</span>
        {
<span class="nc" id="L2977">            throw new IllegalArgumentException(e.getMessage());</span>
<span class="nc" id="L2978">        }</span>
<span class="nc" id="L2979">    }</span>


    @Override
    public Double getCrcCheckChance()
    {
<span class="fc" id="L2985">        return crcCheckChance.value();</span>
    }

    public void setCompactionThresholds(int minThreshold, int maxThreshold)
    {
<span class="nc" id="L2990">        validateCompactionThresholds(minThreshold, maxThreshold);</span>

<span class="nc" id="L2992">        minCompactionThreshold.set(minThreshold);</span>
<span class="nc" id="L2993">        maxCompactionThreshold.set(maxThreshold);</span>
<span class="nc" id="L2994">        CompactionManager.instance.submitBackground(this);</span>
<span class="nc" id="L2995">    }</span>

    public int getMinimumCompactionThreshold()
    {
<span class="fc" id="L2999">        return minCompactionThreshold.value();</span>
    }

    public void setMinimumCompactionThreshold(int minCompactionThreshold)
    {
<span class="nc" id="L3004">        validateCompactionThresholds(minCompactionThreshold, maxCompactionThreshold.value());</span>
<span class="nc" id="L3005">        this.minCompactionThreshold.set(minCompactionThreshold);</span>
<span class="nc" id="L3006">    }</span>

    public int getMaximumCompactionThreshold()
    {
<span class="fc" id="L3010">        return maxCompactionThreshold.value();</span>
    }

    public void setMaximumCompactionThreshold(int maxCompactionThreshold)
    {
<span class="nc" id="L3015">        validateCompactionThresholds(minCompactionThreshold.value(), maxCompactionThreshold);</span>
<span class="nc" id="L3016">        this.maxCompactionThreshold.set(maxCompactionThreshold);</span>
<span class="nc" id="L3017">    }</span>

    private void validateCompactionThresholds(int minThreshold, int maxThreshold)
    {
<span class="nc bnc" id="L3021" title="All 2 branches missed.">        if (minThreshold &gt; maxThreshold)</span>
<span class="nc" id="L3022">            throw new RuntimeException(String.format(&quot;The min_compaction_threshold cannot be larger than the max_compaction_threshold. &quot; +</span>
<span class="nc" id="L3023">                                                     &quot;Min is '%d', Max is '%d'.&quot;, minThreshold, maxThreshold));</span>

<span class="nc bnc" id="L3025" title="All 4 branches missed.">        if (maxThreshold == 0 || minThreshold == 0)</span>
<span class="nc" id="L3026">            throw new RuntimeException(&quot;Disabling compaction by setting min_compaction_threshold or max_compaction_threshold to 0 &quot; +</span>
                                       &quot;is deprecated, set the compaction strategy option 'enabled' to 'false' instead or use the nodetool command 'disableautocompaction'.&quot;);
<span class="nc" id="L3028">    }</span>

    // End JMX get/set.

    public int getMeanEstimatedCellPerPartitionCount()
    {
<span class="fc" id="L3034">        long sum = 0;</span>
<span class="fc" id="L3035">        long count = 0;</span>
<span class="fc bfc" id="L3036" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.CANONICAL))</span>
        {
<span class="fc" id="L3038">            long n = sstable.getEstimatedCellPerPartitionCount().count();</span>
<span class="fc" id="L3039">            sum += sstable.getEstimatedCellPerPartitionCount().mean() * n;</span>
<span class="fc" id="L3040">            count += n;</span>
<span class="fc" id="L3041">        }</span>
<span class="fc bfc" id="L3042" title="All 2 branches covered.">        return count &gt; 0 ? (int) (sum / count) : 0;</span>
    }

    public double getMeanPartitionSize()
    {
<span class="fc" id="L3047">        long sum = 0;</span>
<span class="fc" id="L3048">        long count = 0;</span>
<span class="fc bfc" id="L3049" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.CANONICAL))</span>
        {
<span class="fc" id="L3051">            long n = sstable.getEstimatedPartitionSize().count();</span>
<span class="fc" id="L3052">            sum += sstable.getEstimatedPartitionSize().mean() * n;</span>
<span class="fc" id="L3053">            count += n;</span>
<span class="fc" id="L3054">        }</span>
<span class="fc bfc" id="L3055" title="All 2 branches covered.">        return count &gt; 0 ? sum * 1.0 / count : 0;</span>
    }

    public int getMeanRowCount()
    {
<span class="fc" id="L3060">        long totalRows = 0;</span>
<span class="fc" id="L3061">        long totalPartitions = 0;</span>
<span class="fc bfc" id="L3062" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.CANONICAL))</span>
        {
<span class="fc" id="L3064">            totalPartitions += sstable.getEstimatedPartitionSize().count();</span>
<span class="fc" id="L3065">            totalRows += sstable.getTotalRows();</span>
<span class="fc" id="L3066">        }</span>

<span class="pc bpc" id="L3068" title="1 of 2 branches missed.">        return totalPartitions &gt; 0 ? (int) (totalRows / totalPartitions) : 0;</span>
    }

    public long estimateKeys()
    {
<span class="fc" id="L3073">        long n = 0;</span>
<span class="fc bfc" id="L3074" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.CANONICAL))</span>
<span class="fc" id="L3075">            n += sstable.estimatedKeys();</span>
<span class="fc" id="L3076">        return n;</span>
    }

    public IPartitioner getPartitioner()
    {
<span class="fc" id="L3081">        return metadata().partitioner;</span>
    }

    public DecoratedKey decorateKey(ByteBuffer key)
    {
<span class="fc" id="L3086">        return getPartitioner().decorateKey(key);</span>
    }

    /** true if this CFS contains secondary index data */
    public boolean isIndex()
    {
<span class="fc" id="L3092">        return metadata().isIndex();</span>
    }

    public Iterable&lt;ColumnFamilyStore&gt; concatWithIndexes()
    {
        // we return the main CFS first, which we rely on for simplicity in switchMemtable(), for getting the
        // latest commit log segment position
<span class="fc" id="L3099">        return Iterables.concat(Collections.singleton(this), indexManager.getAllIndexColumnFamilyStores());</span>
    }

    public List&lt;String&gt; getBuiltIndexes()
    {
<span class="fc" id="L3104">        return indexManager.getBuiltIndexNames();</span>
    }

    @Override
    public int getUnleveledSSTables()
    {
<span class="fc" id="L3110">        return compactionStrategyManager.getUnleveledSSTables();</span>
    }

    @Override
    public int[] getSSTableCountPerLevel()
    {
<span class="fc" id="L3116">        return compactionStrategyManager.getSSTableCountPerLevel();</span>
    }

    @Override
    public long[] getPerLevelSizeBytes()
    {
<span class="fc" id="L3122">        return compactionStrategyManager.getPerLevelSizeBytes();</span>
    }

    @Override
    public boolean isLeveledCompaction()
    {
<span class="fc" id="L3128">        return compactionStrategyManager.isLeveledCompaction();</span>
    }

    @Override
    public int[] getSSTableCountPerTWCSBucket()
    {
<span class="fc" id="L3134">        return compactionStrategyManager.getSSTableCountPerTWCSBucket();</span>
    }

    @Override
    public int getLevelFanoutSize()
    {
<span class="fc" id="L3140">        return compactionStrategyManager.getLevelFanoutSize();</span>
    }

    public static class ViewFragment
    {
        public final List&lt;SSTableReader&gt; sstables;
        public final Iterable&lt;Memtable&gt; memtables;

        public ViewFragment(List&lt;SSTableReader&gt; sstables, Iterable&lt;Memtable&gt; memtables)
<span class="fc" id="L3149">        {</span>
<span class="fc" id="L3150">            this.sstables = sstables;</span>
<span class="fc" id="L3151">            this.memtables = memtables;</span>
<span class="fc" id="L3152">        }</span>
    }

    public static class RefViewFragment extends ViewFragment implements AutoCloseable
    {
        public final Refs&lt;SSTableReader&gt; refs;

        public RefViewFragment(List&lt;SSTableReader&gt; sstables, Iterable&lt;Memtable&gt; memtables, Refs&lt;SSTableReader&gt; refs)
        {
<span class="fc" id="L3161">            super(sstables, memtables);</span>
<span class="fc" id="L3162">            this.refs = refs;</span>
<span class="fc" id="L3163">        }</span>

        public void release()
        {
<span class="nc" id="L3167">            refs.release();</span>
<span class="nc" id="L3168">        }</span>

        public void close()
        {
<span class="fc" id="L3172">            refs.release();</span>
<span class="fc" id="L3173">        }</span>
    }

    public boolean isEmpty()
    {
<span class="fc" id="L3178">        return data.getView().isEmpty();</span>
    }

    public boolean isRowCacheEnabled()
    {

<span class="pc bpc" id="L3184" title="3 of 4 branches missed.">        boolean retval = metadata().params.caching.cacheRows() &amp;&amp; CacheService.instance.rowCache.getCapacity() &gt; 0;</span>
<span class="pc bpc" id="L3185" title="3 of 4 branches missed.">        assert(!retval || !isIndex());</span>
<span class="fc" id="L3186">        return retval;</span>
    }

    public boolean isCounterCacheEnabled()
    {
<span class="nc bnc" id="L3191" title="All 4 branches missed.">        return metadata().isCounter() &amp;&amp; CacheService.instance.counterCache.getCapacity() &gt; 0;</span>
    }

    public boolean isKeyCacheEnabled()
    {
<span class="nc bnc" id="L3196" title="All 4 branches missed.">        return metadata().params.caching.cacheKeys() &amp;&amp; CacheService.instance.keyCache.getCapacity() &gt; 0;</span>
    }

    public boolean isAutoSnapshotEnabled()
    {
<span class="fc bfc" id="L3201" title="All 4 branches covered.">        return metadata().params.allowAutoSnapshot &amp;&amp; DatabaseDescriptor.isAutoSnapshot();</span>
    }

    public boolean isTableIncrementalBackupsEnabled()
    {
<span class="fc bfc" id="L3206" title="All 4 branches covered.">        return DatabaseDescriptor.isIncrementalBackupsEnabled() &amp;&amp; metadata().params.incrementalBackups;</span>
    }

    /**
     * Discard all SSTables that were created before given timestamp.
     *
     * Caller should first ensure that comapctions have quiesced.
     *
     * @param truncatedAt The timestamp of the truncation
     *                    (all SSTables before that timestamp are going be marked as compacted)
     */
    public void discardSSTables(long truncatedAt)
    {
<span class="pc bpc" id="L3219" title="1 of 2 branches missed.">        assert data.getCompacting().isEmpty() : data.getCompacting();</span>

<span class="fc" id="L3221">        List&lt;SSTableReader&gt; truncatedSSTables = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L3222">        int keptSSTables = 0;</span>
<span class="fc bfc" id="L3223" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.LIVE))</span>
        {
<span class="pc bpc" id="L3225" title="1 of 2 branches missed.">            if (!sstable.newSince(truncatedAt))</span>
            {
<span class="fc" id="L3227">                truncatedSSTables.add(sstable);</span>
            }
            else
            {
<span class="nc" id="L3231">                keptSSTables++;</span>
<span class="nc" id="L3232">                logger.info(&quot;Truncation is keeping {} maxDataAge={} truncatedAt={}&quot;, sstable, sstable.maxDataAge, truncatedAt);</span>
            }
<span class="fc" id="L3234">        }</span>

<span class="fc bfc" id="L3236" title="All 2 branches covered.">        if (!truncatedSSTables.isEmpty())</span>
        {
<span class="fc" id="L3238">            logger.info(&quot;Truncation is dropping {} sstables and keeping {} due to sstable.maxDataAge &gt; truncatedAt&quot;, truncatedSSTables.size(), keptSSTables);</span>
<span class="fc" id="L3239">            markObsolete(truncatedSSTables, OperationType.UNKNOWN);</span>
        }
<span class="fc" id="L3241">    }</span>

    @Override
    public double getDroppableTombstoneRatio()
    {
<span class="fc" id="L3246">        double allDroppable = 0;</span>
<span class="fc" id="L3247">        long allColumns = 0;</span>
<span class="fc" id="L3248">        int localTime = (int)(currentTimeMillis() / 1000);</span>

<span class="fc bfc" id="L3250" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.LIVE))</span>
        {
<span class="fc" id="L3252">            allDroppable += sstable.getDroppableTombstonesBefore(localTime - metadata().params.gcGraceSeconds);</span>
<span class="fc" id="L3253">            allColumns += sstable.getEstimatedCellPerPartitionCount().mean() * sstable.getEstimatedCellPerPartitionCount().count();</span>
<span class="fc" id="L3254">        }</span>
<span class="fc bfc" id="L3255" title="All 2 branches covered.">        return allColumns &gt; 0 ? allDroppable / allColumns : 0;</span>
    }

    @Override
    public long trueSnapshotsSize()
    {
<span class="fc" id="L3261">        return getDirectories().trueSnapshotsSize();</span>
    }

    /**
     * Returns a ColumnFamilyStore by id if it exists, null otherwise
     * Differently from others, this method does not throw exception if the table does not exist.
     */
    public static ColumnFamilyStore getIfExists(TableId id)
    {
<span class="fc" id="L3270">        TableMetadata metadata = Schema.instance.getTableMetadata(id);</span>
<span class="pc bpc" id="L3271" title="1 of 2 branches missed.">        if (metadata == null)</span>
<span class="nc" id="L3272">            return null;</span>

<span class="fc" id="L3274">        Keyspace keyspace = Keyspace.open(metadata.keyspace);</span>
<span class="pc bpc" id="L3275" title="1 of 2 branches missed.">        if (keyspace == null)</span>
<span class="nc" id="L3276">            return null;</span>

<span class="pc bpc" id="L3278" title="1 of 2 branches missed.">        return keyspace.hasColumnFamilyStore(id)</span>
<span class="fc" id="L3279">             ? keyspace.getColumnFamilyStore(id)</span>
<span class="nc" id="L3280">             : null;</span>
    }

    /**
     * Returns a ColumnFamilyStore by ksname and cfname if it exists, null otherwise
     * Differently from others, this method does not throw exception if the keyspace or table does not exist.
     */
    public static ColumnFamilyStore getIfExists(String ksName, String cfName)
    {
<span class="pc bpc" id="L3289" title="2 of 4 branches missed.">        if (ksName == null || cfName == null)</span>
<span class="nc" id="L3290">            return null;</span>

<span class="fc" id="L3292">        Keyspace keyspace = Keyspace.open(ksName);</span>
<span class="pc bpc" id="L3293" title="1 of 2 branches missed.">        if (keyspace == null)</span>
<span class="nc" id="L3294">            return null;</span>

<span class="fc" id="L3296">        TableMetadata table = Schema.instance.getTableMetadata(ksName, cfName);</span>
<span class="pc bpc" id="L3297" title="1 of 2 branches missed.">        if (table == null)</span>
<span class="nc" id="L3298">            return null;</span>

<span class="fc" id="L3300">        return keyspace.getColumnFamilyStore(table.id);</span>
    }

    public static TableMetrics metricsFor(TableId tableId)
    {
<span class="fc" id="L3305">        return Objects.requireNonNull(getIfExists(tableId)).metric;</span>
    }

    /**
     * Grabs the global first/last tokens among sstables and returns the range of data directories that start/end with those tokens.
     *
     * This is done to avoid grabbing the disk boundaries for every sstable in case of huge compactions.
     */
    public List&lt;File&gt; getDirectoriesForFiles(Set&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L3315">        Directories.DataDirectory[] writeableLocations = directories.getWriteableLocations();</span>
<span class="fc bfc" id="L3316" title="All 4 branches covered.">        if (writeableLocations.length == 1 || sstables.isEmpty())</span>
        {
<span class="fc" id="L3318">            List&lt;File&gt; ret = new ArrayList&lt;&gt;(writeableLocations.length);</span>
<span class="fc bfc" id="L3319" title="All 2 branches covered.">            for (Directories.DataDirectory ddir : writeableLocations)</span>
<span class="fc" id="L3320">                ret.add(getDirectories().getLocationForDisk(ddir));</span>
<span class="fc" id="L3321">            return ret;</span>
        }

<span class="fc" id="L3324">        DecoratedKey first = null;</span>
<span class="fc" id="L3325">        DecoratedKey last = null;</span>
<span class="fc bfc" id="L3326" title="All 2 branches covered.">        for (SSTableReader sstable : sstables)</span>
        {
<span class="fc bfc" id="L3328" title="All 4 branches covered.">            if (first == null || first.compareTo(sstable.getFirst()) &gt; 0)</span>
<span class="fc" id="L3329">                first = sstable.getFirst();</span>
<span class="fc bfc" id="L3330" title="All 4 branches covered.">            if (last == null || last.compareTo(sstable.getLast()) &lt; 0)</span>
<span class="fc" id="L3331">                last = sstable.getLast();</span>
<span class="fc" id="L3332">        }</span>

<span class="fc" id="L3334">        DiskBoundaries diskBoundaries = getDiskBoundaries();</span>
<span class="fc" id="L3335">        return diskBoundaries.getDisksInBounds(first, last).stream().map(directories::getLocationForDisk).collect(Collectors.toList());</span>
    }

    public DiskBoundaries getDiskBoundaries()
    {
<span class="fc" id="L3340">        return diskBoundaryManager.getDiskBoundaries(this);</span>
    }

    public void invalidateLocalRanges()
    {
<span class="fc" id="L3345">        diskBoundaryManager.invalidate();</span>

<span class="fc" id="L3347">        switchMemtableOrNotify(FlushReason.OWNED_RANGES_CHANGE, Memtable::localRangesUpdated);</span>
<span class="fc" id="L3348">    }</span>

    @Override
    public void setNeverPurgeTombstones(boolean value)
    {
<span class="nc bnc" id="L3353" title="All 2 branches missed.">        if (neverPurgeTombstones != value)</span>
<span class="nc" id="L3354">            logger.info(&quot;Changing neverPurgeTombstones for {}.{} from {} to {}&quot;, getKeyspaceName(), getTableName(), neverPurgeTombstones, value);</span>
        else
<span class="nc" id="L3356">            logger.info(&quot;Not changing neverPurgeTombstones for {}.{}, it is {}&quot;, getKeyspaceName(), getTableName(), neverPurgeTombstones);</span>

<span class="nc" id="L3358">        neverPurgeTombstones = value;</span>
<span class="nc" id="L3359">    }</span>

    @Override
    public boolean getNeverPurgeTombstones()
    {
<span class="fc" id="L3364">        return neverPurgeTombstones;</span>
    }

    void onTableDropped()
    {
<span class="fc" id="L3369">        indexManager.markAllIndexesRemoved();</span>

<span class="pc" id="L3371">        CompactionManager.instance.interruptCompactionForCFs(concatWithIndexes(), (sstable) -&gt; true, true);</span>

<span class="fc bfc" id="L3373" title="All 2 branches covered.">        if (isAutoSnapshotEnabled())</span>
<span class="fc" id="L3374">            snapshot(Keyspace.getTimestampedSnapshotNameWithPrefix(name, ColumnFamilyStore.SNAPSHOT_DROP_PREFIX), DatabaseDescriptor.getAutoSnapshotTtl());</span>

<span class="fc" id="L3376">        CommitLog.instance.forceRecycleAllSegments(Collections.singleton(metadata.id));</span>

<span class="fc" id="L3378">        compactionStrategyManager.shutdown();</span>

        // wait for any outstanding reads/writes that might affect the CFS
<span class="fc" id="L3381">        Keyspace.writeOrder.awaitNewBarrier();</span>
<span class="fc" id="L3382">        readOrdering.awaitNewBarrier();</span>
<span class="fc" id="L3383">    }</span>

    /**
     * The thread pools used to flush memtables.
     *
     * &lt;p&gt;Each disk has its own set of thread pools to perform memtable flushes.&lt;/p&gt;
     * &lt;p&gt;Based on the configuration. Local system keyspaces can have their own disk
     * to allow for special redundancy mechanism. If it is the case the executor services returned for
     * local system keyspaces will be different from the ones for the other keyspaces.&lt;/p&gt;
     */
    private static final class PerDiskFlushExecutors
    {
        /**
         * The flush executors for non local system keyspaces.
         */
        private final ExecutorPlus[] nonLocalSystemflushExecutors;

        /**
         * The flush executors for the local system keyspaces.
         */
        private final ExecutorPlus[] localSystemDiskFlushExecutors;

        /**
         * {@code true} if local system keyspaces are stored in their own directory and use an extra flush executor,
         * {@code false} otherwise.
         */
        private final boolean useSpecificExecutorForSystemKeyspaces;

        public PerDiskFlushExecutors(int flushWriters,
                                     String[] locationsForNonSystemKeyspaces,
                                     boolean useSpecificLocationForSystemKeyspaces)
<span class="fc" id="L3414">        {</span>
<span class="fc" id="L3415">            ExecutorPlus[] flushExecutors = createPerDiskFlushWriters(locationsForNonSystemKeyspaces.length, flushWriters);</span>
<span class="fc" id="L3416">            nonLocalSystemflushExecutors = flushExecutors;</span>
<span class="fc" id="L3417">            useSpecificExecutorForSystemKeyspaces = useSpecificLocationForSystemKeyspaces;</span>
<span class="pc bpc" id="L3418" title="1 of 2 branches missed.">            localSystemDiskFlushExecutors = useSpecificLocationForSystemKeyspaces ? new ExecutorPlus[] {newThreadPool(&quot;LocalSystemKeyspacesDiskMemtableFlushWriter&quot;, flushWriters)}</span>
<span class="fc" id="L3419">                                                                                  : new ExecutorPlus[] {flushExecutors[0]};</span>
<span class="fc" id="L3420">        }</span>

        private static ExecutorPlus[] createPerDiskFlushWriters(int numberOfExecutors, int flushWriters)
        {
<span class="fc" id="L3424">            ExecutorPlus[] flushExecutors = new ExecutorPlus[numberOfExecutors];</span>
<span class="fc bfc" id="L3425" title="All 2 branches covered.">            for (int i = 0; i &lt; numberOfExecutors; i++)</span>
            {
<span class="fc" id="L3427">                flushExecutors[i] = newThreadPool(&quot;PerDiskMemtableFlushWriter_&quot;+i, flushWriters);</span>
            }
<span class="fc" id="L3429">            return flushExecutors;</span>
        }

        private static ExecutorPlus newThreadPool(String poolName, int size)
        {
<span class="fc" id="L3434">            return executorFactory().withJmxInternal().pooled(poolName, size);</span>
        }

        /**
         * Returns the flush executors for the specified keyspace.
         *
         * @param keyspaceName the keyspace name
         * @param tableName the table name
         * @return the flush executors that should be used for flushing the memtables of the specified keyspace.
         */
        public ExecutorPlus[] getExecutorsFor(String keyspaceName, String tableName)
        {
<span class="fc bfc" id="L3446" title="All 2 branches covered.">            return Directories.isStoredInLocalSystemKeyspacesDataLocation(keyspaceName, tableName) ? localSystemDiskFlushExecutors</span>
<span class="fc" id="L3447">                                                                                                   : nonLocalSystemflushExecutors;</span>
        }

        /**
         * Appends all the {@code ExecutorService} used for flushes to the collection.
         *
         * @param collection the collection to append to.
         */
        public void appendAllExecutors(Collection&lt;ExecutorService&gt; collection)
        {
<span class="fc" id="L3457">            Collections.addAll(collection, nonLocalSystemflushExecutors);</span>
<span class="pc bpc" id="L3458" title="1 of 2 branches missed.">            if (useSpecificExecutorForSystemKeyspaces)</span>
<span class="nc" id="L3459">                Collections.addAll(collection, localSystemDiskFlushExecutors);</span>
<span class="fc" id="L3460">        }</span>
    }

    /*
     * Check SSTables whether or not they are misplaced.
     * @return true if any of the SSTables is misplaced.
     *         If all SSTables are correctly placed or the partitioner does not support splitting, it returns false.
     */
    @Override
    public boolean hasMisplacedSSTables()
    {
<span class="fc bfc" id="L3471" title="All 2 branches covered.">        if (!getPartitioner().splitter().isPresent())</span>
<span class="fc" id="L3472">            return false;</span>

<span class="fc" id="L3474">        final DiskBoundaries diskBoundaries = getDiskBoundaries();</span>
<span class="fc bfc" id="L3475" title="All 2 branches covered.">        for (SSTableReader sstable : getSSTables(SSTableSet.CANONICAL))</span>
        {
<span class="fc" id="L3477">            Directories.DataDirectory dataDirectory = getDirectories().getDataDirectoryForFile(sstable.descriptor);</span>
<span class="fc bfc" id="L3478" title="All 2 branches covered.">            if (!diskBoundaries.isInCorrectLocation(sstable, dataDirectory))</span>
<span class="fc" id="L3479">                return true;</span>
<span class="fc" id="L3480">        }</span>
<span class="fc" id="L3481">        return false;</span>
    }

    @Override
    public long getMaxSSTableSize()
    {
<span class="fc" id="L3487">        return metric.maxSSTableSize.getValue();</span>
    }

    @Override
    public long getMaxSSTableDuration()
    {
<span class="fc" id="L3493">        return metric.maxSSTableDuration.getValue();</span>
    }

    @Override
    public Map&lt;String, Long&gt; getTopSizePartitions()
    {
<span class="fc bfc" id="L3499" title="All 2 branches covered.">        if (topPartitions == null)</span>
<span class="fc" id="L3500">            return Collections.emptyMap();</span>
<span class="fc" id="L3501">        return topPartitions.getTopSizePartitionMap();</span>
    }

    @Override
    public Long getTopSizePartitionsLastUpdate()
    {
<span class="pc bpc" id="L3507" title="1 of 2 branches missed.">        if (topPartitions == null)</span>
<span class="fc" id="L3508">            return null;</span>
<span class="nc" id="L3509">        return topPartitions.topSizes().lastUpdate;</span>
    }

    @Override
    public Map&lt;String, Long&gt; getTopTombstonePartitions()
    {
<span class="fc bfc" id="L3515" title="All 2 branches covered.">        if (topPartitions == null)</span>
<span class="fc" id="L3516">            return Collections.emptyMap();</span>
<span class="fc" id="L3517">        return topPartitions.getTopTombstonePartitionMap();</span>
    }

    @Override
    public Long getTopTombstonePartitionsLastUpdate()
    {
<span class="pc bpc" id="L3523" title="1 of 2 branches missed.">        if (topPartitions == null)</span>
<span class="fc" id="L3524">            return null;</span>
<span class="nc" id="L3525">        return topPartitions.topTombstones().lastUpdate;</span>
    }

    @Override
    public OpOrder.Barrier newReadOrderingBarrier()
    {
<span class="fc" id="L3531">        return readOrdering.newBarrier();</span>
    }

    @Override
    public TableMetrics getMetrics()
    {
<span class="fc" id="L3537">        return metric;</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>