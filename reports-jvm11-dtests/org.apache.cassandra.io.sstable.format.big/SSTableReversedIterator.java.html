<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SSTableReversedIterator.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Cassandara Coverage Report</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.io.sstable.format.big</a> &gt; <span class="el_source">SSTableReversedIterator.java</span></div><h1>SSTableReversedIterator.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.cassandra.io.sstable.format.big;

import java.io.IOException;
import java.util.Collections;
import java.util.Iterator;
import java.util.NoSuchElementException;

import org.apache.cassandra.db.BufferClusteringBound;
import org.apache.cassandra.db.ClusteringBound;
import org.apache.cassandra.db.DecoratedKey;
import org.apache.cassandra.db.MutableDeletionInfo;
import org.apache.cassandra.db.RegularAndStaticColumns;
import org.apache.cassandra.db.Slice;
import org.apache.cassandra.db.Slices;
import org.apache.cassandra.db.UnfilteredValidation;
import org.apache.cassandra.db.filter.ColumnFilter;
import org.apache.cassandra.db.partitions.ImmutableBTreePartition;
import org.apache.cassandra.db.rows.EncodingStats;
import org.apache.cassandra.db.rows.RangeTombstoneBoundMarker;
import org.apache.cassandra.db.rows.RangeTombstoneMarker;
import org.apache.cassandra.db.rows.Row;
import org.apache.cassandra.db.rows.Rows;
import org.apache.cassandra.db.rows.Unfiltered;
import org.apache.cassandra.io.sstable.AbstractSSTableIterator;
import org.apache.cassandra.io.sstable.format.SSTableReader;
import org.apache.cassandra.io.sstable.format.Version;
import org.apache.cassandra.io.util.FileDataInput;
import org.apache.cassandra.io.util.FileHandle;
import org.apache.cassandra.schema.TableMetadata;
import org.apache.cassandra.utils.AbstractIterator;
import org.apache.cassandra.utils.btree.BTree;

/**
 *  A Cell Iterator in reversed clustering order over SSTable
 */
public class SSTableReversedIterator extends AbstractSSTableIterator&lt;RowIndexEntry&gt;
{
    /**
     * The index of the slice being processed.
     */
    private int slice;

    public SSTableReversedIterator(SSTableReader sstable,
                                   FileDataInput file,
                                   DecoratedKey key,
                                   RowIndexEntry indexEntry,
                                   Slices slices,
                                   ColumnFilter columns,
                                   FileHandle ifile)
    {
<span class="fc" id="L68">        super(sstable, file, key, indexEntry, slices, columns, ifile);</span>
<span class="fc" id="L69">    }</span>

    @SuppressWarnings(&quot;resource&quot;) // caller to close
    protected Reader createReaderInternal(RowIndexEntry indexEntry, FileDataInput file, boolean shouldCloseFile, Version version)
    {
<span class="pc bpc" id="L74" title="1 of 2 branches missed.">        return indexEntry.isIndexed()</span>
<span class="nc" id="L75">             ? new ReverseIndexedReader(indexEntry, file, shouldCloseFile)</span>
<span class="fc" id="L76">             : new ReverseReader(file, shouldCloseFile);</span>
    }

    public boolean isReverseOrder()
    {
<span class="fc" id="L81">        return true;</span>
    }

    protected int nextSliceIndex()
    {
<span class="fc" id="L86">        int next = slice;</span>
<span class="fc" id="L87">        slice++;</span>
<span class="fc" id="L88">        return slices.size() - (next + 1);</span>
    }

    protected boolean hasMoreSlices()
    {
<span class="pc bpc" id="L93" title="1 of 2 branches missed.">        return slice &lt; slices.size();</span>
    }

<span class="fc" id="L96">    private class ReverseReader extends AbstractReader</span>
    {
        protected ReusablePartitionData buffer;
        protected Iterator&lt;Unfiltered&gt; iterator;

        // Set in loadFromDisk () and used in setIterator to handle range tombstone extending on multiple index block. See
        // loadFromDisk for details. Note that those are always false for non-indexed readers.
        protected boolean skipFirstIteratedItem;
        protected boolean skipLastIteratedItem;

        private ReverseReader(FileDataInput file, boolean shouldCloseFile)
<span class="fc" id="L107">        {</span>
<span class="fc" id="L108">            super(file, shouldCloseFile);</span>
<span class="fc" id="L109">        }</span>

        protected ReusablePartitionData createBuffer(int blocksCount)
        {
<span class="fc" id="L113">            int estimatedRowCount = 16;</span>
<span class="fc" id="L114">            int columnCount = metadata().regularColumns().size();</span>
<span class="pc bpc" id="L115" title="2 of 4 branches missed.">            if (columnCount == 0 || metadata().clusteringColumns().isEmpty())</span>
            {
<span class="nc" id="L117">                estimatedRowCount = 1;</span>
            }
            else
            {
                try
                {
                    // To avoid wasted resizing we guess-estimate the number of rows we're likely to read. For that
                    // we use the stats on the number of rows per partition for that sstable.
                    // FIXME: so far we only keep stats on cells, so to get a rough estimate on the number of rows,
                    // we divide by the number of regular columns the table has. We should fix once we collect the
                    // stats on rows
<span class="fc" id="L128">                    int estimatedRowsPerPartition = (int)(sstable.getEstimatedCellPerPartitionCount().percentile(0.75) / columnCount);</span>
<span class="fc" id="L129">                    estimatedRowCount = Math.max(estimatedRowsPerPartition / blocksCount, 1);</span>
                }
<span class="nc" id="L131">                catch (IllegalStateException e)</span>
                {
                    // The EstimatedHistogram mean() method can throw this (if it overflows). While such overflow
                    // shouldn't happen, it's not worth taking the risk of letting the exception bubble up.
<span class="fc" id="L135">                }</span>
            }
<span class="fc" id="L137">            return new ReusablePartitionData(metadata(), partitionKey(), columns(), estimatedRowCount);</span>
        }

        public void setForSlice(Slice slice) throws IOException
        {
            // If we have read the data, just create the iterator for the slice. Otherwise, read the data.
<span class="pc bpc" id="L143" title="1 of 2 branches missed.">            if (buffer == null)</span>
            {
<span class="fc" id="L145">                buffer = createBuffer(1);</span>
                // Note that we can reuse that buffer between slices (we could alternatively re-read from disk
                // every time, but that feels more wasteful) so we want to include everything from the beginning.
                // We can stop at the slice end however since any following slice will be before that.
<span class="fc" id="L149">                loadFromDisk(null, slice.end(), false, false);</span>
            }
<span class="fc" id="L151">            setIterator(slice);</span>
<span class="fc" id="L152">        }</span>

        protected void setIterator(Slice slice)
        {
<span class="pc bpc" id="L156" title="1 of 2 branches missed.">            assert buffer != null;</span>
<span class="fc" id="L157">            iterator = buffer.built.unfilteredIterator(columns, Slices.with(metadata().comparator, slice), true);</span>

<span class="pc bpc" id="L159" title="1 of 2 branches missed.">            if (!iterator.hasNext())</span>
<span class="nc" id="L160">                return;</span>

<span class="pc bpc" id="L162" title="1 of 2 branches missed.">            if (skipFirstIteratedItem)</span>
<span class="nc" id="L163">                iterator.next();</span>

<span class="pc bpc" id="L165" title="1 of 2 branches missed.">            if (skipLastIteratedItem)</span>
<span class="nc" id="L166">                iterator = new SkipLastIterator(iterator);</span>
<span class="fc" id="L167">        }</span>

        protected boolean hasNextInternal() throws IOException
        {
            // If we've never called setForSlice, we're reading everything
<span class="pc bpc" id="L172" title="1 of 2 branches missed.">            if (iterator == null)</span>
<span class="nc" id="L173">                setForSlice(Slice.ALL);</span>

<span class="fc" id="L175">            return iterator.hasNext();</span>
        }

        protected Unfiltered nextInternal() throws IOException
        {
<span class="pc bpc" id="L180" title="1 of 2 branches missed.">            if (!hasNext())</span>
<span class="nc" id="L181">                throw new NoSuchElementException();</span>
<span class="fc" id="L182">            return iterator.next();</span>
        }

        protected boolean stopReadingDisk() throws IOException
        {
<span class="fc" id="L187">            return false;</span>
        }

        // Reads the unfiltered from disk and load them into the reader buffer. It stops reading when either the partition
        // is fully read, or when stopReadingDisk() returns true.
        protected void loadFromDisk(ClusteringBound&lt;?&gt; start,
                                    ClusteringBound&lt;?&gt; end,
                                    boolean hasPreviousBlock,
                                    boolean hasNextBlock) throws IOException
        {
            // start != null means it's the block covering the beginning of the slice, so it has to be the last block for this slice.
<span class="pc bpc" id="L198" title="3 of 4 branches missed.">            assert start == null || !hasNextBlock;</span>

<span class="fc" id="L200">            buffer.reset();</span>
<span class="fc" id="L201">            skipFirstIteratedItem = false;</span>
<span class="fc" id="L202">            skipLastIteratedItem = false;</span>

            // If the start might be in this block, skip everything that comes before it.
<span class="pc bpc" id="L205" title="1 of 2 branches missed.">            if (start != null)</span>
            {
<span class="nc bnc" id="L207" title="All 6 branches missed.">                while (deserializer.hasNext() &amp;&amp; deserializer.compareNextTo(start) &lt;= 0 &amp;&amp; !stopReadingDisk())</span>
                {
<span class="nc bnc" id="L209" title="All 2 branches missed.">                    if (deserializer.nextIsRow())</span>
<span class="nc" id="L210">                        deserializer.skipNext();</span>
                    else
<span class="nc" id="L212">                        updateOpenMarker((RangeTombstoneMarker)deserializer.readNext());</span>
                }
            }

            // If we have an open marker, it's either one from what we just skipped or it's one that open in the next (or
            // one of the next) index block (if openMarker == openMarkerAtStartOfBlock).
<span class="pc bpc" id="L218" title="1 of 2 branches missed.">            if (openMarker != null)</span>
            {
                // We have to feed a marker to the buffer, because that marker is likely to be close later and ImmtableBTreePartition
                // doesn't take kindly to marker that comes without their counterpart. If that's the last block we're gonna read (for
                // the current slice at least) it's easy because we'll want to return that open marker at the end of the data in this
                // block anyway, so we have nothing more to do than adding it to the buffer.
                // If it's not the last block however, in which case we know we'll have start == null, it means this marker is really
                // open in a next block and so while we do need to add it the buffer for the reason mentioned above, we don't
                // want to &quot;return&quot; it just yet, we'll wait until we reach it in the next blocks. That's why we trigger
                // skipLastIteratedItem in that case (this is first item of the block, but we're iterating in reverse order
                // so it will be last returned by the iterator).
<span class="nc bnc" id="L229" title="All 2 branches missed.">                ClusteringBound&lt;?&gt; markerStart = start == null ? BufferClusteringBound.BOTTOM : start;</span>
<span class="nc" id="L230">                buffer.add(new RangeTombstoneBoundMarker(markerStart, openMarker));</span>
<span class="nc bnc" id="L231" title="All 2 branches missed.">                if (hasNextBlock)</span>
<span class="nc" id="L232">                    skipLastIteratedItem = true;</span>
            }

            // Now deserialize everything until we reach our requested end (if we have one)
            // See SSTableIterator.ForwardRead.computeNext() for why this is a strict inequality below: this is the same
            // reasoning here.
<span class="pc bpc" id="L238" title="1 of 4 branches missed.">            while (deserializer.hasNext()</span>
<span class="fc bfc" id="L239" title="All 2 branches covered.">                   &amp;&amp; (end == null || deserializer.compareNextTo(end) &lt; 0)</span>
<span class="pc bpc" id="L240" title="1 of 2 branches missed.">                   &amp;&amp; !stopReadingDisk())</span>
            {
<span class="fc" id="L242">                Unfiltered unfiltered = deserializer.readNext();</span>
<span class="fc" id="L243">                UnfilteredValidation.maybeValidateUnfiltered(unfiltered, metadata(), key, sstable);</span>
                // We may get empty row for the same reason expressed on UnfilteredSerializer.deserializeOne.
<span class="pc bpc" id="L245" title="1 of 2 branches missed.">                if (!unfiltered.isEmpty())</span>
<span class="fc" id="L246">                    buffer.add(unfiltered);</span>

<span class="fc bfc" id="L248" title="All 2 branches covered.">                if (unfiltered.isRangeTombstoneMarker())</span>
<span class="fc" id="L249">                    updateOpenMarker((RangeTombstoneMarker)unfiltered);</span>
<span class="fc" id="L250">            }</span>

            // If we have an open marker, we should close it before finishing
<span class="fc bfc" id="L253" title="All 2 branches covered.">            if (openMarker != null)</span>
            {
                // This is the reverse problem than the one at the start of the block. Namely, if it's the first block
                // we deserialize for the slice (the one covering the slice end basically), then it's easy, we just want
                // to add the close marker to the buffer and return it normally.
                // If it's note our first block (for the slice) however, it means that marker closed in a previously read
                // block and we have already returned it. So while we should still add it to the buffer for the sake of
                // not breaking ImmutableBTreePartition, we should skip it when returning from the iterator, hence the
                // skipFirstIteratedItem (this is the last item of the block, but we're iterating in reverse order so it will
                // be the first returned by the iterator).
<span class="pc bpc" id="L263" title="1 of 2 branches missed.">                ClusteringBound&lt;?&gt; markerEnd = end == null ? BufferClusteringBound.TOP : end;</span>
<span class="fc" id="L264">                buffer.add(new RangeTombstoneBoundMarker(markerEnd, openMarker));</span>
<span class="pc bpc" id="L265" title="1 of 2 branches missed.">                if (hasPreviousBlock)</span>
<span class="nc" id="L266">                    skipFirstIteratedItem = true;</span>
            }

<span class="fc" id="L269">            buffer.build();</span>
<span class="fc" id="L270">        }</span>
    }

    private class ReverseIndexedReader extends ReverseReader
    {
        private final IndexState indexState;

        // The slice we're currently iterating over
        private Slice slice;
        // The last index block to consider for the slice
        private int lastBlockIdx;

        private ReverseIndexedReader(RowIndexEntry indexEntry, FileDataInput file, boolean shouldCloseFile)
        {
            super(file, shouldCloseFile);
            this.indexState = new IndexState(this, metadata.comparator, indexEntry, true, ifile);
        }

        @Override
        public void close() throws IOException
        {
            super.close();
            this.indexState.close();
        }

        @Override
        public void setForSlice(Slice slice) throws IOException
        {
            this.slice = slice;

            // if our previous slicing already got us past the beginning of the sstable, we're done
            if (indexState.isDone())
            {
                iterator = Collections.emptyIterator();
                return;
            }

            // Find the first index block we'll need to read for the slice.
            int startIdx = indexState.findBlockIndex(slice.end(), indexState.currentBlockIdx());
            if (startIdx &lt; 0)
            {
                iterator = Collections.emptyIterator();
                indexState.setToBlock(startIdx);
                return;
            }

            lastBlockIdx = indexState.findBlockIndex(slice.start(), startIdx);

            // If the last block to look (in reverse order) is after the very last block, we have nothing for that slice
            if (lastBlockIdx &gt;= indexState.blocksCount())
            {
                assert startIdx &gt;= indexState.blocksCount();
                iterator = Collections.emptyIterator();
                return;
            }

            // If we start (in reverse order) after the very last block, just read from the last one.
            if (startIdx &gt;= indexState.blocksCount())
                startIdx = indexState.blocksCount() - 1;

            // Note that even if we were already set on the proper block (which would happen if the previous slice
            // requested ended on the same block this one start), we can't reuse it because when reading the previous
            // slice we've only read that block from the previous slice start. Re-reading also handles
            // skipFirstIteratedItem/skipLastIteratedItem that we would need to handle otherwise.
            indexState.setToBlock(startIdx);

            readCurrentBlock(false, startIdx != lastBlockIdx);
        }

        @Override
        protected boolean hasNextInternal() throws IOException
        {
            if (super.hasNextInternal())
                return true;

            while (true)
            {
                // We have nothing more for our current block, move the next one (so the one before on disk).
                int nextBlockIdx = indexState.currentBlockIdx() - 1;
                if (nextBlockIdx &lt; 0 || nextBlockIdx &lt; lastBlockIdx)
                    return false;

                // The slice start can be in
                indexState.setToBlock(nextBlockIdx);
                readCurrentBlock(true, nextBlockIdx != lastBlockIdx);

                // If an indexed block only contains data for a dropped column, the iterator will be empty, even
                // though we may still have data to read in subsequent blocks

                // also, for pre-3.0 storage formats, index blocks that only contain a single row and that row crosses
                // index boundaries, the iterator will be empty even though we haven't read everything we're intending
                // to read. In that case, we want to read the next index block. This shouldn't be possible in 3.0+
                // formats (see next comment)
                if (!iterator.hasNext() &amp;&amp; nextBlockIdx &gt; lastBlockIdx)
                {
                    continue;
                }

                return iterator.hasNext();
            }
        }

        /**
         * Reads the current block, the last one we've set.
         *
         * @param hasPreviousBlock is whether we have already read a previous block for the current slice.
         * @param hasNextBlock is whether we have more blocks to read for the current slice.
         */
        private void readCurrentBlock(boolean hasPreviousBlock, boolean hasNextBlock) throws IOException
        {
            if (buffer == null)
                buffer = createBuffer(indexState.blocksCount());

            // The slice start (resp. slice end) is only meaningful on the last (resp. first) block read (since again,
            // we read blocks in reverse order).
            boolean canIncludeSliceStart = !hasNextBlock;
            boolean canIncludeSliceEnd = !hasPreviousBlock;

            loadFromDisk(canIncludeSliceStart ? slice.start() : null,
                         canIncludeSliceEnd ? slice.end() : null,
                         hasPreviousBlock,
                         hasNextBlock);
            setIterator(slice);
        }

        @Override
        protected boolean stopReadingDisk() throws IOException
        {
            return indexState.isPastCurrentBlock();
        }
    }

    private class ReusablePartitionData
    {
        private final TableMetadata metadata;
        private final DecoratedKey partitionKey;
        private final RegularAndStaticColumns columns;

        private MutableDeletionInfo.Builder deletionBuilder;
        private MutableDeletionInfo deletionInfo;
        private BTree.Builder&lt;Row&gt; rowBuilder;
        private ImmutableBTreePartition built;

        private ReusablePartitionData(TableMetadata metadata,
                                      DecoratedKey partitionKey,
                                      RegularAndStaticColumns columns,
                                      int initialRowCapacity)
<span class="fc" id="L417">        {</span>
<span class="fc" id="L418">            this.metadata = metadata;</span>
<span class="fc" id="L419">            this.partitionKey = partitionKey;</span>
<span class="fc" id="L420">            this.columns = columns;</span>
<span class="fc" id="L421">            this.rowBuilder = BTree.builder(metadata.comparator, initialRowCapacity);</span>
<span class="fc" id="L422">        }</span>


        public void add(Unfiltered unfiltered)
        {
<span class="fc bfc" id="L427" title="All 2 branches covered.">            if (unfiltered.isRow())</span>
<span class="fc" id="L428">                rowBuilder.add((Row)unfiltered);</span>
            else
<span class="fc" id="L430">                deletionBuilder.add((RangeTombstoneMarker)unfiltered);</span>
<span class="fc" id="L431">        }</span>

        public void reset()
        {
<span class="fc" id="L435">            built = null;</span>
<span class="fc" id="L436">            rowBuilder.reuse();</span>
<span class="fc" id="L437">            deletionBuilder = MutableDeletionInfo.builder(partitionLevelDeletion, metadata().comparator, false);</span>
<span class="fc" id="L438">        }</span>

        public void build()
        {
<span class="fc" id="L442">            deletionInfo = deletionBuilder.build();</span>
<span class="fc" id="L443">            built = new ImmutableBTreePartition(metadata, partitionKey, columns, Rows.EMPTY_STATIC_ROW, rowBuilder.build(),</span>
                                                deletionInfo, EncodingStats.NO_STATS);
<span class="fc" id="L445">            deletionBuilder = null;</span>
<span class="fc" id="L446">        }</span>
    }

    private static class SkipLastIterator extends AbstractIterator&lt;Unfiltered&gt;
    {
        private final Iterator&lt;Unfiltered&gt; iterator;

        private SkipLastIterator(Iterator&lt;Unfiltered&gt; iterator)
        {
            this.iterator = iterator;
        }

        protected Unfiltered computeNext()
        {
            if (!iterator.hasNext())
                return endOfData();

            Unfiltered next = iterator.next();
            return iterator.hasNext() ? next : endOfData();
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>