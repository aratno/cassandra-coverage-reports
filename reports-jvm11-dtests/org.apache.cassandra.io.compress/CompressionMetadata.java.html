<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>CompressionMetadata.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Cassandara Coverage Report</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.io.compress</a> &gt; <span class="el_source">CompressionMetadata.java</span></div><h1>CompressionMetadata.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.cassandra.io.compress;

import java.io.DataOutput;
import java.io.EOFException;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.nio.file.NoSuchFileException;
import java.util.Collection;
import java.util.HashMap;
import java.util.Map;
import java.util.SortedSet;
import java.util.TreeSet;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.primitives.Longs;

import org.apache.cassandra.db.TypeSizes;
import org.apache.cassandra.exceptions.ConfigurationException;
import org.apache.cassandra.io.FSReadError;
import org.apache.cassandra.io.FSWriteError;
import org.apache.cassandra.io.IVersionedSerializer;
import org.apache.cassandra.io.sstable.CorruptSSTableException;
import org.apache.cassandra.io.sstable.format.SSTableReader;
import org.apache.cassandra.io.util.DataInputPlus;
import org.apache.cassandra.io.util.DataOutputPlus;
import org.apache.cassandra.io.util.File;
import org.apache.cassandra.io.util.FileInputStreamPlus;
import org.apache.cassandra.io.util.FileOutputStreamPlus;
import org.apache.cassandra.io.util.Memory;
import org.apache.cassandra.io.util.SafeMemory;
import org.apache.cassandra.schema.CompressionParams;
import org.apache.cassandra.utils.concurrent.Ref;
import org.apache.cassandra.utils.concurrent.Transactional;
import org.apache.cassandra.utils.concurrent.WrappedSharedCloseable;

/**
 * Holds metadata about compressed file
 * TODO extract interface ICompressionMetadata which will just provide non-resource properties
 */
public class CompressionMetadata extends WrappedSharedCloseable
{
    // dataLength can represent either the true length of the file
    // or some shorter value, in the case we want to impose a shorter limit on readers
    // (when early opening, we want to ensure readers cannot read past fully written sections)
    public final long dataLength;
    public final long compressedFileLength;
    private final Memory chunkOffsets;
    private final long chunkOffsetsSize;
    public final File chunksIndexFile;
    public final CompressionParams parameters;

    @VisibleForTesting
    @SuppressWarnings(&quot;resource&quot;)
    public static CompressionMetadata open(File chunksIndexFile, long compressedLength, boolean hasMaxCompressedSize)
    {
        CompressionParams parameters;
        long dataLength;
        Memory chunkOffsets;

<span class="fc" id="L77">        try (FileInputStreamPlus stream = chunksIndexFile.newInputStream())</span>
        {
<span class="fc" id="L79">            String compressorName = stream.readUTF();</span>
<span class="fc" id="L80">            int optionCount = stream.readInt();</span>
<span class="fc" id="L81">            Map&lt;String, String&gt; options = new HashMap&lt;&gt;(optionCount);</span>
<span class="pc bpc" id="L82" title="1 of 2 branches missed.">            for (int i = 0; i &lt; optionCount; ++i)</span>
            {
<span class="nc" id="L84">                String key = stream.readUTF();</span>
<span class="nc" id="L85">                String value = stream.readUTF();</span>
<span class="nc" id="L86">                options.put(key, value);</span>
            }
<span class="fc" id="L88">            int chunkLength = stream.readInt();</span>
<span class="fc" id="L89">            int maxCompressedSize = Integer.MAX_VALUE;</span>
<span class="pc bpc" id="L90" title="1 of 2 branches missed.">            if (hasMaxCompressedSize)</span>
<span class="fc" id="L91">                maxCompressedSize = stream.readInt();</span>
            try
            {
<span class="fc" id="L94">                parameters = new CompressionParams(compressorName, chunkLength, maxCompressedSize, options);</span>
            }
<span class="nc" id="L96">            catch (ConfigurationException e)</span>
            {
<span class="nc" id="L98">                throw new RuntimeException(&quot;Cannot create CompressionParams for stored parameters&quot;, e);</span>
<span class="fc" id="L99">            }</span>

<span class="fc" id="L101">            dataLength = stream.readLong();</span>
<span class="fc" id="L102">            chunkOffsets = readChunkOffsets(stream);</span>
        }
<span class="nc" id="L104">        catch (FileNotFoundException | NoSuchFileException e)</span>
        {
<span class="nc" id="L106">            throw new RuntimeException(e);</span>
        }
<span class="nc" id="L108">        catch (IOException e)</span>
        {
<span class="nc" id="L110">            throw new CorruptSSTableException(e, chunksIndexFile);</span>
<span class="fc" id="L111">        }</span>

<span class="fc" id="L113">        return new CompressionMetadata(chunksIndexFile, parameters, chunkOffsets, chunkOffsets.size(), dataLength, compressedLength);</span>
    }

    // do not call this constructor directly, unless used in testing
    @VisibleForTesting
    public CompressionMetadata(File chunksIndexFile,
                               CompressionParams parameters,
                               Memory chunkOffsets,
                               long chunkOffsetsSize,
                               long dataLength,
                               long compressedFileLength)
    {
<span class="fc" id="L125">        super(chunkOffsets);</span>
<span class="fc" id="L126">        this.chunksIndexFile = chunksIndexFile;</span>
<span class="fc" id="L127">        this.parameters = parameters;</span>
<span class="fc" id="L128">        this.dataLength = dataLength;</span>
<span class="fc" id="L129">        this.compressedFileLength = compressedFileLength;</span>
<span class="fc" id="L130">        this.chunkOffsets = chunkOffsets;</span>
<span class="fc" id="L131">        this.chunkOffsetsSize = chunkOffsetsSize;</span>
<span class="fc" id="L132">    }</span>

    private CompressionMetadata(CompressionMetadata copy)
    {
<span class="fc" id="L136">        super(copy);</span>
<span class="fc" id="L137">        this.chunksIndexFile = copy.chunksIndexFile;</span>
<span class="fc" id="L138">        this.parameters = copy.parameters;</span>
<span class="fc" id="L139">        this.dataLength = copy.dataLength;</span>
<span class="fc" id="L140">        this.compressedFileLength = copy.compressedFileLength;</span>
<span class="fc" id="L141">        this.chunkOffsets = copy.chunkOffsets;</span>
<span class="fc" id="L142">        this.chunkOffsetsSize = copy.chunkOffsetsSize;</span>
<span class="fc" id="L143">    }</span>

    public ICompressor compressor()
    {
<span class="fc" id="L147">        return parameters.getSstableCompressor();</span>
    }

    public int chunkLength()
    {
<span class="fc" id="L152">        return parameters.chunkLength();</span>
    }

    public int maxCompressedLength()
    {
<span class="fc" id="L157">        return parameters.maxCompressedLength();</span>
    }

    /**
     * Returns the amount of memory in bytes used off heap.
     * @return the amount of memory in bytes used off heap
     */
    public long offHeapSize()
    {
<span class="fc" id="L166">        return chunkOffsets.size();</span>
    }

    @Override
    public void addTo(Ref.IdentityCollection identities)
    {
<span class="nc" id="L172">        super.addTo(identities);</span>
<span class="nc" id="L173">        identities.add(chunkOffsets);</span>
<span class="nc" id="L174">    }</span>

    @Override
    public CompressionMetadata sharedCopy()
    {
<span class="fc" id="L179">        return new CompressionMetadata(this);</span>
    }

    /**
     * Read offsets of the individual chunks from the given input.
     *
     * @param input Source of the data.
     *
     * @return collection of the chunk offsets.
     */
    private static Memory readChunkOffsets(FileInputStreamPlus input)
    {
        final int chunkCount;
        try
        {
<span class="fc" id="L194">            chunkCount = input.readInt();</span>
<span class="pc bpc" id="L195" title="1 of 2 branches missed.">            if (chunkCount &lt;= 0)</span>
<span class="nc" id="L196">                throw new IOException(&quot;Compressed file with 0 chunks encountered: &quot; + input);</span>
        }
<span class="nc" id="L198">        catch (IOException e)</span>
        {
<span class="nc" id="L200">            throw new FSReadError(e, input.file);</span>
<span class="fc" id="L201">        }</span>

        @SuppressWarnings(&quot;resource&quot;)
<span class="fc" id="L204">        Memory offsets = Memory.allocate(chunkCount * 8L);</span>
<span class="fc" id="L205">        int i = 0;</span>
        try
        {

<span class="fc bfc" id="L209" title="All 2 branches covered.">            for (i = 0; i &lt; chunkCount; i++)</span>
            {
<span class="fc" id="L211">                offsets.setLong(i * 8L, input.readLong());</span>
            }

<span class="fc" id="L214">            return offsets;</span>
        }
<span class="nc" id="L216">        catch (IOException e)</span>
        {
<span class="nc bnc" id="L218" title="All 2 branches missed.">            if (offsets != null)</span>
<span class="nc" id="L219">                offsets.close();</span>

<span class="nc bnc" id="L221" title="All 2 branches missed.">            if (e instanceof EOFException)</span>
            {
<span class="nc" id="L223">                String msg = String.format(&quot;Corrupted Index File %s: read %d but expected %d chunks.&quot;,</span>
<span class="nc" id="L224">                                           input.file.path(), i, chunkCount);</span>
<span class="nc" id="L225">                throw new CorruptSSTableException(new IOException(msg, e), input.file);</span>
            }
<span class="nc" id="L227">            throw new FSReadError(e, input.file);</span>
        }
    }

    /**
     * Get a chunk of compressed data (offset, length) corresponding to given position
     *
     * @param position Position in the file.
     * @return pair of chunk offset and length.
     */
    public Chunk chunkFor(long position)
    {
        // position of the chunk
<span class="fc" id="L240">        long idx = 8 * (position / parameters.chunkLength());</span>

<span class="pc bpc" id="L242" title="1 of 2 branches missed.">        if (idx &gt;= chunkOffsetsSize)</span>
<span class="nc" id="L243">            throw new CorruptSSTableException(new EOFException(), chunksIndexFile);</span>

<span class="pc bpc" id="L245" title="1 of 2 branches missed.">        if (idx &lt; 0)</span>
<span class="nc" id="L246">            throw new CorruptSSTableException(new IllegalArgumentException(String.format(&quot;Invalid negative chunk index %d with position %d&quot;, idx, position)),</span>
                                              chunksIndexFile);

<span class="fc" id="L249">        long chunkOffset = chunkOffsets.getLong(idx);</span>
<span class="fc bfc" id="L250" title="All 2 branches covered.">        long nextChunkOffset = (idx + 8 == chunkOffsetsSize)</span>
<span class="fc" id="L251">                                ? compressedFileLength</span>
<span class="fc" id="L252">                                : chunkOffsets.getLong(idx + 8);</span>

<span class="fc" id="L254">        return new Chunk(chunkOffset, (int) (nextChunkOffset - chunkOffset - 4)); // &quot;4&quot; bytes reserved for checksum</span>
    }

    public long getDataOffsetForChunkOffset(long chunkOffset)
    {
<span class="fc" id="L259">        long l = 0;</span>
<span class="fc" id="L260">        long h = (chunkOffsetsSize &gt;&gt; 3) - 1;</span>
        long idx, offset;

<span class="pc bpc" id="L263" title="1 of 2 branches missed.">        while (l &lt;= h)</span>
        {
<span class="fc" id="L265">            idx = (l + h) &gt;&gt;&gt; 1;</span>
<span class="fc" id="L266">            offset = chunkOffsets.getLong(idx &lt;&lt; 3);</span>

<span class="pc bpc" id="L268" title="1 of 2 branches missed.">            if (offset &lt; chunkOffset)</span>
<span class="nc" id="L269">                l = idx + 1;</span>
<span class="fc bfc" id="L270" title="All 2 branches covered.">            else if (offset &gt; chunkOffset)</span>
<span class="fc" id="L271">                h = idx - 1;</span>
            else
<span class="fc" id="L273">                return idx * parameters.chunkLength();</span>
        }

<span class="nc" id="L276">        throw new IllegalArgumentException(&quot;No chunk with offset &quot; + chunkOffset);</span>
    }

    /**
     * @param sections Collection of sections in uncompressed file. Should not contain sections that overlap each other.
     * @return Total chunk size in bytes for given sections including checksum.
     */
    public long getTotalSizeForSections(Collection&lt;SSTableReader.PartitionPositionBounds&gt; sections)
    {
<span class="fc" id="L285">        long size = 0;</span>
<span class="fc" id="L286">        long lastOffset = -1;</span>
<span class="fc bfc" id="L287" title="All 2 branches covered.">        for (SSTableReader.PartitionPositionBounds section : sections)</span>
        {
<span class="fc" id="L289">            int startIndex = (int) (section.lowerPosition / parameters.chunkLength());</span>

<span class="fc" id="L291">            int endIndex = (int) (section.upperPosition / parameters.chunkLength());</span>
<span class="fc bfc" id="L292" title="All 2 branches covered.">            if (section.upperPosition % parameters.chunkLength() == 0)</span>
<span class="fc" id="L293">                endIndex--;</span>

<span class="fc bfc" id="L295" title="All 2 branches covered.">            for (int i = startIndex; i &lt;= endIndex; i++)</span>
            {
<span class="fc" id="L297">                long offset = i * 8L;</span>
<span class="fc" id="L298">                long chunkOffset = chunkOffsets.getLong(offset);</span>
<span class="fc bfc" id="L299" title="All 2 branches covered.">                if (chunkOffset &gt; lastOffset)</span>
                {
<span class="fc" id="L301">                    lastOffset = chunkOffset;</span>
<span class="fc bfc" id="L302" title="All 2 branches covered.">                    long nextChunkOffset = offset + 8 == chunkOffsetsSize</span>
<span class="fc" id="L303">                                                   ? compressedFileLength</span>
<span class="fc" id="L304">                                                   : chunkOffsets.getLong(offset + 8);</span>
<span class="fc" id="L305">                    size += (nextChunkOffset - chunkOffset);</span>
                }
            }
<span class="fc" id="L308">        }</span>
<span class="fc" id="L309">        return size;</span>
    }

    /**
     * @param sections Collection of sections in uncompressed file
     * @return Array of chunks which corresponds to given sections of uncompressed file, sorted by chunk offset
     */
    public Chunk[] getChunksForSections(Collection&lt;SSTableReader.PartitionPositionBounds&gt; sections)
    {
        // use SortedSet to eliminate duplicates and sort by chunk offset
<span class="fc" id="L319">        SortedSet&lt;Chunk&gt; offsets = new TreeSet&lt;&gt;((o1, o2) -&gt; Longs.compare(o1.offset, o2.offset));</span>

<span class="fc bfc" id="L321" title="All 2 branches covered.">        for (SSTableReader.PartitionPositionBounds section : sections)</span>
        {
<span class="fc" id="L323">            int startIndex = (int) (section.lowerPosition / parameters.chunkLength());</span>

<span class="fc" id="L325">            int endIndex = (int) (section.upperPosition / parameters.chunkLength());</span>
<span class="fc bfc" id="L326" title="All 2 branches covered.">            if (section.upperPosition % parameters.chunkLength() == 0)</span>
<span class="fc" id="L327">                endIndex--;</span>

<span class="fc bfc" id="L329" title="All 2 branches covered.">            for (int i = startIndex; i &lt;= endIndex; i++)</span>
            {
<span class="fc" id="L331">                long offset = i * 8L;</span>
<span class="fc" id="L332">                long chunkOffset = chunkOffsets.getLong(offset);</span>
<span class="fc bfc" id="L333" title="All 2 branches covered.">                long nextChunkOffset = offset + 8 == chunkOffsetsSize</span>
<span class="fc" id="L334">                                     ? compressedFileLength</span>
<span class="fc" id="L335">                                     : chunkOffsets.getLong(offset + 8);</span>
<span class="fc" id="L336">                offsets.add(new Chunk(chunkOffset, (int) (nextChunkOffset - chunkOffset - 4))); // &quot;4&quot; bytes reserved for checksum</span>
            }
<span class="fc" id="L338">        }</span>

<span class="fc" id="L340">        return offsets.toArray(new Chunk[offsets.size()]);</span>
    }

<span class="fc" id="L343">    public static class Writer extends Transactional.AbstractTransactional implements Transactional</span>
    {
        // path to the file
        private final CompressionParams parameters;
        private final File file;
<span class="fc" id="L348">        private int maxCount = 100;</span>
<span class="fc" id="L349">        private SafeMemory offsets = new SafeMemory(maxCount * 8L);</span>
<span class="fc" id="L350">        private int count = 0;</span>

        // provided by user when setDescriptor
        private long dataLength, chunkCount;

        private Writer(CompressionParams parameters, File file)
<span class="fc" id="L356">        {</span>
<span class="fc" id="L357">            this.parameters = parameters;</span>
<span class="fc" id="L358">            this.file = file;</span>
<span class="fc" id="L359">        }</span>

        public static Writer open(CompressionParams parameters, File file)
        {
<span class="fc" id="L363">            return new Writer(parameters, file);</span>
        }

        public void addOffset(long offset)
        {
<span class="fc bfc" id="L368" title="All 2 branches covered.">            if (count == maxCount)</span>
            {
<span class="fc" id="L370">                SafeMemory newOffsets = offsets.copy((maxCount *= 2L) * 8L);</span>
<span class="fc" id="L371">                offsets.close();</span>
<span class="fc" id="L372">                offsets = newOffsets;</span>
            }
<span class="fc" id="L374">            offsets.setLong(8L * count++, offset);</span>
<span class="fc" id="L375">        }</span>

        private void writeHeader(DataOutput out, long dataLength, int chunks)
        {
            try
            {
<span class="fc" id="L381">                out.writeUTF(parameters.getSstableCompressor().getClass().getSimpleName());</span>
<span class="fc" id="L382">                out.writeInt(parameters.getOtherOptions().size());</span>
<span class="pc bpc" id="L383" title="1 of 2 branches missed.">                for (Map.Entry&lt;String, String&gt; entry : parameters.getOtherOptions().entrySet())</span>
                {
<span class="nc" id="L385">                    out.writeUTF(entry.getKey());</span>
<span class="nc" id="L386">                    out.writeUTF(entry.getValue());</span>
<span class="nc" id="L387">                }</span>

                // store the length of the chunk
<span class="fc" id="L390">                out.writeInt(parameters.chunkLength());</span>
<span class="fc" id="L391">                out.writeInt(parameters.maxCompressedLength());</span>
                // store position and reserve a place for uncompressed data length and chunks count
<span class="fc" id="L393">                out.writeLong(dataLength);</span>
<span class="fc" id="L394">                out.writeInt(chunks);</span>
            }
<span class="nc" id="L396">            catch (IOException e)</span>
            {
<span class="nc" id="L398">                throw new FSWriteError(e, file);</span>
<span class="fc" id="L399">            }</span>
<span class="fc" id="L400">        }</span>

        // we've written everything; wire up some final metadata state
        public Writer finalizeLength(long dataLength, int chunkCount)
        {
<span class="fc" id="L405">            this.dataLength = dataLength;</span>
<span class="fc" id="L406">            this.chunkCount = chunkCount;</span>
<span class="fc" id="L407">            return this;</span>
        }

        @Override
        public void doPrepare()
        {
<span class="pc bpc" id="L413" title="1 of 2 branches missed.">            assert chunkCount == count;</span>

            // finalize the size of memory used if it won't now change;
            // unnecessary if already correct size
<span class="pc bpc" id="L417" title="1 of 2 branches missed.">            if (offsets.size() != count * 8L)</span>
            {
<span class="fc" id="L419">                SafeMemory tmp = offsets;</span>
<span class="fc" id="L420">                offsets = offsets.copy(count * 8L);</span>
<span class="fc" id="L421">                tmp.free();</span>
            }

            // flush the data to disk
<span class="fc" id="L425">            try (FileOutputStreamPlus out = file.newOutputStream(File.WriteMode.OVERWRITE))</span>
            {
<span class="fc" id="L427">                writeHeader(out, dataLength, count);</span>
<span class="fc bfc" id="L428" title="All 2 branches covered.">                for (int i = 0; i &lt; count; i++)</span>
<span class="fc" id="L429">                    out.writeLong(offsets.getLong(i * 8L));</span>

<span class="fc" id="L431">                out.flush();</span>
<span class="fc" id="L432">                out.sync();</span>
            }
<span class="nc" id="L434">            catch (FileNotFoundException | NoSuchFileException fnfe)</span>
            {
<span class="nc" id="L436">                throw new RuntimeException(fnfe);</span>
            }
<span class="nc" id="L438">            catch (IOException e)</span>
            {
<span class="nc" id="L440">                throw new FSWriteError(e, file);</span>
<span class="fc" id="L441">            }</span>
<span class="fc" id="L442">        }</span>

        @SuppressWarnings(&quot;resource&quot;)
        public CompressionMetadata open(long dataLength, long compressedLength)
        {
<span class="fc" id="L447">            SafeMemory tOffsets = this.offsets.sharedCopy();</span>

            // calculate how many entries we need, if our dataLength is truncated
<span class="fc" id="L450">            int tCount = (int) (dataLength / parameters.chunkLength());</span>
<span class="pc bpc" id="L451" title="1 of 2 branches missed.">            if (dataLength % parameters.chunkLength() != 0)</span>
<span class="fc" id="L452">                tCount++;</span>

<span class="pc bpc" id="L454" title="1 of 2 branches missed.">            assert tCount &gt; 0;</span>
            // grab our actual compressed length from the next offset from our the position we're opened to
<span class="fc bfc" id="L456" title="All 2 branches covered.">            if (tCount &lt; this.count)</span>
<span class="fc" id="L457">                compressedLength = tOffsets.getLong(tCount * 8L);</span>

<span class="fc" id="L459">            return new CompressionMetadata(file, parameters, tOffsets, tCount * 8L, dataLength, compressedLength);</span>
        }

        /**
         * Get a chunk offset by it's index.
         *
         * @param chunkIndex Index of the chunk.
         *
         * @return offset of the chunk in the compressed file.
         */
        public long chunkOffsetBy(int chunkIndex)
        {
<span class="nc" id="L471">            return offsets.getLong(chunkIndex * 8L);</span>
        }

        /**
         * Reset the writer so that the next chunk offset written will be the
         * one of {@code chunkIndex}.
         *
         * @param chunkIndex the next index to write
         */
        public void resetAndTruncate(int chunkIndex)
        {
<span class="nc" id="L482">            count = chunkIndex;</span>
<span class="nc" id="L483">        }</span>

        @Override
        protected Throwable doPostCleanup(Throwable failed)
        {
<span class="fc" id="L488">            return offsets.close(failed);</span>
        }

        @Override
        protected Throwable doCommit(Throwable accumulate)
        {
<span class="fc" id="L494">            return accumulate;</span>
        }

        @Override
        protected Throwable doAbort(Throwable accumulate)
        {
<span class="fc" id="L500">            return accumulate;</span>
        }
    }

    /**
     * Holds offset and length of the file chunk
     */
    public static class Chunk
    {
<span class="fc" id="L509">        public static final IVersionedSerializer&lt;Chunk&gt; serializer = new ChunkSerializer();</span>

        public final long offset;
        public final int length;

        public Chunk(long offset, int length)
<span class="fc" id="L515">        {</span>
<span class="pc bpc" id="L516" title="1 of 2 branches missed.">            assert(length &gt; 0);</span>

<span class="fc" id="L518">            this.offset = offset;</span>
<span class="fc" id="L519">            this.length = length;</span>
<span class="fc" id="L520">        }</span>

        @Override
        public boolean equals(Object o)
        {
<span class="nc bnc" id="L525" title="All 2 branches missed.">            if (this == o) return true;</span>
<span class="nc bnc" id="L526" title="All 4 branches missed.">            if (o == null || getClass() != o.getClass()) return false;</span>

<span class="nc" id="L528">            Chunk chunk = (Chunk) o;</span>
<span class="nc bnc" id="L529" title="All 4 branches missed.">            return length == chunk.length &amp;&amp; offset == chunk.offset;</span>
        }

        @Override
        public int hashCode()
        {
<span class="nc" id="L535">            int result = (int) (offset ^ (offset &gt;&gt;&gt; 32));</span>
<span class="nc" id="L536">            result = 31 * result + length;</span>
<span class="nc" id="L537">            return result;</span>
        }

        @Override
        public String toString()
        {
<span class="nc" id="L543">            return String.format(&quot;Chunk&lt;offset: %d, length: %d&gt;&quot;, offset, length);</span>
        }
    }

<span class="fc" id="L547">    static class ChunkSerializer implements IVersionedSerializer&lt;Chunk&gt;</span>
    {
        @Override
        public void serialize(Chunk chunk, DataOutputPlus out, int version) throws IOException
        {
<span class="fc" id="L552">            out.writeLong(chunk.offset);</span>
<span class="fc" id="L553">            out.writeInt(chunk.length);</span>
<span class="fc" id="L554">        }</span>

        @Override
        public Chunk deserialize(DataInputPlus in, int version) throws IOException
        {
<span class="fc" id="L559">            return new Chunk(in.readLong(), in.readInt());</span>
        }

        @Override
        public long serializedSize(Chunk chunk, int version)
        {
<span class="nc" id="L565">            long size = TypeSizes.sizeof(chunk.offset);</span>
<span class="nc" id="L566">            size += TypeSizes.sizeof(chunk.length);</span>
<span class="nc" id="L567">            return size;</span>
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>