<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SizeTieredCompactionStrategy.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Cassandara Coverage Report</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.db.compaction</a> &gt; <span class="el_source">SizeTieredCompactionStrategy.java</span></div><h1>SizeTieredCompactionStrategy.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.cassandra.db.compaction;

import java.util.*;
import java.util.Map.Entry;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.ImmutableSet;
import com.google.common.collect.Iterables;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.cassandra.db.ColumnFamilyStore;
import org.apache.cassandra.db.Directories;
import org.apache.cassandra.db.compaction.writers.CompactionAwareWriter;
import org.apache.cassandra.db.compaction.writers.SplittingSizeTieredCompactionWriter;
import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
import org.apache.cassandra.exceptions.ConfigurationException;
import org.apache.cassandra.io.sstable.format.SSTableReader;
import org.apache.cassandra.schema.CompactionParams;
import org.apache.cassandra.utils.Pair;

import static com.google.common.collect.Iterables.filter;

public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy
{
<span class="fc" id="L43">    private static final Logger logger = LoggerFactory.getLogger(SizeTieredCompactionStrategy.class);</span>

<span class="fc" id="L45">    private static final Comparator&lt;Pair&lt;List&lt;SSTableReader&gt;,Double&gt;&gt; bucketsByHotnessComparator = new Comparator&lt;Pair&lt;List&lt;SSTableReader&gt;, Double&gt;&gt;()</span>
<span class="fc" id="L46">    {</span>
        public int compare(Pair&lt;List&lt;SSTableReader&gt;, Double&gt; o1, Pair&lt;List&lt;SSTableReader&gt;, Double&gt; o2)
        {
<span class="nc" id="L49">            int comparison = Double.compare(o1.right, o2.right);</span>
<span class="nc bnc" id="L50" title="All 2 branches missed.">            if (comparison != 0)</span>
<span class="nc" id="L51">                return comparison;</span>

            // break ties by compacting the smallest sstables first (this will probably only happen for
            // system tables and new/unread sstables)
<span class="nc" id="L55">            return Long.compare(avgSize(o1.left), avgSize(o2.left));</span>
        }

        private long avgSize(List&lt;SSTableReader&gt; sstables)
        {
<span class="nc" id="L60">            long n = 0;</span>
<span class="nc bnc" id="L61" title="All 2 branches missed.">            for (SSTableReader sstable : sstables)</span>
<span class="nc" id="L62">                n += sstable.bytesOnDisk();</span>
<span class="nc" id="L63">            return n / sstables.size();</span>
        }
    };

    protected SizeTieredCompactionStrategyOptions sizeTieredOptions;
    protected volatile int estimatedRemainingTasks;
<span class="fc" id="L69">    @VisibleForTesting</span>
    protected final Set&lt;SSTableReader&gt; sstables = new HashSet&lt;&gt;();

    public SizeTieredCompactionStrategy(ColumnFamilyStore cfs, Map&lt;String, String&gt; options)
    {
<span class="fc" id="L74">        super(cfs, options);</span>
<span class="fc" id="L75">        this.estimatedRemainingTasks = 0;</span>
<span class="fc" id="L76">        this.sizeTieredOptions = new SizeTieredCompactionStrategyOptions(options);</span>
<span class="fc" id="L77">    }</span>

    private synchronized List&lt;SSTableReader&gt; getNextBackgroundSSTables(final long gcBefore)
    {
        // make local copies so they can't be changed out from under us mid-method
<span class="fc" id="L82">        int minThreshold = cfs.getMinimumCompactionThreshold();</span>
<span class="fc" id="L83">        int maxThreshold = cfs.getMaximumCompactionThreshold();</span>

<span class="fc" id="L85">        Iterable&lt;SSTableReader&gt; candidates = filterSuspectSSTables(filter(cfs.getUncompactingSSTables(), sstables::contains));</span>

<span class="fc" id="L87">        List&lt;List&lt;SSTableReader&gt;&gt; buckets = getBuckets(createSSTableAndLengthPairs(candidates), sizeTieredOptions.bucketHigh, sizeTieredOptions.bucketLow, sizeTieredOptions.minSSTableSize);</span>
<span class="fc" id="L88">        logger.trace(&quot;Compaction buckets are {}&quot;, buckets);</span>
<span class="fc" id="L89">        estimatedRemainingTasks = getEstimatedCompactionsByTasks(cfs, buckets);</span>
<span class="fc" id="L90">        cfs.getCompactionStrategyManager().compactionLogger.pending(this, estimatedRemainingTasks);</span>
<span class="fc" id="L91">        List&lt;SSTableReader&gt; mostInteresting = mostInterestingBucket(buckets, minThreshold, maxThreshold);</span>
<span class="pc bpc" id="L92" title="1 of 2 branches missed.">        if (!mostInteresting.isEmpty())</span>
<span class="nc" id="L93">            return mostInteresting;</span>

        // if there is no sstable to compact in standard way, try compacting single sstable whose droppable tombstone
        // ratio is greater than threshold.
<span class="fc" id="L97">        List&lt;SSTableReader&gt; sstablesWithTombstones = new ArrayList&lt;&gt;();</span>
<span class="fc bfc" id="L98" title="All 2 branches covered.">        for (SSTableReader sstable : candidates)</span>
        {
<span class="pc bpc" id="L100" title="1 of 2 branches missed.">            if (worthDroppingTombstones(sstable, gcBefore))</span>
<span class="nc" id="L101">                sstablesWithTombstones.add(sstable);</span>
<span class="fc" id="L102">        }</span>
<span class="pc bpc" id="L103" title="1 of 2 branches missed.">        if (sstablesWithTombstones.isEmpty())</span>
<span class="fc" id="L104">            return Collections.emptyList();</span>

<span class="nc" id="L106">        return Collections.singletonList(Collections.max(sstablesWithTombstones, SSTableReader.sizeComparator));</span>
    }


    /**
     * @param buckets list of buckets from which to return the most interesting, where &quot;interesting&quot; is the total hotness for reads
     * @param minThreshold minimum number of sstables in a bucket to qualify as interesting
     * @param maxThreshold maximum number of sstables to compact at once (the returned bucket will be trimmed down to this)
     * @return a bucket (list) of sstables to compact
     */
    public static List&lt;SSTableReader&gt; mostInterestingBucket(List&lt;List&lt;SSTableReader&gt;&gt; buckets, int minThreshold, int maxThreshold)
    {
        // skip buckets containing less than minThreshold sstables, and limit other buckets to maxThreshold sstables
<span class="fc" id="L119">        final List&lt;Pair&lt;List&lt;SSTableReader&gt;, Double&gt;&gt; prunedBucketsAndHotness = new ArrayList&lt;&gt;(buckets.size());</span>
<span class="fc bfc" id="L120" title="All 2 branches covered.">        for (List&lt;SSTableReader&gt; bucket : buckets)</span>
        {
<span class="fc" id="L122">            Pair&lt;List&lt;SSTableReader&gt;, Double&gt; bucketAndHotness = trimToThresholdWithHotness(bucket, maxThreshold);</span>
<span class="pc bpc" id="L123" title="2 of 4 branches missed.">            if (bucketAndHotness != null &amp;&amp; bucketAndHotness.left.size() &gt;= minThreshold)</span>
<span class="nc" id="L124">                prunedBucketsAndHotness.add(bucketAndHotness);</span>
<span class="fc" id="L125">        }</span>
<span class="pc bpc" id="L126" title="1 of 2 branches missed.">        if (prunedBucketsAndHotness.isEmpty())</span>
<span class="fc" id="L127">            return Collections.emptyList();</span>

<span class="nc" id="L129">        Pair&lt;List&lt;SSTableReader&gt;, Double&gt; hottest = Collections.max(prunedBucketsAndHotness, bucketsByHotnessComparator);</span>
<span class="nc" id="L130">        return hottest.left;</span>
    }

    /**
     * Returns a (bucket, hotness) pair or null if there were not enough sstables in the bucket to meet minThreshold.
     * If there are more than maxThreshold sstables, the coldest sstables will be trimmed to meet the threshold.
     **/
    @VisibleForTesting
    static Pair&lt;List&lt;SSTableReader&gt;, Double&gt; trimToThresholdWithHotness(List&lt;SSTableReader&gt; bucket, int maxThreshold)
    {
        // Sort by sstable hotness (descending). We first build a map because the hotness may change during the sort.
<span class="fc" id="L141">        final Map&lt;SSTableReader, Double&gt; hotnessSnapshot = getHotnessMap(bucket);</span>
<span class="fc" id="L142">        Collections.sort(bucket, new Comparator&lt;SSTableReader&gt;()</span>
<span class="fc" id="L143">        {</span>
            public int compare(SSTableReader o1, SSTableReader o2)
            {
<span class="nc" id="L146">                return -1 * Double.compare(hotnessSnapshot.get(o1), hotnessSnapshot.get(o2));</span>
            }
        });

        // and then trim the coldest sstables off the end to meet the maxThreshold
<span class="fc" id="L151">        List&lt;SSTableReader&gt; prunedBucket = bucket.subList(0, Math.min(bucket.size(), maxThreshold));</span>

        // bucket hotness is the sum of the hotness of all sstable members
<span class="fc" id="L154">        double bucketHotness = 0.0;</span>
<span class="fc bfc" id="L155" title="All 2 branches covered.">        for (SSTableReader sstr : prunedBucket)</span>
<span class="fc" id="L156">            bucketHotness += hotness(sstr);</span>

<span class="fc" id="L158">        return Pair.create(prunedBucket, bucketHotness);</span>
    }

    private static Map&lt;SSTableReader, Double&gt; getHotnessMap(Collection&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L163">        Map&lt;SSTableReader, Double&gt; hotness = new HashMap&lt;&gt;(sstables.size());</span>
<span class="fc bfc" id="L164" title="All 2 branches covered.">        for (SSTableReader sstable : sstables)</span>
<span class="fc" id="L165">            hotness.put(sstable, hotness(sstable));</span>
<span class="fc" id="L166">        return hotness;</span>
    }

    /**
     * Returns the reads per second per key for this sstable, or 0.0 if the sstable has no read meter
     */
    private static double hotness(SSTableReader sstr)
    {
        // system tables don't have read meters, just use 0.0 for the hotness
<span class="pc bpc" id="L175" title="1 of 2 branches missed.">        return sstr.getReadMeter() == null ? 0.0 : sstr.getReadMeter().twoHourRate() / sstr.estimatedKeys();</span>
    }

    @SuppressWarnings(&quot;resource&quot;)
    public AbstractCompactionTask getNextBackgroundTask(long gcBefore)
    {
<span class="fc" id="L181">        List&lt;SSTableReader&gt; previousCandidate = null;</span>
        while (true)
        {
<span class="fc" id="L184">            List&lt;SSTableReader&gt; hottestBucket = getNextBackgroundSSTables(gcBefore);</span>

<span class="pc bpc" id="L186" title="1 of 2 branches missed.">            if (hottestBucket.isEmpty())</span>
<span class="fc" id="L187">                return null;</span>

            // Already tried acquiring references without success. It means there is a race with
            // the tracker but candidate SSTables were not yet replaced in the compaction strategy manager
<span class="nc bnc" id="L191" title="All 2 branches missed.">            if (hottestBucket.equals(previousCandidate))</span>
            {
<span class="nc" id="L193">                logger.warn(&quot;Could not acquire references for compacting SSTables {} which is not a problem per se,&quot; +</span>
                            &quot;unless it happens frequently, in which case it must be reported. Will retry later.&quot;,
                            hottestBucket);
<span class="nc" id="L196">                return null;</span>
            }

<span class="nc" id="L199">            LifecycleTransaction transaction = cfs.getTracker().tryModify(hottestBucket, OperationType.COMPACTION);</span>
<span class="nc bnc" id="L200" title="All 2 branches missed.">            if (transaction != null)</span>
<span class="nc" id="L201">                return new CompactionTask(cfs, transaction, gcBefore);</span>
<span class="nc" id="L202">            previousCandidate = hottestBucket;</span>
<span class="nc" id="L203">        }</span>
    }

    @SuppressWarnings(&quot;resource&quot;)
    public synchronized Collection&lt;AbstractCompactionTask&gt; getMaximalTask(final long gcBefore, boolean splitOutput)
    {
<span class="nc" id="L209">        Iterable&lt;SSTableReader&gt; filteredSSTables = filterSuspectSSTables(sstables);</span>
<span class="nc bnc" id="L210" title="All 2 branches missed.">        if (Iterables.isEmpty(filteredSSTables))</span>
<span class="nc" id="L211">            return null;</span>
<span class="nc" id="L212">        LifecycleTransaction txn = cfs.getTracker().tryModify(filteredSSTables, OperationType.COMPACTION);</span>
<span class="nc bnc" id="L213" title="All 2 branches missed.">        if (txn == null)</span>
<span class="nc" id="L214">            return null;</span>
<span class="nc bnc" id="L215" title="All 2 branches missed.">        if (splitOutput)</span>
<span class="nc" id="L216">            return Arrays.&lt;AbstractCompactionTask&gt;asList(new SplittingCompactionTask(cfs, txn, gcBefore));</span>
<span class="nc" id="L217">        return Arrays.&lt;AbstractCompactionTask&gt;asList(new CompactionTask(cfs, txn, gcBefore));</span>
    }

    @SuppressWarnings(&quot;resource&quot;)
    public AbstractCompactionTask getUserDefinedTask(Collection&lt;SSTableReader&gt; sstables, final long gcBefore)
    {
<span class="nc bnc" id="L223" title="All 2 branches missed.">        assert !sstables.isEmpty(); // checked for by CM.submitUserDefined</span>

<span class="nc" id="L225">        LifecycleTransaction transaction = cfs.getTracker().tryModify(sstables, OperationType.COMPACTION);</span>
<span class="nc bnc" id="L226" title="All 2 branches missed.">        if (transaction == null)</span>
        {
<span class="nc" id="L228">            logger.trace(&quot;Unable to mark {} for compaction; probably a background compaction got to it first.  You can disable background compactions temporarily if this is a problem&quot;, sstables);</span>
<span class="nc" id="L229">            return null;</span>
        }

<span class="nc" id="L232">        return new CompactionTask(cfs, transaction, gcBefore).setUserDefined(true);</span>
    }

    public int getEstimatedRemainingTasks()
    {
<span class="fc" id="L237">        return estimatedRemainingTasks;</span>
    }

    public static List&lt;Pair&lt;SSTableReader, Long&gt;&gt; createSSTableAndLengthPairs(Iterable&lt;SSTableReader&gt; sstables)
    {
<span class="fc" id="L242">        List&lt;Pair&lt;SSTableReader, Long&gt;&gt; sstableLengthPairs = new ArrayList&lt;&gt;(Iterables.size(sstables));</span>
<span class="fc bfc" id="L243" title="All 2 branches covered.">        for(SSTableReader sstable : sstables)</span>
<span class="fc" id="L244">            sstableLengthPairs.add(Pair.create(sstable, sstable.onDiskLength()));</span>
<span class="fc" id="L245">        return sstableLengthPairs;</span>
    }

    /*
     * Group files of similar size into buckets.
     */
    public static &lt;T&gt; List&lt;List&lt;T&gt;&gt; getBuckets(Collection&lt;Pair&lt;T, Long&gt;&gt; files, double bucketHigh, double bucketLow, long minSSTableSize)
    {
        // Sort the list in order to get deterministic results during the grouping below
<span class="fc" id="L254">        List&lt;Pair&lt;T, Long&gt;&gt; sortedFiles = new ArrayList&lt;Pair&lt;T, Long&gt;&gt;(files);</span>
<span class="fc" id="L255">        Collections.sort(sortedFiles, new Comparator&lt;Pair&lt;T, Long&gt;&gt;()</span>
<span class="fc" id="L256">        {</span>
            public int compare(Pair&lt;T, Long&gt; p1, Pair&lt;T, Long&gt; p2)
            {
<span class="nc" id="L259">                return p1.right.compareTo(p2.right);</span>
            }
        });

<span class="fc" id="L263">        Map&lt;Long, List&lt;T&gt;&gt; buckets = new HashMap&lt;Long, List&lt;T&gt;&gt;();</span>

        outer:
<span class="fc bfc" id="L266" title="All 2 branches covered.">        for (Pair&lt;T, Long&gt; pair: sortedFiles)</span>
        {
<span class="fc" id="L268">            long size = pair.right;</span>

            // look for a bucket containing similar-sized files:
            // group in the same bucket if it's w/in 50% of the average for this bucket,
            // or this file and the bucket are all considered &quot;small&quot; (less than `minSSTableSize`)
<span class="pc bpc" id="L273" title="1 of 2 branches missed.">            for (Entry&lt;Long, List&lt;T&gt;&gt; entry : buckets.entrySet())</span>
            {
<span class="nc" id="L275">                List&lt;T&gt; bucket = entry.getValue();</span>
<span class="nc" id="L276">                long oldAverageSize = entry.getKey();</span>
<span class="nc bnc" id="L277" title="All 8 branches missed.">                if ((size &gt; (oldAverageSize * bucketLow) &amp;&amp; size &lt; (oldAverageSize * bucketHigh))</span>
                    || (size &lt; minSSTableSize &amp;&amp; oldAverageSize &lt; minSSTableSize))
                {
                    // remove and re-add under new new average size
<span class="nc" id="L281">                    buckets.remove(oldAverageSize);</span>
<span class="nc" id="L282">                    long totalSize = bucket.size() * oldAverageSize;</span>
<span class="nc" id="L283">                    long newAverageSize = (totalSize + size) / (bucket.size() + 1);</span>
<span class="nc" id="L284">                    bucket.add(pair.left);</span>
<span class="nc" id="L285">                    buckets.put(newAverageSize, bucket);</span>
<span class="nc" id="L286">                    continue outer;</span>
                }
<span class="nc" id="L288">            }</span>

            // no similar bucket found; put it in a new one
<span class="fc" id="L291">            ArrayList&lt;T&gt; bucket = new ArrayList&lt;T&gt;();</span>
<span class="fc" id="L292">            bucket.add(pair.left);</span>
<span class="fc" id="L293">            buckets.put(size, bucket);</span>
<span class="fc" id="L294">        }</span>

<span class="fc" id="L296">        return new ArrayList&lt;List&lt;T&gt;&gt;(buckets.values());</span>
    }

    public static int getEstimatedCompactionsByTasks(ColumnFamilyStore cfs, List&lt;List&lt;SSTableReader&gt;&gt; tasks)
    {
<span class="fc" id="L301">        int n = 0;</span>
<span class="fc bfc" id="L302" title="All 2 branches covered.">        for (List&lt;SSTableReader&gt; bucket : tasks)</span>
        {
<span class="pc bpc" id="L304" title="1 of 2 branches missed.">            if (bucket.size() &gt;= cfs.getMinimumCompactionThreshold())</span>
<span class="nc" id="L305">                n += Math.ceil((double)bucket.size() / cfs.getMaximumCompactionThreshold());</span>
<span class="fc" id="L306">        }</span>
<span class="fc" id="L307">        return n;</span>
    }

    public long getMaxSSTableBytes()
    {
<span class="fc" id="L312">        return Long.MAX_VALUE;</span>
    }

    public static Map&lt;String, String&gt; validateOptions(Map&lt;String, String&gt; options) throws ConfigurationException
    {
<span class="fc" id="L317">        Map&lt;String, String&gt; uncheckedOptions = AbstractCompactionStrategy.validateOptions(options);</span>
<span class="fc" id="L318">        uncheckedOptions = SizeTieredCompactionStrategyOptions.validateOptions(options, uncheckedOptions);</span>

<span class="fc" id="L320">        uncheckedOptions.remove(CompactionParams.Option.MIN_THRESHOLD.toString());</span>
<span class="fc" id="L321">        uncheckedOptions.remove(CompactionParams.Option.MAX_THRESHOLD.toString());</span>

<span class="fc" id="L323">        return uncheckedOptions;</span>
    }

    @Override
    public synchronized void addSSTable(SSTableReader added)
    {
<span class="fc" id="L329">        sstables.add(added);</span>
<span class="fc" id="L330">    }</span>

    @Override
    public synchronized void removeSSTable(SSTableReader sstable)
    {
<span class="nc" id="L335">        sstables.remove(sstable);</span>
<span class="nc" id="L336">    }</span>

    @Override
    protected synchronized Set&lt;SSTableReader&gt; getSSTables()
    {
<span class="nc" id="L341">        return ImmutableSet.copyOf(sstables);</span>
    }

    public String toString()
    {
<span class="nc" id="L346">        return String.format(&quot;SizeTieredCompactionStrategy[%s/%s]&quot;,</span>
<span class="nc" id="L347">            cfs.getMinimumCompactionThreshold(),</span>
<span class="nc" id="L348">            cfs.getMaximumCompactionThreshold());</span>
    }

    private static class SplittingCompactionTask extends CompactionTask
    {
        public SplittingCompactionTask(ColumnFamilyStore cfs, LifecycleTransaction txn, long gcBefore)
        {
            super(cfs, txn, gcBefore);
        }

        @Override
        public CompactionAwareWriter getCompactionAwareWriter(ColumnFamilyStore cfs,
                                                              Directories directories,
                                                              LifecycleTransaction txn,
                                                              Set&lt;SSTableReader&gt; nonExpiredSSTables)
        {
            return new SplittingSizeTieredCompactionWriter(cfs, directories, txn, nonExpiredSSTables);
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>