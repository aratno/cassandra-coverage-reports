<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ShortReadPartitionsProtection.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Cassandara Coverage Report</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.service.reads</a> &gt; <span class="el_source">ShortReadPartitionsProtection.java</span></div><h1>ShortReadPartitionsProtection.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.cassandra.service.reads;

import org.apache.cassandra.locator.Endpoints;
import org.apache.cassandra.locator.ReplicaPlan;
import org.apache.cassandra.locator.ReplicaPlans;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.cassandra.concurrent.Stage;
import org.apache.cassandra.db.ColumnFamilyStore;
import org.apache.cassandra.db.DataRange;
import org.apache.cassandra.db.DecoratedKey;
import org.apache.cassandra.db.Keyspace;
import org.apache.cassandra.db.PartitionPosition;
import org.apache.cassandra.db.PartitionRangeReadCommand;
import org.apache.cassandra.db.ReadCommand;
import org.apache.cassandra.db.filter.DataLimits;
import org.apache.cassandra.db.partitions.UnfilteredPartitionIterator;
import org.apache.cassandra.db.rows.UnfilteredRowIterator;
import org.apache.cassandra.db.transform.MorePartitions;
import org.apache.cassandra.db.transform.MoreRows;
import org.apache.cassandra.db.transform.Transformation;
import org.apache.cassandra.dht.AbstractBounds;
import org.apache.cassandra.dht.ExcludingBounds;
import org.apache.cassandra.dht.Range;
import org.apache.cassandra.locator.Replica;
import org.apache.cassandra.net.MessagingService;
import org.apache.cassandra.service.reads.repair.NoopReadRepair;
import org.apache.cassandra.service.StorageProxy;
import org.apache.cassandra.tracing.Tracing;

public class ShortReadPartitionsProtection extends Transformation&lt;UnfilteredRowIterator&gt; implements MorePartitions&lt;UnfilteredPartitionIterator&gt;
{
<span class="fc" id="L52">    private static final Logger logger = LoggerFactory.getLogger(ShortReadPartitionsProtection.class);</span>
    private final ReadCommand command;
    private final Replica source;

    private final Runnable preFetchCallback; // called immediately before fetching more contents

    private final DataLimits.Counter singleResultCounter; // unmerged per-source counter
    private final DataLimits.Counter mergedResultCounter; // merged end-result counter

    private DecoratedKey lastPartitionKey; // key of the last observed partition

    private boolean partitionsFetched; // whether we've seen any new partitions since iteration start or last moreContents() call

    private final long queryStartNanoTime;

    public ShortReadPartitionsProtection(ReadCommand command,
                                         Replica source,
                                         Runnable preFetchCallback,
                                         DataLimits.Counter singleResultCounter,
                                         DataLimits.Counter mergedResultCounter,
                                         long queryStartNanoTime)
<span class="fc" id="L73">    {</span>
<span class="fc" id="L74">        this.command = command;</span>
<span class="fc" id="L75">        this.source = source;</span>
<span class="fc" id="L76">        this.preFetchCallback = preFetchCallback;</span>
<span class="fc" id="L77">        this.singleResultCounter = singleResultCounter;</span>
<span class="fc" id="L78">        this.mergedResultCounter = mergedResultCounter;</span>
<span class="fc" id="L79">        this.queryStartNanoTime = queryStartNanoTime;</span>
<span class="fc" id="L80">    }</span>

    @Override
    public UnfilteredRowIterator applyToPartition(UnfilteredRowIterator partition)
    {
<span class="fc" id="L85">        partitionsFetched = true;</span>

<span class="fc" id="L87">        lastPartitionKey = partition.partitionKey();</span>

        /*
         * Extend for moreContents() then apply protection to track lastClustering by applyToRow().
         *
         * If we don't apply the transformation *after* extending the partition with MoreRows,
         * applyToRow() method of protection will not be called on the first row of the new extension iterator.
         */
<span class="fc" id="L95">        ReplicaPlan.ForTokenRead replicaPlan = ReplicaPlans.forSingleReplicaRead(Keyspace.open(command.metadata().keyspace), partition.partitionKey().getToken(), source);</span>
<span class="fc" id="L96">        ReplicaPlan.SharedForTokenRead sharedReplicaPlan = ReplicaPlan.shared(replicaPlan);</span>
<span class="fc" id="L97">        ShortReadRowsProtection protection = new ShortReadRowsProtection(partition.partitionKey(),</span>
                                                                         command, source,
<span class="fc" id="L99">                                                                         (cmd) -&gt; executeReadCommand(cmd, sharedReplicaPlan),</span>
                                                                         singleResultCounter,
                                                                         mergedResultCounter);
<span class="fc" id="L102">        return Transformation.apply(MoreRows.extend(partition, protection), protection);</span>
    }

    /*
     * We only get here once all the rows and partitions in this iterator have been iterated over, and so
     * if the node had returned the requested number of rows but we still get here, then some results were
     * skipped during reconciliation.
     */
    public UnfilteredPartitionIterator moreContents()
    {
        // never try to request additional partitions from replicas if our reconciled partitions are already filled to the limit
<span class="pc bpc" id="L113" title="1 of 2 branches missed.">        assert !mergedResultCounter.isDone();</span>

        // we do not apply short read protection when we have no limits at all
<span class="pc bpc" id="L116" title="1 of 2 branches missed.">        assert !command.limits().isUnlimited();</span>

        /*
         * If this is a single partition read command or an (indexed) partition range read command with
         * a partition key specified, then we can't and shouldn't try fetch more partitions.
         */
<span class="pc bpc" id="L122" title="1 of 2 branches missed.">        assert !command.isLimitedToOnePartition();</span>

        /*
         * If the returned result doesn't have enough rows/partitions to satisfy even the original limit, don't ask for more.
         *
         * Can only take the short cut if there is no per partition limit set. Otherwise it's possible to hit false
         * positives due to some rows being uncounted for in certain scenarios (see CASSANDRA-13911).
         */
<span class="pc bpc" id="L130" title="1 of 4 branches missed.">        if (command.limits().isExhausted(singleResultCounter) &amp;&amp; command.limits().perPartitionCount() == DataLimits.NO_LIMIT)</span>
<span class="fc" id="L131">            return null;</span>

        /*
         * Either we had an empty iterator as the initial response, or our moreContents() call got us an empty iterator.
         * There is no point to ask the replica for more rows - it has no more in the requested range.
         */
<span class="fc bfc" id="L137" title="All 2 branches covered.">        if (!partitionsFetched)</span>
<span class="fc" id="L138">            return null;</span>
<span class="fc" id="L139">        partitionsFetched = false;</span>

        /*
         * We are going to fetch one partition at a time for thrift and potentially more for CQL.
         * The row limit will either be set to the per partition limit - if the command has no total row limit set, or
         * the total # of rows remaining - if it has some. If we don't grab enough rows in some of the partitions,
         * then future ShortReadRowsProtection.moreContents() calls will fetch the missing ones.
         */
<span class="fc bfc" id="L147" title="All 2 branches covered.">        int toQuery = command.limits().count() != DataLimits.NO_LIMIT</span>
<span class="fc" id="L148">                      ? command.limits().count() - mergedResultCounter.rowsCounted()</span>
<span class="fc" id="L149">                      : command.limits().perPartitionCount();</span>

<span class="fc" id="L151">        ColumnFamilyStore.metricsFor(command.metadata().id).shortReadProtectionRequests.mark();</span>
<span class="fc" id="L152">        Tracing.trace(&quot;Requesting {} extra rows from {} for short read protection&quot;, toQuery, source);</span>
<span class="fc" id="L153">        logger.info(&quot;Requesting {} extra rows from {} for short read protection&quot;, toQuery, source);</span>

        // If we've arrived here, all responses have been consumed, and we're about to request more.
<span class="fc" id="L156">        preFetchCallback.run();</span>

<span class="fc" id="L158">        return makeAndExecuteFetchAdditionalPartitionReadCommand(toQuery);</span>
    }

    private UnfilteredPartitionIterator makeAndExecuteFetchAdditionalPartitionReadCommand(int toQuery)
    {
<span class="fc" id="L163">        PartitionRangeReadCommand cmd = (PartitionRangeReadCommand) command;</span>

<span class="fc" id="L165">        DataLimits newLimits = cmd.limits().forShortReadRetry(toQuery);</span>

<span class="fc" id="L167">        AbstractBounds&lt;PartitionPosition&gt; bounds = cmd.dataRange().keyRange();</span>
<span class="pc bpc" id="L168" title="1 of 2 branches missed.">        AbstractBounds&lt;PartitionPosition&gt; newBounds = bounds.inclusiveRight()</span>
<span class="fc" id="L169">                                                      ? new Range&lt;&gt;(lastPartitionKey, bounds.right)</span>
<span class="pc" id="L170">                                                      : new ExcludingBounds&lt;&gt;(lastPartitionKey, bounds.right);</span>
<span class="fc" id="L171">        DataRange newDataRange = cmd.dataRange().forSubRange(newBounds);</span>

<span class="fc" id="L173">        ReplicaPlan.ForRangeRead replicaPlan = ReplicaPlans.forSingleReplicaRead(Keyspace.open(command.metadata().keyspace), cmd.dataRange().keyRange(), source, 1);</span>
<span class="fc" id="L174">        return executeReadCommand(cmd.withUpdatedLimitsAndDataRange(newLimits, newDataRange), ReplicaPlan.shared(replicaPlan));</span>
    }

    private &lt;E extends Endpoints&lt;E&gt;, P extends ReplicaPlan.ForRead&lt;E, P&gt;&gt;
    UnfilteredPartitionIterator executeReadCommand(ReadCommand cmd, ReplicaPlan.Shared&lt;E, P&gt; replicaPlan)
    {
<span class="fc" id="L180">        DataResolver&lt;E, P&gt; resolver = new DataResolver&lt;&gt;(cmd, replicaPlan, (NoopReadRepair&lt;E, P&gt;)NoopReadRepair.instance, queryStartNanoTime);</span>
<span class="fc" id="L181">        ReadCallback&lt;E, P&gt; handler = new ReadCallback&lt;&gt;(resolver, cmd, replicaPlan, queryStartNanoTime);</span>

<span class="fc bfc" id="L183" title="All 2 branches covered.">        if (source.isSelf())</span>
        {
<span class="fc" id="L185">            Stage.READ.maybeExecuteImmediately(new StorageProxy.LocalReadRunnable(cmd, handler));</span>
        }
        else
        {
<span class="pc bpc" id="L189" title="1 of 2 branches missed.">            if (source.isTransient())</span>
<span class="nc" id="L190">                cmd = cmd.copyAsTransientQuery(source);</span>
<span class="fc" id="L191">            MessagingService.instance().sendWithCallback(cmd.createMessage(false), source.endpoint(), handler);</span>
        }

        // We don't call handler.get() because we want to preserve tombstones since we're still in the middle of merging node results.
<span class="fc" id="L195">        handler.awaitResults();</span>
<span class="pc bpc" id="L196" title="1 of 2 branches missed.">        assert resolver.getMessages().size() == 1;</span>
<span class="fc" id="L197">        return resolver.getMessages().get(0).payload.makeIterator(command);</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>