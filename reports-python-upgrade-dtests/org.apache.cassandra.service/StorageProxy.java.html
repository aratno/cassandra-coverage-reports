<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>StorageProxy.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JaCoCo Cassandara Coverage Report</a> &gt; <a href="index.source.html" class="el_package">org.apache.cassandra.service</a> &gt; <span class="el_source">StorageProxy.java</span></div><h1>StorageProxy.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.cassandra.service;

import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import java.util.Set;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.Future;
import java.util.concurrent.ThreadLocalRandom;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.function.Function;
import java.util.stream.Collectors;

import com.google.common.base.Preconditions;
import com.google.common.cache.CacheLoader;
import com.google.common.collect.Iterables;
import com.google.common.util.concurrent.Uninterruptibles;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.cassandra.batchlog.Batch;
import org.apache.cassandra.batchlog.BatchlogManager;
import org.apache.cassandra.concurrent.DebuggableTask.RunnableDebuggableTask;
import org.apache.cassandra.concurrent.Stage;
import org.apache.cassandra.config.CassandraRelevantProperties;
import org.apache.cassandra.config.Config;
import org.apache.cassandra.config.DatabaseDescriptor;
import org.apache.cassandra.db.ColumnFamilyStore;
import org.apache.cassandra.db.ConsistencyLevel;
import org.apache.cassandra.db.CounterMutation;
import org.apache.cassandra.db.DecoratedKey;
import org.apache.cassandra.db.IMutation;
import org.apache.cassandra.db.Keyspace;
import org.apache.cassandra.db.MessageParams;
import org.apache.cassandra.db.Mutation;
import org.apache.cassandra.db.PartitionRangeReadCommand;
import org.apache.cassandra.db.ReadCommand;
import org.apache.cassandra.db.ReadExecutionController;
import org.apache.cassandra.db.ReadResponse;
import org.apache.cassandra.db.RejectException;
import org.apache.cassandra.db.SinglePartitionReadCommand;
import org.apache.cassandra.db.TruncateRequest;
import org.apache.cassandra.db.WriteType;
import org.apache.cassandra.db.filter.TombstoneOverwhelmingException;
import org.apache.cassandra.db.partitions.FilteredPartition;
import org.apache.cassandra.db.partitions.PartitionIterator;
import org.apache.cassandra.db.partitions.PartitionIterators;
import org.apache.cassandra.db.partitions.PartitionUpdate;
import org.apache.cassandra.db.partitions.UnfilteredPartitionIterator;
import org.apache.cassandra.db.rows.RowIterator;
import org.apache.cassandra.db.view.ViewUtils;
import org.apache.cassandra.dht.Token;
import org.apache.cassandra.exceptions.CasWriteTimeoutException;
import org.apache.cassandra.exceptions.CasWriteUnknownResultException;
import org.apache.cassandra.exceptions.InvalidRequestException;
import org.apache.cassandra.exceptions.IsBootstrappingException;
import org.apache.cassandra.exceptions.OverloadedException;
import org.apache.cassandra.exceptions.QueryCancelledException;
import org.apache.cassandra.exceptions.ReadAbortException;
import org.apache.cassandra.exceptions.ReadFailureException;
import org.apache.cassandra.exceptions.ReadTimeoutException;
import org.apache.cassandra.exceptions.RequestFailureException;
import org.apache.cassandra.exceptions.RequestFailureReason;
import org.apache.cassandra.exceptions.RequestTimeoutException;
import org.apache.cassandra.exceptions.UnavailableException;
import org.apache.cassandra.exceptions.WriteFailureException;
import org.apache.cassandra.exceptions.WriteTimeoutException;
import org.apache.cassandra.gms.FailureDetector;
import org.apache.cassandra.gms.Gossiper;
import org.apache.cassandra.hints.Hint;
import org.apache.cassandra.hints.HintsService;
import org.apache.cassandra.locator.AbstractReplicationStrategy;
import org.apache.cassandra.locator.DynamicEndpointSnitch;
import org.apache.cassandra.locator.EndpointsForToken;
import org.apache.cassandra.locator.IEndpointSnitch;
import org.apache.cassandra.locator.InetAddressAndPort;
import org.apache.cassandra.locator.Replica;
import org.apache.cassandra.locator.ReplicaLayout;
import org.apache.cassandra.locator.ReplicaPlan;
import org.apache.cassandra.locator.ReplicaPlans;
import org.apache.cassandra.locator.Replicas;
import org.apache.cassandra.metrics.CASClientRequestMetrics;
import org.apache.cassandra.metrics.ClientRequestSizeMetrics;
import org.apache.cassandra.metrics.DenylistMetrics;
import org.apache.cassandra.metrics.ReadRepairMetrics;
import org.apache.cassandra.metrics.StorageMetrics;
import org.apache.cassandra.net.ForwardingInfo;
import org.apache.cassandra.net.Message;
import org.apache.cassandra.net.MessageFlag;
import org.apache.cassandra.net.MessagingService;
import org.apache.cassandra.net.RequestCallback;
import org.apache.cassandra.net.Verb;
import org.apache.cassandra.schema.PartitionDenylist;
import org.apache.cassandra.schema.Schema;
import org.apache.cassandra.schema.SchemaConstants;
import org.apache.cassandra.schema.TableId;
import org.apache.cassandra.schema.TableMetadata;
import org.apache.cassandra.service.paxos.Ballot;
import org.apache.cassandra.service.paxos.Commit;
import org.apache.cassandra.service.paxos.ContentionStrategy;
import org.apache.cassandra.service.paxos.Paxos;
import org.apache.cassandra.service.paxos.PaxosState;
import org.apache.cassandra.service.paxos.v1.PrepareCallback;
import org.apache.cassandra.service.paxos.v1.ProposeCallback;
import org.apache.cassandra.service.reads.AbstractReadExecutor;
import org.apache.cassandra.service.reads.ReadCallback;
import org.apache.cassandra.service.reads.range.RangeCommands;
import org.apache.cassandra.service.reads.repair.ReadRepair;
import org.apache.cassandra.tracing.Tracing;
import org.apache.cassandra.triggers.TriggerExecutor;
import org.apache.cassandra.utils.Clock;
import org.apache.cassandra.utils.FBUtilities;
import org.apache.cassandra.utils.MBeanWrapper;
import org.apache.cassandra.utils.MonotonicClock;
import org.apache.cassandra.utils.NoSpamLogger;
import org.apache.cassandra.utils.Pair;
import org.apache.cassandra.utils.TimeUUID;
import org.apache.cassandra.utils.concurrent.CountDownLatch;
import org.apache.cassandra.utils.concurrent.UncheckedInterruptedException;

import static java.util.concurrent.TimeUnit.MILLISECONDS;
import static java.util.concurrent.TimeUnit.NANOSECONDS;

import static com.google.common.collect.Iterables.concat;
import static org.apache.commons.lang3.StringUtils.join;

import static org.apache.cassandra.db.ConsistencyLevel.SERIAL;
import static org.apache.cassandra.metrics.ClientRequestsMetricsHolder.casReadMetrics;
import static org.apache.cassandra.metrics.ClientRequestsMetricsHolder.casWriteMetrics;
import static org.apache.cassandra.metrics.ClientRequestsMetricsHolder.readMetrics;
import static org.apache.cassandra.metrics.ClientRequestsMetricsHolder.readMetricsForLevel;
import static org.apache.cassandra.metrics.ClientRequestsMetricsHolder.viewWriteMetrics;
import static org.apache.cassandra.metrics.ClientRequestsMetricsHolder.writeMetrics;
import static org.apache.cassandra.metrics.ClientRequestsMetricsHolder.writeMetricsForLevel;
import static org.apache.cassandra.net.Message.out;
import static org.apache.cassandra.net.NoPayload.noPayload;
import static org.apache.cassandra.net.Verb.BATCH_STORE_REQ;
import static org.apache.cassandra.net.Verb.MUTATION_REQ;
import static org.apache.cassandra.net.Verb.PAXOS_COMMIT_REQ;
import static org.apache.cassandra.net.Verb.PAXOS_PREPARE_REQ;
import static org.apache.cassandra.net.Verb.PAXOS_PROPOSE_REQ;
import static org.apache.cassandra.net.Verb.SCHEMA_VERSION_REQ;
import static org.apache.cassandra.net.Verb.TRUNCATE_REQ;
import static org.apache.cassandra.service.BatchlogResponseHandler.BatchlogCleanup;
import static org.apache.cassandra.service.paxos.Ballot.Flag.GLOBAL;
import static org.apache.cassandra.service.paxos.Ballot.Flag.LOCAL;
import static org.apache.cassandra.service.paxos.BallotGenerator.Global.nextBallot;
import static org.apache.cassandra.service.paxos.v1.PrepareVerbHandler.doPrepare;
import static org.apache.cassandra.service.paxos.v1.ProposeVerbHandler.doPropose;
import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
import static org.apache.cassandra.utils.Clock.Global.nanoTime;
import static org.apache.cassandra.utils.TimeUUID.Generator.nextTimeUUID;
import static org.apache.cassandra.utils.concurrent.CountDownLatch.newCountDownLatch;

public class StorageProxy implements StorageProxyMBean
{
    public static final String MBEAN_NAME = &quot;org.apache.cassandra.db:type=StorageProxy&quot;;
<span class="fc" id="L187">    private static final Logger logger = LoggerFactory.getLogger(StorageProxy.class);</span>

    public static final String UNREACHABLE = &quot;UNREACHABLE&quot;;

<span class="fc" id="L191">    private static final int FAILURE_LOGGING_INTERVAL_SECONDS = CassandraRelevantProperties.FAILURE_LOGGING_INTERVAL_SECONDS.getInt();</span>

    private static final WritePerformer standardWritePerformer;
    private static final WritePerformer counterWritePerformer;
    private static final WritePerformer counterWriteOnCoordinatorPerformer;

<span class="fc" id="L197">    public static final StorageProxy instance = new StorageProxy();</span>

<span class="fc" id="L199">    private static volatile int maxHintsInProgress = 128 * FBUtilities.getAvailableProcessors();</span>
<span class="fc" id="L200">    private static final CacheLoader&lt;InetAddressAndPort, AtomicInteger&gt; hintsInProgress = new CacheLoader&lt;InetAddressAndPort, AtomicInteger&gt;()</span>
<span class="fc" id="L201">    {</span>
        public AtomicInteger load(InetAddressAndPort inetAddress)
        {
<span class="fc" id="L204">            return new AtomicInteger(0);</span>
        }
    };

<span class="fc" id="L208">    private static final DenylistMetrics denylistMetrics = new DenylistMetrics();</span>

<span class="fc" id="L210">    private static final PartitionDenylist partitionDenylist = new PartitionDenylist();</span>

<span class="fc" id="L212">    private volatile long logBlockingReadRepairAttemptsUntilNanos = Long.MIN_VALUE;</span>

    private StorageProxy()
<span class="fc" id="L215">    {</span>
<span class="fc" id="L216">    }</span>

    static
    {
<span class="fc" id="L220">        MBeanWrapper.instance.registerMBean(instance, MBEAN_NAME);</span>
<span class="fc" id="L221">        HintsService.instance.registerMBean();</span>

<span class="fc" id="L223">        standardWritePerformer = (mutation, targets, responseHandler, localDataCenter) -&gt;</span>
        {
<span class="pc bpc" id="L225" title="1 of 2 branches missed.">            assert mutation instanceof Mutation;</span>
<span class="fc" id="L226">            sendToHintedReplicas((Mutation) mutation, targets, responseHandler, localDataCenter, Stage.MUTATION);</span>
<span class="fc" id="L227">        };</span>

        /*
         * We execute counter writes in 2 places: either directly in the coordinator node if it is a replica, or
         * in CounterMutationVerbHandler on a replica othewise. The write must be executed on the COUNTER_MUTATION stage
         * but on the latter case, the verb handler already run on the COUNTER_MUTATION stage, so we must not execute the
         * underlying on the stage otherwise we risk a deadlock. Hence two different performer.
         */
<span class="fc" id="L235">        counterWritePerformer = (mutation, targets, responseHandler, localDataCenter) -&gt;</span>
        {
<span class="fc" id="L237">            EndpointsForToken selected = targets.contacts().withoutSelf();</span>
<span class="fc" id="L238">            Replicas.temporaryAssertFull(selected); // TODO CASSANDRA-14548</span>
<span class="fc" id="L239">            counterWriteTask(mutation, targets.withContacts(selected), responseHandler, localDataCenter).run();</span>
<span class="fc" id="L240">        };</span>

<span class="fc" id="L242">        counterWriteOnCoordinatorPerformer = (mutation, targets, responseHandler, localDataCenter) -&gt;</span>
        {
<span class="fc" id="L244">            EndpointsForToken selected = targets.contacts().withoutSelf();</span>
<span class="fc" id="L245">            Replicas.temporaryAssertFull(selected); // TODO CASSANDRA-14548</span>
<span class="fc" id="L246">            Stage.COUNTER_MUTATION.executor()</span>
<span class="fc" id="L247">                                  .execute(counterWriteTask(mutation, targets.withContacts(selected), responseHandler, localDataCenter));</span>
<span class="fc" id="L248">        };</span>


<span class="fc" id="L251">        ReadRepairMetrics.init();</span>

<span class="pc bpc" id="L253" title="1 of 2 branches missed.">        if (!Paxos.isLinearizable())</span>
        {
<span class="nc" id="L255">            logger.warn(&quot;This node was started with paxos variant {}. SERIAL (and LOCAL_SERIAL) reads coordinated by this node &quot; +</span>
                        &quot;will not offer linearizability (see CASSANDRA-12126 for details on what this means) with &quot; +
                        &quot;respect to other SERIAL operations. Please note that with this variant, SERIAL reads will be &quot; +
                        &quot;slower than QUORUM reads, yet offer no additional guarantees. This flag should only be used in &quot; +
                        &quot;the restricted case of upgrading from a pre-CASSANDRA-12126 version, and only if you &quot; +
<span class="nc" id="L260">                        &quot;understand the tradeoff.&quot;, Paxos.getPaxosVariant());</span>
        }
<span class="fc" id="L262">    }</span>

    /**
     * Apply @param updates if and only if the current values in the row for @param key
     * match the provided @param conditions.  The algorithm is &quot;raw&quot; Paxos: that is, Paxos
     * minus leader election -- any node in the cluster may propose changes for any row,
     * which (that is, the row) is the unit of values being proposed, not single columns.
     *
     * The Paxos cohort is only the replicas for the given key, not the entire cluster.
     * So we expect performance to be reasonable, but CAS is still intended to be used
     * &quot;when you really need it,&quot; not for all your updates.
     *
     * There are three phases to Paxos:
     *  1. Prepare: the coordinator generates a ballot (timeUUID in our case) and asks replicas to (a) promise
     *     not to accept updates from older ballots and (b) tell us about the most recent update it has already
     *     accepted.
     *  2. Accept: if a majority of replicas respond, the coordinator asks replicas to accept the value of the
     *     highest proposal ballot it heard about, or a new value if no in-progress proposals were reported.
     *  3. Commit (Learn): if a majority of replicas acknowledge the accept request, we can commit the new
     *     value.
     *
     *  Commit procedure is not covered in &quot;Paxos Made Simple,&quot; and only briefly mentioned in &quot;Paxos Made Live,&quot;
     *  so here is our approach:
     *   3a. The coordinator sends a commit message to all replicas with the ballot and value.
     *   3b. Because of 1-2, this will be the highest-seen commit ballot.  The replicas will note that,
     *       and send it with subsequent promise replies.  This allows us to discard acceptance records
     *       for successfully committed replicas, without allowing incomplete proposals to commit erroneously
     *       later on.
     *
     *  Note that since we are performing a CAS rather than a simple update, we perform a read (of committed
     *  values) between the prepare and accept phases.  This gives us a slightly longer window for another
     *  coordinator to come along and trump our own promise with a newer one but is otherwise safe.
     *
     * @param keyspaceName the keyspace for the CAS
     * @param cfName the column family for the CAS
     * @param key the row key for the row to CAS
     * @param request the conditions for the CAS to apply as well as the update to perform if the conditions hold.
     * @param consistencyForPaxos the consistency for the paxos prepare and propose round. This can only be either SERIAL or LOCAL_SERIAL.
     * @param consistencyForCommit the consistency for write done during the commit phase. This can be anything, except SERIAL or LOCAL_SERIAL.
     *
     * @return null if the operation succeeds in updating the row, or the current values corresponding to conditions.
     * (since, if the CAS doesn't succeed, it means the current value do not match the conditions).
     */
    public static RowIterator cas(String keyspaceName,
                                  String cfName,
                                  DecoratedKey key,
                                  CASRequest request,
                                  ConsistencyLevel consistencyForPaxos,
                                  ConsistencyLevel consistencyForCommit,
                                  ClientState clientState,
                                  long nowInSeconds,
                                  long queryStartNanoTime)
    throws UnavailableException, IsBootstrappingException, RequestFailureException, RequestTimeoutException, InvalidRequestException, CasWriteUnknownResultException
    {
<span class="pc bpc" id="L316" title="5 of 6 branches missed.">        if (DatabaseDescriptor.getPartitionDenylistEnabled() &amp;&amp; DatabaseDescriptor.getDenylistWritesEnabled() &amp;&amp; !partitionDenylist.isKeyPermitted(keyspaceName, cfName, key.getKey()))</span>
        {
<span class="nc" id="L318">            denylistMetrics.incrementWritesRejected();</span>
<span class="nc" id="L319">            throw new InvalidRequestException(String.format(&quot;Unable to CAS write to denylisted partition [0x%s] in %s/%s&quot;,</span>
<span class="nc" id="L320">                                                            key.toString(), keyspaceName, cfName));</span>
        }

<span class="pc bpc" id="L323" title="1 of 2 branches missed.">        return Paxos.useV2()</span>
<span class="nc" id="L324">                ? Paxos.cas(key, request, consistencyForPaxos, consistencyForCommit, clientState)</span>
<span class="fc" id="L325">                : legacyCas(keyspaceName, cfName, key, request, consistencyForPaxos, consistencyForCommit, clientState, nowInSeconds, queryStartNanoTime);</span>
    }

    public static RowIterator legacyCas(String keyspaceName,
                                        String cfName,
                                        DecoratedKey key,
                                        CASRequest request,
                                        ConsistencyLevel consistencyForPaxos,
                                        ConsistencyLevel consistencyForCommit,
                                        ClientState clientState,
                                        long nowInSeconds,
                                        long queryStartNanoTime)
    throws UnavailableException, IsBootstrappingException, RequestFailureException, RequestTimeoutException, InvalidRequestException
    {
<span class="fc" id="L339">        final long startTimeForMetrics = nanoTime();</span>
        try
        {
<span class="fc" id="L342">            TableMetadata metadata = Schema.instance.validateTable(keyspaceName, cfName);</span>

<span class="fc" id="L344">            Function&lt;Ballot, Pair&lt;PartitionUpdate, RowIterator&gt;&gt; updateProposer = ballot -&gt;</span>
            {
                // read the current values and check they validate the conditions
<span class="fc" id="L347">                Tracing.trace(&quot;Reading existing values for CAS precondition&quot;);</span>
<span class="fc" id="L348">                SinglePartitionReadCommand readCommand = (SinglePartitionReadCommand) request.readCommand(nowInSeconds);</span>
<span class="pc bpc" id="L349" title="1 of 2 branches missed.">                ConsistencyLevel readConsistency = consistencyForPaxos == ConsistencyLevel.LOCAL_SERIAL ? ConsistencyLevel.LOCAL_QUORUM : ConsistencyLevel.QUORUM;</span>

                FilteredPartition current;
<span class="fc" id="L352">                try (RowIterator rowIter = readOne(readCommand, readConsistency, queryStartNanoTime))</span>
                {
<span class="fc" id="L354">                    current = FilteredPartition.create(rowIter);</span>
                }

<span class="fc bfc" id="L357" title="All 2 branches covered.">                if (!request.appliesTo(current))</span>
                {
<span class="fc" id="L359">                    Tracing.trace(&quot;CAS precondition does not match current values {}&quot;, current);</span>
<span class="fc" id="L360">                    casWriteMetrics.conditionNotMet.inc();</span>
<span class="fc" id="L361">                    return Pair.create(PartitionUpdate.emptyUpdate(metadata, key), current.rowIterator());</span>
                }

                // Create the desired updates
<span class="fc" id="L365">                PartitionUpdate updates = request.makeUpdates(current, clientState, ballot);</span>

                // Update the metrics before triggers potentially add mutations.
<span class="fc" id="L368">                ClientRequestSizeMetrics.recordRowAndColumnCountMetrics(updates);</span>

<span class="fc" id="L370">                long size = updates.dataSize();</span>
<span class="fc" id="L371">                casWriteMetrics.mutationSize.update(size);</span>
<span class="fc" id="L372">                writeMetricsForLevel(consistencyForPaxos).mutationSize.update(size);</span>

                // Apply triggers to cas updates. A consideration here is that
                // triggers emit Mutations, and so a given trigger implementation
                // may generate mutations for partitions other than the one this
                // paxos round is scoped for. In this case, TriggerExecutor will
                // validate that the generated mutations are targetted at the same
                // partition as the initial updates and reject (via an
                // InvalidRequestException) any which aren't.
<span class="fc" id="L381">                updates = TriggerExecutor.instance.execute(updates);</span>

<span class="fc" id="L383">                return Pair.create(updates, null);</span>
            };

<span class="fc" id="L386">            return doPaxos(metadata,</span>
                           key,
                           consistencyForPaxos,
                           consistencyForCommit,
                           consistencyForCommit,
                           queryStartNanoTime,
                           casWriteMetrics,
                           updateProposer);

        }
<span class="nc" id="L396">        catch (CasWriteUnknownResultException e)</span>
        {
<span class="nc" id="L398">            casWriteMetrics.unknownResult.mark();</span>
<span class="nc" id="L399">            throw e;</span>
        }
<span class="nc" id="L401">        catch (CasWriteTimeoutException wte)</span>
        {
<span class="nc" id="L403">            casWriteMetrics.timeouts.mark();</span>
<span class="nc" id="L404">            writeMetricsForLevel(consistencyForPaxos).timeouts.mark();</span>
<span class="nc" id="L405">            throw new CasWriteTimeoutException(wte.writeType, wte.consistency, wte.received, wte.blockFor, wte.contentions);</span>
        }
<span class="nc" id="L407">        catch (ReadTimeoutException e)</span>
        {
<span class="nc" id="L409">            casWriteMetrics.timeouts.mark();</span>
<span class="nc" id="L410">            writeMetricsForLevel(consistencyForPaxos).timeouts.mark();</span>
<span class="nc" id="L411">            throw e;</span>
        }
<span class="nc" id="L413">        catch (ReadAbortException e)</span>
        {
<span class="nc" id="L415">            casWriteMetrics.markAbort(e);</span>
<span class="nc" id="L416">            writeMetricsForLevel(consistencyForPaxos).markAbort(e);</span>
<span class="nc" id="L417">            throw e;</span>
        }
<span class="nc" id="L419">        catch (WriteFailureException | ReadFailureException e)</span>
        {
<span class="nc" id="L421">            casWriteMetrics.failures.mark();</span>
<span class="nc" id="L422">            writeMetricsForLevel(consistencyForPaxos).failures.mark();</span>
<span class="nc" id="L423">            throw e;</span>
        }
<span class="nc" id="L425">        catch (UnavailableException e)</span>
        {
<span class="nc" id="L427">            casWriteMetrics.unavailables.mark();</span>
<span class="nc" id="L428">            writeMetricsForLevel(consistencyForPaxos).unavailables.mark();</span>
<span class="nc" id="L429">            throw e;</span>
        }
        finally
        {
<span class="fc" id="L433">            final long latency = nanoTime() - startTimeForMetrics;</span>
<span class="fc" id="L434">            casWriteMetrics.addNano(latency);</span>
<span class="fc" id="L435">            writeMetricsForLevel(consistencyForPaxos).addNano(latency);</span>
        }
    }

    private static void recordCasContention(TableMetadata table,
                                            DecoratedKey key,
                                            CASClientRequestMetrics casMetrics,
                                            int contentions)
    {
<span class="pc bpc" id="L444" title="1 of 2 branches missed.">        if (contentions == 0)</span>
<span class="fc" id="L445">            return;</span>

<span class="nc" id="L447">        casMetrics.contention.update(contentions);</span>
<span class="nc" id="L448">        Keyspace.open(table.keyspace)</span>
<span class="nc" id="L449">                .getColumnFamilyStore(table.name)</span>
                .metric
                .topCasPartitionContention
<span class="nc" id="L452">                .addSample(key.getKey(), contentions);</span>
<span class="nc" id="L453">    }</span>

    /**
     * Performs the Paxos rounds for a given proposal, retrying when preempted until the timeout.
     *
     * &lt;p&gt;The main 'configurable' of this method is the {@code createUpdateProposal} method: it is called by the method
     * once a ballot has been successfully 'prepared' to generate the update to 'propose' (and commit if the proposal is
     * successful). That method also generates the result that the whole method will return. Note that due to retrying,
     * this method may be called multiple times and does not have to return the same results.
     *
     * @param metadata the table to update with Paxos.
     * @param key the partition updated.
     * @param consistencyForPaxos the serial consistency of the operation (either {@link ConsistencyLevel#SERIAL} or
     *     {@link ConsistencyLevel#LOCAL_SERIAL}).
     * @param consistencyForReplayCommits the consistency for the commit phase of &quot;replayed&quot; in-progress operations.
     * @param consistencyForCommit the consistency for the commit phase of _this_ operation update.
     * @param queryStartNanoTime the nano time for the start of the query this is part of. This is the base time for
     *     timeouts.
     * @param casMetrics the metrics to update for this operation.
     * @param createUpdateProposal method called after a successful 'prepare' phase to obtain 1) the actual update of
     *     this operation and 2) the result that the whole method should return. This can return {@code null} in the
     *     special where, after having &quot;prepared&quot; (and thus potentially replayed in-progress upgdates), we don't want
     *     to propose anything (the whole method then return {@code null}).
     * @return the second element of the pair returned by {@code createUpdateProposal} (for the last call of that method
     *     if that method is called multiple times due to retries).
     */
    private static RowIterator doPaxos(TableMetadata metadata,
                                       DecoratedKey key,
                                       ConsistencyLevel consistencyForPaxos,
                                       ConsistencyLevel consistencyForReplayCommits,
                                       ConsistencyLevel consistencyForCommit,
                                       long queryStartNanoTime,
                                       CASClientRequestMetrics casMetrics,
                                       Function&lt;Ballot, Pair&lt;PartitionUpdate, RowIterator&gt;&gt; createUpdateProposal)
    throws UnavailableException, IsBootstrappingException, RequestFailureException, RequestTimeoutException, InvalidRequestException
    {
<span class="fc" id="L489">        int contentions = 0;</span>
<span class="fc" id="L490">        Keyspace keyspace = Keyspace.open(metadata.keyspace);</span>
<span class="fc" id="L491">        AbstractReplicationStrategy latestRs = keyspace.getReplicationStrategy();</span>
        try
        {
<span class="fc" id="L494">            consistencyForPaxos.validateForCas();</span>
<span class="fc" id="L495">            consistencyForReplayCommits.validateForCasCommit(latestRs);</span>
<span class="fc" id="L496">            consistencyForCommit.validateForCasCommit(latestRs);</span>

<span class="fc" id="L498">            long timeoutNanos = DatabaseDescriptor.getCasContentionTimeout(NANOSECONDS);</span>
<span class="pc bpc" id="L499" title="1 of 2 branches missed.">            while (nanoTime() - queryStartNanoTime &lt; timeoutNanos)</span>
            {
                // for simplicity, we'll do a single liveness check at the start of each attempt
<span class="fc" id="L502">                ReplicaPlan.ForPaxosWrite replicaPlan = ReplicaPlans.forPaxos(keyspace, key, consistencyForPaxos);</span>
<span class="fc" id="L503">                latestRs = replicaPlan.replicationStrategy();</span>
<span class="fc" id="L504">                PaxosBallotAndContention pair = beginAndRepairPaxos(queryStartNanoTime,</span>
                                                                    key,
                                                                    metadata,
                                                                    replicaPlan,
                                                                    consistencyForPaxos,
                                                                    consistencyForReplayCommits,
                                                                    casMetrics);

<span class="fc" id="L512">                final Ballot ballot = pair.ballot;</span>
<span class="fc" id="L513">                contentions += pair.contentions;</span>

<span class="fc" id="L515">                Pair&lt;PartitionUpdate, RowIterator&gt; proposalPair = createUpdateProposal.apply(ballot);</span>
                // See method javadoc: null here is code for &quot;stop here and return null&quot;.
<span class="pc bpc" id="L517" title="1 of 2 branches missed.">                if (proposalPair == null)</span>
<span class="nc" id="L518">                    return null;</span>

<span class="fc" id="L520">                Commit proposal = Commit.newProposal(ballot, proposalPair.left);</span>
<span class="fc" id="L521">                Tracing.trace(&quot;CAS precondition is met; proposing client-requested updates for {}&quot;, ballot);</span>
<span class="pc bpc" id="L522" title="1 of 2 branches missed.">                if (proposePaxos(proposal, replicaPlan, true, queryStartNanoTime))</span>
                {
                    // We skip committing accepted updates when they are empty. This is an optimization which works
                    // because we also skip replaying those same empty update in beginAndRepairPaxos (see the longer
                    // comment there). As empty update are somewhat common (serial reads and non-applying CAS propose
                    // them), this is worth bothering.
<span class="fc bfc" id="L528" title="All 2 branches covered.">                    if (!proposal.update.isEmpty())</span>
<span class="fc" id="L529">                        commitPaxos(proposal, consistencyForCommit, true, queryStartNanoTime);</span>
<span class="fc" id="L530">                    RowIterator result = proposalPair.right;</span>
<span class="fc bfc" id="L531" title="All 2 branches covered.">                    if (result != null)</span>
<span class="fc" id="L532">                        Tracing.trace(&quot;CAS did not apply&quot;);</span>
                    else
<span class="fc" id="L534">                        Tracing.trace(&quot;CAS applied successfully&quot;);</span>
<span class="fc" id="L535">                    return result;</span>
                }

<span class="nc" id="L538">                Tracing.trace(&quot;Paxos proposal not accepted (pre-empted by a higher ballot)&quot;);</span>
<span class="nc" id="L539">                contentions++;</span>

<span class="nc" id="L541">                Uninterruptibles.sleepUninterruptibly(ThreadLocalRandom.current().nextInt(100), TimeUnit.MILLISECONDS);</span>
                // continue to retry
<span class="nc" id="L543">            }</span>
        }
<span class="nc" id="L545">        catch (CasWriteTimeoutException e)</span>
        {
            // Might be thrown by beginRepairAndPaxos. In that case, any contention that happened within the method and
            // led up to the timeout was not accounted in our local 'contentions' variable and we add it now so it the
            // contention recorded in the finally is correct.
<span class="nc" id="L550">            contentions += e.contentions;</span>
<span class="nc" id="L551">            throw e;</span>
        }
<span class="nc" id="L553">        catch (WriteTimeoutException e)</span>
        {
            // Might be thrown by proposePaxos or commitPaxos
<span class="nc" id="L556">            throw new CasWriteTimeoutException(e.writeType, e.consistency, e.received, e.blockFor, contentions);</span>
        }
        finally
        {
<span class="fc" id="L560">            recordCasContention(metadata, key, casMetrics, contentions);</span>
        }

<span class="nc" id="L563">        throw new CasWriteTimeoutException(WriteType.CAS, consistencyForPaxos, 0, consistencyForPaxos.blockFor(latestRs), contentions);</span>
    }

    /**
     * begin a Paxos session by sending a prepare request and completing any in-progress requests seen in the replies
     *
     * @return the Paxos ballot promised by the replicas if no in-progress requests were seen and a quorum of
     * nodes have seen the mostRecentCommit.  Otherwise, return null.
     */
    private static PaxosBallotAndContention beginAndRepairPaxos(long queryStartNanoTime,
                                                                DecoratedKey key,
                                                                TableMetadata metadata,
                                                                ReplicaPlan.ForPaxosWrite paxosPlan,
                                                                ConsistencyLevel consistencyForPaxos,
                                                                ConsistencyLevel consistencyForCommit,
                                                                CASClientRequestMetrics casMetrics)
    throws WriteTimeoutException, WriteFailureException
    {
<span class="fc" id="L581">        long timeoutNanos = DatabaseDescriptor.getCasContentionTimeout(NANOSECONDS);</span>

<span class="fc" id="L583">        PrepareCallback summary = null;</span>
<span class="fc" id="L584">        int contentions = 0;</span>
<span class="pc bpc" id="L585" title="1 of 2 branches missed.">        while (nanoTime() - queryStartNanoTime &lt; timeoutNanos)</span>
        {
            // We want a timestamp that is guaranteed to be unique for that node (so that the ballot is globally unique), but if we've got a prepare rejected
            // already we also want to make sure we pick a timestamp that has a chance to be promised, i.e. one that is greater that the most recently known
            // in progress (#5667). Lastly, we don't want to use a timestamp that is older than the last one assigned by ClientState or operations may appear
            // out-of-order (#7801).
<span class="fc bfc" id="L591" title="All 2 branches covered.">            long minTimestampMicrosToUse = summary == null ? Long.MIN_VALUE : 1 + summary.mostRecentInProgressCommit.ballot.unixMicros();</span>
            // Note that ballotMicros is not guaranteed to be unique if two proposal are being handled concurrently by the same coordinator. But we still
            // need ballots to be unique for each proposal so we have to use getRandomTimeUUIDFromMicros.
<span class="pc bpc" id="L594" title="1 of 2 branches missed.">            Ballot ballot = nextBallot(minTimestampMicrosToUse, consistencyForPaxos == SERIAL ? GLOBAL : LOCAL);</span>

            // prepare
            try
            {
<span class="fc" id="L599">                Tracing.trace(&quot;Preparing {}&quot;, ballot);</span>
<span class="fc" id="L600">                Commit toPrepare = Commit.newPrepare(key, metadata, ballot);</span>
<span class="fc" id="L601">                summary = preparePaxos(toPrepare, paxosPlan, queryStartNanoTime);</span>
<span class="pc bpc" id="L602" title="1 of 2 branches missed.">                if (!summary.promised)</span>
                {
<span class="nc" id="L604">                    Tracing.trace(&quot;Some replicas have already promised a higher ballot than ours; aborting&quot;);</span>
<span class="nc" id="L605">                    contentions++;</span>
                    // sleep a random amount to give the other proposer a chance to finish
<span class="nc" id="L607">                    Uninterruptibles.sleepUninterruptibly(ThreadLocalRandom.current().nextInt(100), MILLISECONDS);</span>
<span class="nc" id="L608">                    continue;</span>
                }

<span class="fc" id="L611">                Commit inProgress = summary.mostRecentInProgressCommit;</span>
<span class="fc" id="L612">                Commit mostRecent = summary.mostRecentCommit;</span>

                // If we have an in-progress ballot greater than the MRC we know, then it's an in-progress round that
                // needs to be completed, so do it.
                // One special case we make is for update that are empty (which are proposed by serial reads and
                // non-applying CAS). While we could handle those as any other updates, we can optimize this somewhat by
                // neither committing those empty updates, nor replaying in-progress ones. The reasoning is this: as the
                // update is empty, we have nothing to apply to storage in the commit phase, so the only reason to commit
                // would be to update the MRC. However, if we skip replaying those empty updates, then we don't need to
                // update the MRC for following updates to make progress (that is, if we didn't had the empty update skip
                // below _but_ skipped updating the MRC on empty updates, then we'd be stuck always proposing that same
                // empty update). And the reason skipping that replay is safe is that when an operation tries to propose
                // an empty value, there can be only 2 cases:
                //  1) the propose succeed, meaning a quorum of nodes accept it, in which case we are guaranteed no earlier
                //     pending operation can ever be replayed (which is what we want to guarantee with the empty update).
                //  2) the propose does not succeed. But then the operation proposing the empty update will not succeed
                //     either (it will retry or ultimately timeout), and we're actually ok if earlier pending operation gets
                //     replayed in that case.
                // Tl;dr, it is safe to skip committing empty updates _as long as_ we also skip replying them below. And
                // doing is more efficient, so we do so.
<span class="pc bpc" id="L632" title="1 of 4 branches missed.">                if (!inProgress.update.isEmpty() &amp;&amp; inProgress.isAfter(mostRecent))</span>
                {
<span class="nc" id="L634">                    Tracing.trace(&quot;Finishing incomplete paxos round {}&quot;, inProgress);</span>
<span class="nc" id="L635">                    casMetrics.unfinishedCommit.inc();</span>
<span class="nc" id="L636">                    Commit refreshedInProgress = Commit.newProposal(ballot, inProgress.update);</span>
<span class="nc bnc" id="L637" title="All 2 branches missed.">                    if (proposePaxos(refreshedInProgress, paxosPlan, false, queryStartNanoTime))</span>
                    {
<span class="nc" id="L639">                        commitPaxos(refreshedInProgress, consistencyForCommit, false, queryStartNanoTime);</span>
                    }
                    else
                    {
<span class="nc" id="L643">                        Tracing.trace(&quot;Some replicas have already promised a higher ballot than ours; aborting&quot;);</span>
                        // sleep a random amount to give the other proposer a chance to finish
<span class="nc" id="L645">                        contentions++;</span>
<span class="nc" id="L646">                        Uninterruptibles.sleepUninterruptibly(ThreadLocalRandom.current().nextInt(100), MILLISECONDS);</span>
                    }
<span class="nc" id="L648">                    continue;</span>
                }

                // To be able to propose our value on a new round, we need a quorum of replica to have learn the previous one. Why is explained at:
                // https://issues.apache.org/jira/browse/CASSANDRA-5062?focusedCommentId=13619810&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13619810)
                // Since we waited for quorum nodes, if some of them haven't seen the last commit (which may just be a timing issue, but may also
                // mean we lost messages), we pro-actively &quot;repair&quot; those nodes, and retry.
<span class="fc" id="L655">                Iterable&lt;InetAddressAndPort&gt; missingMRC = summary.replicasMissingMostRecentCommit();</span>
<span class="fc bfc" id="L656" title="All 2 branches covered.">                if (Iterables.size(missingMRC) &gt; 0)</span>
                {
<span class="fc" id="L658">                    Tracing.trace(&quot;Repairing replicas that missed the most recent commit&quot;);</span>
<span class="fc" id="L659">                    sendCommit(mostRecent, missingMRC);</span>
                    // TODO: provided commits don't invalid the prepare we just did above (which they don't), we could just wait
                    // for all the missingMRC to acknowledge this commit and then move on with proposing our value. But that means
                    // adding the ability to have commitPaxos block, which is exactly CASSANDRA-5442 will do. So once we have that
                    // latter ticket, we can pass CL.ALL to the commit above and remove the 'continue'.
<span class="fc" id="L664">                    continue;</span>
                }

<span class="fc" id="L667">                return new PaxosBallotAndContention(ballot, contentions);</span>
            }
<span class="nc" id="L669">            catch (WriteTimeoutException e)</span>
            {
                // We're still doing preparation for the paxos rounds, so we want to use the CAS (see CASSANDRA-8672)
<span class="nc" id="L672">                throw new CasWriteTimeoutException(WriteType.CAS, e.consistency, e.received, e.blockFor, contentions);</span>
            }
        }

<span class="nc" id="L676">        throw new CasWriteTimeoutException(WriteType.CAS, consistencyForPaxos, 0, consistencyForPaxos.blockFor(paxosPlan.replicationStrategy()), contentions);</span>
    }

    /**
     * Unlike commitPaxos, this does not wait for replies
     */
    private static void sendCommit(Commit commit, Iterable&lt;InetAddressAndPort&gt; replicas)
    {
<span class="fc" id="L684">        Message&lt;Commit&gt; message = Message.out(PAXOS_COMMIT_REQ, commit);</span>
<span class="fc bfc" id="L685" title="All 2 branches covered.">        for (InetAddressAndPort target : replicas)</span>
<span class="fc" id="L686">            MessagingService.instance().send(message, target);</span>
<span class="fc" id="L687">    }</span>

    private static PrepareCallback preparePaxos(Commit toPrepare, ReplicaPlan.ForPaxosWrite replicaPlan, long queryStartNanoTime)
    throws WriteTimeoutException
    {
<span class="fc" id="L692">        PrepareCallback callback = new PrepareCallback(toPrepare.update.partitionKey(), toPrepare.update.metadata(), replicaPlan.requiredParticipants(), replicaPlan.consistencyLevel(), queryStartNanoTime);</span>
<span class="fc" id="L693">        Message&lt;Commit&gt; message = Message.out(PAXOS_PREPARE_REQ, toPrepare);</span>

<span class="fc" id="L695">        boolean hasLocalRequest = false;</span>

<span class="fc bfc" id="L697" title="All 2 branches covered.">        for (Replica replica: replicaPlan.contacts())</span>
        {
<span class="fc bfc" id="L699" title="All 2 branches covered.">            if (replica.isSelf())</span>
            {
<span class="fc" id="L701">                hasLocalRequest = true;</span>
<span class="fc" id="L702">                PAXOS_PREPARE_REQ.stage.execute(() -&gt; {</span>
                    try
                    {
<span class="fc" id="L705">                        callback.onResponse(message.responseWith(doPrepare(toPrepare)));</span>
                    }
<span class="nc" id="L707">                    catch (Exception ex)</span>
                    {
<span class="nc" id="L709">                        logger.error(&quot;Failed paxos prepare locally&quot;, ex);</span>
<span class="fc" id="L710">                    }</span>
<span class="fc" id="L711">                });</span>
            }
            else
            {
<span class="fc" id="L715">                MessagingService.instance().sendWithCallback(message, replica.endpoint(), callback);</span>
            }
<span class="fc" id="L717">        }</span>

<span class="fc bfc" id="L719" title="All 2 branches covered.">        if (hasLocalRequest)</span>
<span class="fc" id="L720">            writeMetrics.localRequests.mark();</span>
        else
<span class="fc" id="L722">            writeMetrics.remoteRequests.mark();</span>

<span class="fc" id="L724">        callback.await();</span>
<span class="fc" id="L725">        return callback;</span>
    }

    /**
     * Propose the {@param proposal} accoding to the {@param replicaPlan}.
     * When {@param backoffIfPartial} is true, the proposer backs off when seeing the proposal being accepted by some but not a quorum.
     * The result of the cooresponding CAS in uncertain as the accepted proposal may or may not be spread to other nodes in later rounds.
     */
    private static boolean proposePaxos(Commit proposal, ReplicaPlan.ForPaxosWrite replicaPlan, boolean backoffIfPartial, long queryStartNanoTime)
    throws WriteTimeoutException, CasWriteUnknownResultException
    {
<span class="pc bpc" id="L736" title="1 of 2 branches missed.">        ProposeCallback callback = new ProposeCallback(replicaPlan.contacts().size(), replicaPlan.requiredParticipants(), !backoffIfPartial, replicaPlan.consistencyLevel(), queryStartNanoTime);</span>
<span class="fc" id="L737">        Message&lt;Commit&gt; message = Message.out(PAXOS_PROPOSE_REQ, proposal);</span>
<span class="fc bfc" id="L738" title="All 2 branches covered.">        for (Replica replica : replicaPlan.contacts())</span>
        {
<span class="fc bfc" id="L740" title="All 2 branches covered.">            if (replica.isSelf())</span>
            {
<span class="fc" id="L742">                PAXOS_PROPOSE_REQ.stage.execute(() -&gt; {</span>
                    try
                    {
<span class="fc" id="L745">                        Message&lt;Boolean&gt; response = message.responseWith(doPropose(proposal));</span>
<span class="fc" id="L746">                        callback.onResponse(response);</span>
                    }
<span class="nc" id="L748">                    catch (Exception ex)</span>
                    {
<span class="nc" id="L750">                        logger.error(&quot;Failed paxos propose locally&quot;, ex);</span>
<span class="fc" id="L751">                    }</span>
<span class="fc" id="L752">                });</span>
            }
            else
            {
<span class="fc" id="L756">                MessagingService.instance().sendWithCallback(message, replica.endpoint(), callback);</span>
            }
<span class="fc" id="L758">        }</span>
<span class="fc" id="L759">        callback.await();</span>

<span class="pc bpc" id="L761" title="1 of 2 branches missed.">        if (callback.isSuccessful())</span>
<span class="fc" id="L762">            return true;</span>

<span class="nc bnc" id="L764" title="All 4 branches missed.">        if (backoffIfPartial &amp;&amp; !callback.isFullyRefused())</span>
<span class="nc" id="L765">            throw new CasWriteUnknownResultException(replicaPlan.consistencyLevel(), callback.getAcceptCount(), replicaPlan.requiredParticipants());</span>

<span class="nc" id="L767">        return false;</span>
    }

    private static void commitPaxos(Commit proposal, ConsistencyLevel consistencyLevel, boolean allowHints, long queryStartNanoTime) throws WriteTimeoutException
    {
<span class="pc bpc" id="L772" title="1 of 2 branches missed.">        boolean shouldBlock = consistencyLevel != ConsistencyLevel.ANY;</span>
<span class="fc" id="L773">        Keyspace keyspace = Keyspace.open(proposal.update.metadata().keyspace);</span>

<span class="fc" id="L775">        Token tk = proposal.update.partitionKey().getToken();</span>

<span class="fc" id="L777">        AbstractWriteResponseHandler&lt;Commit&gt; responseHandler = null;</span>
        // NOTE: this ReplicaPlan is a lie, this usage of ReplicaPlan could do with being clarified - the selected() collection is essentially (I think) never used
<span class="fc" id="L779">        ReplicaPlan.ForWrite replicaPlan = ReplicaPlans.forWrite(keyspace, consistencyLevel, tk, ReplicaPlans.writeAll);</span>
<span class="pc bpc" id="L780" title="1 of 2 branches missed.">        if (shouldBlock)</span>
        {
<span class="fc" id="L782">            AbstractReplicationStrategy rs = replicaPlan.replicationStrategy();</span>
<span class="fc" id="L783">            responseHandler = rs.getWriteResponseHandler(replicaPlan, null, WriteType.SIMPLE, proposal::makeMutation, queryStartNanoTime);</span>
        }

<span class="fc" id="L786">        Message&lt;Commit&gt; message = Message.outWithFlag(PAXOS_COMMIT_REQ, proposal, MessageFlag.CALL_BACK_ON_FAILURE);</span>
<span class="fc bfc" id="L787" title="All 2 branches covered.">        for (Replica replica : replicaPlan.liveAndDown())</span>
        {
<span class="fc" id="L789">            InetAddressAndPort destination = replica.endpoint();</span>
<span class="fc" id="L790">            checkHintOverload(replica);</span>

<span class="pc bpc" id="L792" title="1 of 2 branches missed.">            if (replicaPlan.isAlive(replica))</span>
            {
<span class="pc bpc" id="L794" title="1 of 2 branches missed.">                if (shouldBlock)</span>
                {
<span class="fc bfc" id="L796" title="All 2 branches covered.">                    if (replica.isSelf())</span>
<span class="fc" id="L797">                        commitPaxosLocal(replica, message, responseHandler);</span>
                    else
<span class="fc" id="L799">                        MessagingService.instance().sendWriteWithCallback(message, replica, responseHandler);</span>
                }
                else
                {
<span class="nc" id="L803">                    MessagingService.instance().send(message, destination);</span>
                }
            }
            else
            {
<span class="nc bnc" id="L808" title="All 2 branches missed.">                if (responseHandler != null)</span>
                {
<span class="nc" id="L810">                    responseHandler.expired();</span>
                }
<span class="nc bnc" id="L812" title="All 4 branches missed.">                if (allowHints &amp;&amp; shouldHint(replica))</span>
                {
<span class="nc" id="L814">                    submitHint(proposal.makeMutation(), replica, null);</span>
                }
            }
<span class="fc" id="L817">        }</span>

<span class="pc bpc" id="L819" title="1 of 2 branches missed.">        if (shouldBlock)</span>
<span class="fc" id="L820">            responseHandler.get();</span>
<span class="fc" id="L821">    }</span>

    /**
     * Commit a PAXOS task locally, and if the task times out rather then submitting a real hint
     * submit a fake one that executes immediately on the mutation stage, but generates the necessary backpressure
     * signal for hints
     */
    private static void commitPaxosLocal(Replica localReplica, final Message&lt;Commit&gt; message, final AbstractWriteResponseHandler&lt;?&gt; responseHandler)
    {
<span class="fc" id="L830">        PAXOS_COMMIT_REQ.stage.maybeExecuteImmediately(new LocalMutationRunnable(localReplica)</span>
<span class="fc" id="L831">        {</span>
            public void runMayThrow()
            {
                try
                {
<span class="fc" id="L836">                    PaxosState.commitDirect(message.payload);</span>
<span class="pc bpc" id="L837" title="1 of 2 branches missed.">                    if (responseHandler != null)</span>
<span class="fc" id="L838">                        responseHandler.onResponse(null);</span>
                }
<span class="nc" id="L840">                catch (Exception ex)</span>
                {
<span class="nc bnc" id="L842" title="All 2 branches missed.">                    if (!(ex instanceof WriteTimeoutException))</span>
<span class="nc" id="L843">                        logger.error(&quot;Failed to apply paxos commit locally : &quot;, ex);</span>
<span class="nc" id="L844">                    responseHandler.onFailure(FBUtilities.getBroadcastAddressAndPort(), RequestFailureReason.forException(ex));</span>
<span class="fc" id="L845">                }</span>
<span class="fc" id="L846">            }</span>

            @Override
            public String description()
            {
<span class="nc" id="L851">                return &quot;Paxos &quot; + message.payload.toString();</span>
            }

            @Override
            protected Verb verb()
            {
<span class="fc" id="L857">                return PAXOS_COMMIT_REQ;</span>
            }
        });
<span class="fc" id="L860">    }</span>

    /**
     * Use this method to have these Mutations applied
     * across all replicas. This method will take care
     * of the possibility of a replica being down and hint
     * the data across to some other replica.
     *
     * @param mutations the mutations to be applied across the replicas
     * @param consistencyLevel the consistency level for the operation
     * @param queryStartNanoTime the value of nanoTime() when the query started to be processed
     */
    public static void mutate(List&lt;? extends IMutation&gt; mutations, ConsistencyLevel consistencyLevel, long queryStartNanoTime)
    throws UnavailableException, OverloadedException, WriteTimeoutException, WriteFailureException
    {
<span class="fc" id="L875">        Tracing.trace(&quot;Determining replicas for mutation&quot;);</span>
<span class="fc" id="L876">        final String localDataCenter = DatabaseDescriptor.getEndpointSnitch().getLocalDatacenter();</span>

<span class="fc" id="L878">        long startTime = nanoTime();</span>

<span class="fc" id="L880">        List&lt;AbstractWriteResponseHandler&lt;IMutation&gt;&gt; responseHandlers = new ArrayList&lt;&gt;(mutations.size());</span>
<span class="fc bfc" id="L881" title="All 2 branches covered.">        WriteType plainWriteType = mutations.size() &lt;= 1 ? WriteType.SIMPLE : WriteType.UNLOGGED_BATCH;</span>

        try
        {
<span class="fc bfc" id="L885" title="All 2 branches covered.">            for (IMutation mutation : mutations)</span>
            {
<span class="fc bfc" id="L887" title="All 2 branches covered.">                if (mutation instanceof CounterMutation)</span>
<span class="fc" id="L888">                    responseHandlers.add(mutateCounter((CounterMutation)mutation, localDataCenter, queryStartNanoTime));</span>
                else
<span class="fc" id="L890">                    responseHandlers.add(performWrite(mutation, consistencyLevel, localDataCenter, standardWritePerformer, null, plainWriteType, queryStartNanoTime));</span>
<span class="fc" id="L891">            }</span>

            // upgrade to full quorum any failed cheap quorums
<span class="fc bfc" id="L894" title="All 2 branches covered.">            for (int i = 0 ; i &lt; mutations.size() ; ++i)</span>
            {
<span class="fc bfc" id="L896" title="All 2 branches covered.">                if (!(mutations.get(i) instanceof CounterMutation)) // at the moment, only non-counter writes support cheap quorums</span>
<span class="fc" id="L897">                    responseHandlers.get(i).maybeTryAdditionalReplicas(mutations.get(i), standardWritePerformer, localDataCenter);</span>
            }

            // wait for writes.  throws TimeoutException if necessary
<span class="fc bfc" id="L901" title="All 2 branches covered.">            for (AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler : responseHandlers)</span>
<span class="fc" id="L902">                responseHandler.get();</span>
        }
<span class="nc" id="L904">        catch (WriteTimeoutException|WriteFailureException ex)</span>
        {
<span class="nc bnc" id="L906" title="All 2 branches missed.">            if (consistencyLevel == ConsistencyLevel.ANY)</span>
            {
<span class="nc" id="L908">                hintMutations(mutations);</span>
            }
            else
            {
<span class="nc bnc" id="L912" title="All 2 branches missed.">                if (ex instanceof WriteFailureException)</span>
                {
<span class="nc" id="L914">                    writeMetrics.failures.mark();</span>
<span class="nc" id="L915">                    writeMetricsForLevel(consistencyLevel).failures.mark();</span>
<span class="nc" id="L916">                    WriteFailureException fe = (WriteFailureException)ex;</span>
<span class="nc" id="L917">                    Tracing.trace(&quot;Write failure; received {} of {} required replies, failed {} requests&quot;,</span>
<span class="nc" id="L918">                                  fe.received, fe.blockFor, fe.failureReasonByEndpoint.size());</span>
<span class="nc" id="L919">                }</span>
                else
                {
<span class="nc" id="L922">                    writeMetrics.timeouts.mark();</span>
<span class="nc" id="L923">                    writeMetricsForLevel(consistencyLevel).timeouts.mark();</span>
<span class="nc" id="L924">                    WriteTimeoutException te = (WriteTimeoutException)ex;</span>
<span class="nc" id="L925">                    Tracing.trace(&quot;Write timeout; received {} of {} required replies&quot;, te.received, te.blockFor);</span>
                }
<span class="nc" id="L927">                throw ex;</span>
            }
        }
<span class="nc" id="L930">        catch (UnavailableException e)</span>
        {
<span class="nc" id="L932">            writeMetrics.unavailables.mark();</span>
<span class="nc" id="L933">            writeMetricsForLevel(consistencyLevel).unavailables.mark();</span>
<span class="nc" id="L934">            Tracing.trace(&quot;Unavailable&quot;);</span>
<span class="nc" id="L935">            throw e;</span>
        }
<span class="nc" id="L937">        catch (OverloadedException e)</span>
        {
<span class="nc" id="L939">            writeMetrics.unavailables.mark();</span>
<span class="nc" id="L940">            writeMetricsForLevel(consistencyLevel).unavailables.mark();</span>
<span class="nc" id="L941">            Tracing.trace(&quot;Overloaded&quot;);</span>
<span class="nc" id="L942">            throw e;</span>
        }
        finally
        {
<span class="fc" id="L946">            long latency = nanoTime() - startTime;</span>
<span class="fc" id="L947">            writeMetrics.addNano(latency);</span>
<span class="fc" id="L948">            writeMetricsForLevel(consistencyLevel).addNano(latency);</span>
<span class="fc" id="L949">            updateCoordinatorWriteLatencyTableMetric(mutations, latency);</span>
        }
<span class="fc" id="L951">    }</span>

    /**
     * Hint all the mutations (except counters, which can't be safely retried).  This means
     * we'll re-hint any successful ones; doesn't seem worth it to track individual success
     * just for this unusual case.
     *
     * Only used for CL.ANY
     *
     * @param mutations the mutations that require hints
     */
    private static void hintMutations(Collection&lt;? extends IMutation&gt; mutations)
    {
<span class="nc bnc" id="L964" title="All 2 branches missed.">        for (IMutation mutation : mutations)</span>
<span class="nc bnc" id="L965" title="All 2 branches missed.">            if (!(mutation instanceof CounterMutation))</span>
<span class="nc" id="L966">                hintMutation((Mutation) mutation);</span>

<span class="nc" id="L968">        Tracing.trace(&quot;Wrote hints to satisfy CL.ANY after no replicas acknowledged the write&quot;);</span>
<span class="nc" id="L969">    }</span>

    private static void hintMutation(Mutation mutation)
    {
<span class="nc" id="L973">        String keyspaceName = mutation.getKeyspaceName();</span>
<span class="nc" id="L974">        Token token = mutation.key().getToken();</span>

        // local writes can timeout, but cannot be dropped (see LocalMutationRunnable and CASSANDRA-6510),
        // so there is no need to hint or retry.
<span class="nc" id="L978">        EndpointsForToken replicasToHint = ReplicaLayout.forTokenWriteLiveAndDown(Keyspace.open(keyspaceName), token)</span>
<span class="nc" id="L979">                .all()</span>
<span class="nc" id="L980">                .filter(StorageProxy::shouldHint);</span>

<span class="nc" id="L982">        submitHint(mutation, replicasToHint, null);</span>
<span class="nc" id="L983">    }</span>

    public boolean appliesLocally(Mutation mutation)
    {
<span class="fc" id="L987">        String keyspaceName = mutation.getKeyspaceName();</span>
<span class="fc" id="L988">        Token token = mutation.key().getToken();</span>
<span class="fc" id="L989">        InetAddressAndPort local = FBUtilities.getBroadcastAddressAndPort();</span>

<span class="fc" id="L991">        return ReplicaLayout.forTokenWriteLiveAndDown(Keyspace.open(keyspaceName), token)</span>
<span class="fc" id="L992">                .all().endpoints().contains(local);</span>
    }

    /**
     * Use this method to have these Mutations applied
     * across all replicas.
     *
     * @param mutations the mutations to be applied across the replicas
     * @param writeCommitLog if commitlog should be written
     * @param baseComplete time from epoch in ms that the local base mutation was(or will be) completed
     * @param queryStartNanoTime the value of nanoTime() when the query started to be processed
     */
    public static void mutateMV(ByteBuffer dataKey, Collection&lt;Mutation&gt; mutations, boolean writeCommitLog, AtomicLong baseComplete, long queryStartNanoTime)
    throws UnavailableException, OverloadedException, WriteTimeoutException
    {
<span class="nc" id="L1007">        Tracing.trace(&quot;Determining replicas for mutation&quot;);</span>
<span class="nc" id="L1008">        final String localDataCenter = DatabaseDescriptor.getEndpointSnitch().getLocalDatacenter();</span>

<span class="nc" id="L1010">        long startTime = nanoTime();</span>


        try
        {
            // if we haven't joined the ring, write everything to batchlog because paired replicas may be stale
<span class="nc" id="L1016">            final TimeUUID batchUUID = nextTimeUUID();</span>

<span class="nc bnc" id="L1018" title="All 6 branches missed.">            if (StorageService.instance.isStarting() || StorageService.instance.isJoining() || StorageService.instance.isMoving())</span>
            {
<span class="nc" id="L1020">                BatchlogManager.store(Batch.createLocal(batchUUID, FBUtilities.timestampMicros(),</span>
                                                        mutations), writeCommitLog);
            }
            else
            {
<span class="nc" id="L1025">                List&lt;WriteResponseHandlerWrapper&gt; wrappers = new ArrayList&lt;&gt;(mutations.size());</span>
                //non-local mutations rely on the base mutation commit-log entry for eventual consistency
<span class="nc" id="L1027">                Set&lt;Mutation&gt; nonLocalMutations = new HashSet&lt;&gt;(mutations);</span>
<span class="nc" id="L1028">                Token baseToken = StorageService.instance.getTokenMetadata().partitioner.getToken(dataKey);</span>

<span class="nc" id="L1030">                ConsistencyLevel consistencyLevel = ConsistencyLevel.ONE;</span>

                //Since the base -&gt; view replication is 1:1 we only need to store the BL locally
<span class="nc" id="L1033">                ReplicaPlan.ForWrite replicaPlan = ReplicaPlans.forLocalBatchlogWrite();</span>
<span class="nc" id="L1034">                BatchlogCleanup cleanup = new BatchlogCleanup(mutations.size(),</span>
<span class="nc" id="L1035">                                                              () -&gt; asyncRemoveFromBatchlog(replicaPlan, batchUUID));</span>

                // add a handler for each mutation - includes checking availability, but doesn't initiate any writes, yet
<span class="nc bnc" id="L1038" title="All 2 branches missed.">                for (Mutation mutation : mutations)</span>
                {
<span class="nc" id="L1040">                    String keyspaceName = mutation.getKeyspaceName();</span>
<span class="nc" id="L1041">                    Token tk = mutation.key().getToken();</span>
<span class="nc" id="L1042">                    AbstractReplicationStrategy replicationStrategy = Keyspace.open(keyspaceName).getReplicationStrategy();</span>
<span class="nc" id="L1043">                    Optional&lt;Replica&gt; pairedEndpoint = ViewUtils.getViewNaturalEndpoint(replicationStrategy, baseToken, tk);</span>
<span class="nc" id="L1044">                    EndpointsForToken pendingReplicas = StorageService.instance.getTokenMetadata().pendingEndpointsForToken(tk, keyspaceName);</span>

                    // if there are no paired endpoints there are probably range movements going on, so we write to the local batchlog to replay later
<span class="nc bnc" id="L1047" title="All 2 branches missed.">                    if (!pairedEndpoint.isPresent())</span>
                    {
<span class="nc bnc" id="L1049" title="All 2 branches missed.">                        if (pendingReplicas.isEmpty())</span>
<span class="nc" id="L1050">                            logger.warn(&quot;Received base materialized view mutation for key {} that does not belong &quot; +</span>
                                        &quot;to this node. There is probably a range movement happening (move or decommission),&quot; +
                                        &quot;but this node hasn't updated its ring metadata yet. Adding mutation to &quot; +
                                        &quot;local batchlog to be replayed later.&quot;,
<span class="nc" id="L1054">                                        mutation.key());</span>
                        continue;
                    }

                    // When local node is the endpoint we can just apply the mutation locally,
                    // unless there are pending endpoints, in which case we want to do an ordinary
                    // write so the view mutation is sent to the pending endpoint
<span class="nc bnc" id="L1061" title="All 4 branches missed.">                    if (pairedEndpoint.get().isSelf() &amp;&amp; StorageService.instance.isJoined()</span>
<span class="nc bnc" id="L1062" title="All 2 branches missed.">                        &amp;&amp; pendingReplicas.isEmpty())</span>
                    {
                        try
                        {
<span class="nc" id="L1066">                            mutation.apply(writeCommitLog);</span>
<span class="nc" id="L1067">                            nonLocalMutations.remove(mutation);</span>
                            // won't trigger cleanup
<span class="nc" id="L1069">                            cleanup.decrement();</span>
                        }
<span class="nc" id="L1071">                        catch (Exception exc)</span>
                        {
<span class="nc" id="L1073">                            logger.error(&quot;Error applying local view update: Mutation (keyspace {}, tables {}, partition key {})&quot;,</span>
<span class="nc" id="L1074">                                         mutation.getKeyspaceName(), mutation.getTableIds(), mutation.key());</span>
<span class="nc" id="L1075">                            throw exc;</span>
<span class="nc" id="L1076">                        }</span>
                    }
                    else
                    {
<span class="nc" id="L1080">                        ReplicaLayout.ForTokenWrite liveAndDown = ReplicaLayout.forTokenWrite(replicationStrategy,</span>
<span class="nc" id="L1081">                                                                                              EndpointsForToken.of(tk, pairedEndpoint.get()),</span>
                                                                                              pendingReplicas);
<span class="nc" id="L1083">                        wrappers.add(wrapViewBatchResponseHandler(mutation,</span>
                                                                  consistencyLevel,
                                                                  consistencyLevel,
                                                                  liveAndDown,
                                                                  baseComplete,
                                                                  WriteType.BATCH,
                                                                  cleanup,
                                                                  queryStartNanoTime));
                    }
<span class="nc" id="L1092">                }</span>

                // Apply to local batchlog memtable in this thread
<span class="nc bnc" id="L1095" title="All 2 branches missed.">                if (!nonLocalMutations.isEmpty())</span>
<span class="nc" id="L1096">                    BatchlogManager.store(Batch.createLocal(batchUUID, FBUtilities.timestampMicros(), nonLocalMutations), writeCommitLog);</span>

                // Perform remote writes
<span class="nc bnc" id="L1099" title="All 2 branches missed.">                if (!wrappers.isEmpty())</span>
<span class="nc" id="L1100">                    asyncWriteBatchedMutations(wrappers, localDataCenter, Stage.VIEW_MUTATION);</span>
            }
        }
        finally
        {
<span class="nc" id="L1105">            viewWriteMetrics.addNano(nanoTime() - startTime);</span>
        }
<span class="nc" id="L1107">    }</span>

    @SuppressWarnings(&quot;unchecked&quot;)
    public static void mutateWithTriggers(List&lt;? extends IMutation&gt; mutations,
                                          ConsistencyLevel consistencyLevel,
                                          boolean mutateAtomically,
                                          long queryStartNanoTime)
    throws WriteTimeoutException, WriteFailureException, UnavailableException, OverloadedException, InvalidRequestException
    {
<span class="pc bpc" id="L1116" title="3 of 4 branches missed.">        if (DatabaseDescriptor.getPartitionDenylistEnabled() &amp;&amp; DatabaseDescriptor.getDenylistWritesEnabled())</span>
        {
<span class="nc bnc" id="L1118" title="All 2 branches missed.">            for (final IMutation mutation : mutations)</span>
            {
<span class="nc bnc" id="L1120" title="All 2 branches missed.">                for (final TableId tid : mutation.getTableIds())</span>
                {
<span class="nc bnc" id="L1122" title="All 2 branches missed.">                    if (!partitionDenylist.isKeyPermitted(tid, mutation.key().getKey()))</span>
                    {
<span class="nc" id="L1124">                        denylistMetrics.incrementWritesRejected();</span>
                        // While Schema.instance.getTableMetadata() can return a null value, in this case the isKeyPermitted
                        // call above ensures that we cannot have a null associated tid at this point.
<span class="nc" id="L1127">                        final TableMetadata tmd = Schema.instance.getTableMetadata(tid);</span>
<span class="nc" id="L1128">                        throw new InvalidRequestException(String.format(&quot;Unable to write to denylisted partition [0x%s] in %s/%s&quot;,</span>
<span class="nc" id="L1129">                                                                        mutation.key().toString(), tmd.keyspace, tmd.name));</span>
                    }
<span class="nc" id="L1131">                }</span>
<span class="nc" id="L1132">            }</span>
        }

<span class="fc" id="L1135">        Collection&lt;Mutation&gt; augmented = TriggerExecutor.instance.execute(mutations);</span>

<span class="fc" id="L1137">        boolean updatesView = Keyspace.open(mutations.iterator().next().getKeyspaceName())</span>
                              .viewManager
<span class="fc" id="L1139">                              .updatesAffectView(mutations, true);</span>

<span class="fc" id="L1141">        long size = IMutation.dataSize(mutations);</span>
<span class="fc" id="L1142">        writeMetrics.mutationSize.update(size);</span>
<span class="fc" id="L1143">        writeMetricsForLevel(consistencyLevel).mutationSize.update(size);</span>

<span class="pc bpc" id="L1145" title="1 of 2 branches missed.">        if (augmented != null)</span>
<span class="nc" id="L1146">            mutateAtomically(augmented, consistencyLevel, updatesView, queryStartNanoTime);</span>
        else
        {
<span class="pc bpc" id="L1149" title="1 of 4 branches missed.">            if (mutateAtomically || updatesView)</span>
<span class="fc" id="L1150">                mutateAtomically((Collection&lt;Mutation&gt;) mutations, consistencyLevel, updatesView, queryStartNanoTime);</span>
            else
<span class="fc" id="L1152">                mutate(mutations, consistencyLevel, queryStartNanoTime);</span>
        }
<span class="fc" id="L1154">    }</span>

    /**
     * See mutate. Adds additional steps before and after writing a batch.
     * Before writing the batch (but after doing availability check against the FD for the row replicas):
     *      write the entire batch to a batchlog elsewhere in the cluster.
     * After: remove the batchlog entry (after writing hints for the batch rows, if necessary).
     *
     * @param mutations the Mutations to be applied across the replicas
     * @param consistency_level the consistency level for the operation
     * @param requireQuorumForRemove at least a quorum of nodes will see update before deleting batchlog
     * @param queryStartNanoTime the value of nanoTime() when the query started to be processed
     */
    public static void mutateAtomically(Collection&lt;Mutation&gt; mutations,
                                        ConsistencyLevel consistency_level,
                                        boolean requireQuorumForRemove,
                                        long queryStartNanoTime)
    throws UnavailableException, OverloadedException, WriteTimeoutException
    {
<span class="fc" id="L1173">        Tracing.trace(&quot;Determining replicas for atomic batch&quot;);</span>
<span class="fc" id="L1174">        long startTime = nanoTime();</span>

<span class="fc" id="L1176">        List&lt;WriteResponseHandlerWrapper&gt; wrappers = new ArrayList&lt;&gt;(mutations.size());</span>

<span class="pc bpc" id="L1178" title="1 of 2 branches missed.">        if (mutations.stream().anyMatch(mutation -&gt; Keyspace.open(mutation.getKeyspaceName()).getReplicationStrategy().hasTransientReplicas()))</span>
<span class="nc" id="L1179">            throw new AssertionError(&quot;Logged batches are unsupported with transient replication&quot;);</span>

        try
        {

            // If we are requiring quorum nodes for removal, we upgrade consistency level to QUORUM unless we already
            // require ALL, or EACH_QUORUM. This is so that *at least* QUORUM nodes see the update.
<span class="pc bpc" id="L1186" title="1 of 2 branches missed.">            ConsistencyLevel batchConsistencyLevel = requireQuorumForRemove</span>
<span class="nc" id="L1187">                                                     ? ConsistencyLevel.QUORUM</span>
<span class="fc" id="L1188">                                                     : consistency_level;</span>

<span class="fc bfc" id="L1190" title="All 2 branches covered.">            switch (consistency_level)</span>
            {
                case ALL:
                case EACH_QUORUM:
<span class="fc" id="L1194">                    batchConsistencyLevel = consistency_level;</span>
            }

<span class="pc bpc" id="L1197" title="1 of 2 branches missed.">            ReplicaPlan.ForWrite replicaPlan = ReplicaPlans.forBatchlogWrite(batchConsistencyLevel == ConsistencyLevel.ANY);</span>

<span class="fc" id="L1199">            final TimeUUID batchUUID = nextTimeUUID();</span>
<span class="fc" id="L1200">            BatchlogCleanup cleanup = new BatchlogCleanup(mutations.size(),</span>
<span class="fc" id="L1201">                                                          () -&gt; asyncRemoveFromBatchlog(replicaPlan, batchUUID));</span>

            // add a handler for each mutation - includes checking availability, but doesn't initiate any writes, yet
<span class="fc bfc" id="L1204" title="All 2 branches covered.">            for (Mutation mutation : mutations)</span>
            {
<span class="fc" id="L1206">                WriteResponseHandlerWrapper wrapper = wrapBatchResponseHandler(mutation,</span>
                                                                               consistency_level,
                                                                               batchConsistencyLevel,
                                                                               WriteType.BATCH,
                                                                               cleanup,
                                                                               queryStartNanoTime);
                // exit early if we can't fulfill the CL at this time.
<span class="fc" id="L1213">                wrappers.add(wrapper);</span>
<span class="fc" id="L1214">            }</span>

            // write to the batchlog
<span class="fc" id="L1217">            syncWriteToBatchlog(mutations, replicaPlan, batchUUID, queryStartNanoTime);</span>

            // now actually perform the writes and wait for them to complete
<span class="fc" id="L1220">            syncWriteBatchedMutations(wrappers, Stage.MUTATION);</span>
        }
<span class="nc" id="L1222">        catch (UnavailableException e)</span>
        {
<span class="nc" id="L1224">            writeMetrics.unavailables.mark();</span>
<span class="nc" id="L1225">            writeMetricsForLevel(consistency_level).unavailables.mark();</span>
<span class="nc" id="L1226">            Tracing.trace(&quot;Unavailable&quot;);</span>
<span class="nc" id="L1227">            throw e;</span>
        }
<span class="nc" id="L1229">        catch (WriteTimeoutException e)</span>
        {
<span class="nc" id="L1231">            writeMetrics.timeouts.mark();</span>
<span class="nc" id="L1232">            writeMetricsForLevel(consistency_level).timeouts.mark();</span>
<span class="nc" id="L1233">            Tracing.trace(&quot;Write timeout; received {} of {} required replies&quot;, e.received, e.blockFor);</span>
<span class="nc" id="L1234">            throw e;</span>
        }
<span class="nc" id="L1236">        catch (WriteFailureException e)</span>
        {
<span class="nc" id="L1238">            writeMetrics.failures.mark();</span>
<span class="nc" id="L1239">            writeMetricsForLevel(consistency_level).failures.mark();</span>
<span class="nc" id="L1240">            Tracing.trace(&quot;Write failure; received {} of {} required replies&quot;, e.received, e.blockFor);</span>
<span class="nc" id="L1241">            throw e;</span>
        }
        finally
        {
<span class="fc" id="L1245">            long latency = nanoTime() - startTime;</span>
<span class="fc" id="L1246">            writeMetrics.addNano(latency);</span>
<span class="fc" id="L1247">            writeMetricsForLevel(consistency_level).addNano(latency);</span>
<span class="fc" id="L1248">            updateCoordinatorWriteLatencyTableMetric(mutations, latency);</span>
        }
<span class="fc" id="L1250">    }</span>

    private static void updateCoordinatorWriteLatencyTableMetric(Collection&lt;? extends IMutation&gt; mutations, long latency)
    {
<span class="pc bpc" id="L1254" title="1 of 2 branches missed.">        if (null == mutations)</span>
        {
<span class="nc" id="L1256">            return;</span>
        }

        try
        {
            //We could potentially pass a callback into performWrite. And add callback provision for mutateCounter or mutateAtomically (sendToHintedEndPoints)
            //However, Trade off between write metric per CF accuracy vs performance hit due to callbacks. Similar issue exists with CoordinatorReadLatency metric.
<span class="fc" id="L1263">            mutations.stream()</span>
<span class="fc" id="L1264">                     .flatMap(m -&gt; m.getTableIds().stream().map(tableId -&gt; Keyspace.open(m.getKeyspaceName()).getColumnFamilyStore(tableId)))</span>
<span class="fc" id="L1265">                     .distinct()</span>
<span class="fc" id="L1266">                     .forEach(store -&gt; store.metric.coordinatorWriteLatency.update(latency, TimeUnit.NANOSECONDS));</span>
        }
<span class="nc" id="L1268">        catch (Exception ex)</span>
        {
<span class="nc" id="L1270">            logger.warn(&quot;Exception occurred updating coordinatorWriteLatency metric&quot;, ex);</span>
<span class="fc" id="L1271">        }</span>
<span class="fc" id="L1272">    }</span>

    private static void syncWriteToBatchlog(Collection&lt;Mutation&gt; mutations, ReplicaPlan.ForWrite replicaPlan, TimeUUID uuid, long queryStartNanoTime)
    throws WriteTimeoutException, WriteFailureException
    {
<span class="fc" id="L1277">        WriteResponseHandler&lt;?&gt; handler = new WriteResponseHandler(replicaPlan,</span>
                                                                   WriteType.BATCH_LOG,
                                                                   null,
                                                                   queryStartNanoTime);

<span class="fc" id="L1282">        Batch batch = Batch.createLocal(uuid, FBUtilities.timestampMicros(), mutations);</span>
<span class="fc" id="L1283">        Message&lt;Batch&gt; message = Message.out(BATCH_STORE_REQ, batch);</span>
<span class="fc bfc" id="L1284" title="All 2 branches covered.">        for (Replica replica : replicaPlan.liveAndDown())</span>
        {
<span class="fc" id="L1286">            logger.trace(&quot;Sending batchlog store request {} to {} for {} mutations&quot;, batch.id, replica, batch.size());</span>

<span class="pc bpc" id="L1288" title="1 of 2 branches missed.">            if (replica.isSelf())</span>
<span class="nc" id="L1289">                performLocally(Stage.MUTATION, replica, () -&gt; BatchlogManager.store(batch), handler, &quot;Batchlog store&quot;);</span>
            else
<span class="fc" id="L1291">                MessagingService.instance().sendWithCallback(message, replica.endpoint(), handler);</span>
<span class="fc" id="L1292">        }</span>
<span class="fc" id="L1293">        handler.get();</span>
<span class="fc" id="L1294">    }</span>

    private static void asyncRemoveFromBatchlog(ReplicaPlan.ForWrite replicaPlan, TimeUUID uuid)
    {
<span class="fc" id="L1298">        Message&lt;TimeUUID&gt; message = Message.out(Verb.BATCH_REMOVE_REQ, uuid);</span>
<span class="fc bfc" id="L1299" title="All 2 branches covered.">        for (Replica target : replicaPlan.contacts())</span>
        {
<span class="pc bpc" id="L1301" title="1 of 2 branches missed.">            if (logger.isTraceEnabled())</span>
<span class="nc" id="L1302">                logger.trace(&quot;Sending batchlog remove request {} to {}&quot;, uuid, target);</span>

<span class="pc bpc" id="L1304" title="1 of 2 branches missed.">            if (target.isSelf())</span>
<span class="nc" id="L1305">                performLocally(Stage.MUTATION, target, () -&gt; BatchlogManager.remove(uuid), &quot;Batchlog remove&quot;);</span>
            else
<span class="fc" id="L1307">                MessagingService.instance().send(message, target.endpoint());</span>
<span class="fc" id="L1308">        }</span>
<span class="fc" id="L1309">    }</span>

    private static void asyncWriteBatchedMutations(List&lt;WriteResponseHandlerWrapper&gt; wrappers, String localDataCenter, Stage stage)
    {
<span class="nc bnc" id="L1313" title="All 2 branches missed.">        for (WriteResponseHandlerWrapper wrapper : wrappers)</span>
        {
<span class="nc" id="L1315">            Replicas.temporaryAssertFull(wrapper.handler.replicaPlan.liveAndDown());  // TODO: CASSANDRA-14549</span>
<span class="nc" id="L1316">            ReplicaPlan.ForWrite replicas = wrapper.handler.replicaPlan.withContacts(wrapper.handler.replicaPlan.liveAndDown());</span>

            try
            {
<span class="nc" id="L1320">                sendToHintedReplicas(wrapper.mutation, replicas, wrapper.handler, localDataCenter, stage);</span>
            }
<span class="nc" id="L1322">            catch (OverloadedException | WriteTimeoutException e)</span>
            {
<span class="nc" id="L1324">                wrapper.handler.onFailure(FBUtilities.getBroadcastAddressAndPort(), RequestFailureReason.forException(e));</span>
<span class="nc" id="L1325">            }</span>
<span class="nc" id="L1326">        }</span>
<span class="nc" id="L1327">    }</span>

    private static void syncWriteBatchedMutations(List&lt;WriteResponseHandlerWrapper&gt; wrappers, Stage stage)
    throws WriteTimeoutException, OverloadedException
    {
<span class="fc" id="L1332">        String localDataCenter = DatabaseDescriptor.getEndpointSnitch().getLocalDatacenter();</span>

<span class="fc bfc" id="L1334" title="All 2 branches covered.">        for (WriteResponseHandlerWrapper wrapper : wrappers)</span>
        {
<span class="fc" id="L1336">            EndpointsForToken sendTo = wrapper.handler.replicaPlan.liveAndDown();</span>
<span class="fc" id="L1337">            Replicas.temporaryAssertFull(sendTo); // TODO: CASSANDRA-14549</span>
<span class="fc" id="L1338">            sendToHintedReplicas(wrapper.mutation, wrapper.handler.replicaPlan.withContacts(sendTo), wrapper.handler, localDataCenter, stage);</span>
<span class="fc" id="L1339">        }</span>

<span class="fc bfc" id="L1341" title="All 2 branches covered.">        for (WriteResponseHandlerWrapper wrapper : wrappers)</span>
<span class="fc" id="L1342">            wrapper.handler.get();</span>
<span class="fc" id="L1343">    }</span>

    /**
     * Perform the write of a mutation given a WritePerformer.
     * Gather the list of write endpoints, apply locally and/or forward the mutation to
     * said write endpoint (deletaged to the actual WritePerformer) and wait for the
     * responses based on consistency level.
     *
     * @param mutation the mutation to be applied
     * @param consistencyLevel the consistency level for the write operation
     * @param performer the WritePerformer in charge of appliying the mutation
     * given the list of write endpoints (either standardWritePerformer for
     * standard writes or counterWritePerformer for counter writes).
     * @param callback an optional callback to be run if and when the write is
     * @param queryStartNanoTime the value of nanoTime() when the query started to be processed
     */
    public static AbstractWriteResponseHandler&lt;IMutation&gt; performWrite(IMutation mutation,
                                                                       ConsistencyLevel consistencyLevel,
                                                                       String localDataCenter,
                                                                       WritePerformer performer,
                                                                       Runnable callback,
                                                                       WriteType writeType,
                                                                       long queryStartNanoTime)
    {
<span class="fc" id="L1367">        String keyspaceName = mutation.getKeyspaceName();</span>
<span class="fc" id="L1368">        Keyspace keyspace = Keyspace.open(keyspaceName);</span>
<span class="fc" id="L1369">        Token tk = mutation.key().getToken();</span>

<span class="fc" id="L1371">        ReplicaPlan.ForWrite replicaPlan = ReplicaPlans.forWrite(keyspace, consistencyLevel, tk, ReplicaPlans.writeNormal);</span>

<span class="fc bfc" id="L1373" title="All 2 branches covered.">        if (replicaPlan.lookup(FBUtilities.getBroadcastAddressAndPort()) != null)</span>
<span class="fc" id="L1374">            writeMetrics.localRequests.mark();</span>
        else
<span class="fc" id="L1376">            writeMetrics.remoteRequests.mark();</span>

<span class="fc" id="L1378">        AbstractReplicationStrategy rs = replicaPlan.replicationStrategy();</span>
<span class="fc" id="L1379">        AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler = rs.getWriteResponseHandler(replicaPlan, callback, writeType, mutation.hintOnFailure(), queryStartNanoTime);</span>

<span class="fc" id="L1381">        performer.apply(mutation, replicaPlan, responseHandler, localDataCenter);</span>
<span class="fc" id="L1382">        return responseHandler;</span>
    }

    // same as performWrites except does not initiate writes (but does perform availability checks).
    private static WriteResponseHandlerWrapper wrapBatchResponseHandler(Mutation mutation,
                                                                        ConsistencyLevel consistencyLevel,
                                                                        ConsistencyLevel batchConsistencyLevel,
                                                                        WriteType writeType,
                                                                        BatchlogResponseHandler.BatchlogCleanup cleanup,
                                                                        long queryStartNanoTime)
    {
<span class="fc" id="L1393">        Keyspace keyspace = Keyspace.open(mutation.getKeyspaceName());</span>
<span class="fc" id="L1394">        Token tk = mutation.key().getToken();</span>

<span class="fc" id="L1396">        ReplicaPlan.ForWrite replicaPlan = ReplicaPlans.forWrite(keyspace, consistencyLevel, tk, ReplicaPlans.writeNormal);</span>

<span class="fc bfc" id="L1398" title="All 2 branches covered.">        if (replicaPlan.lookup(FBUtilities.getBroadcastAddressAndPort()) != null)</span>
<span class="fc" id="L1399">            writeMetrics.localRequests.mark();</span>
        else
<span class="fc" id="L1401">            writeMetrics.remoteRequests.mark();</span>

<span class="fc" id="L1403">        AbstractReplicationStrategy rs = replicaPlan.replicationStrategy();</span>
<span class="fc" id="L1404">        AbstractWriteResponseHandler&lt;IMutation&gt; writeHandler = rs.getWriteResponseHandler(replicaPlan, null, writeType, mutation, queryStartNanoTime);</span>
<span class="fc" id="L1405">        BatchlogResponseHandler&lt;IMutation&gt; batchHandler = new BatchlogResponseHandler&lt;&gt;(writeHandler, batchConsistencyLevel.blockFor(rs), cleanup, queryStartNanoTime);</span>
<span class="fc" id="L1406">        return new WriteResponseHandlerWrapper(batchHandler, mutation);</span>
    }

    /**
     * Same as performWrites except does not initiate writes (but does perform availability checks).
     * Keeps track of ViewWriteMetrics
     */
    private static WriteResponseHandlerWrapper wrapViewBatchResponseHandler(Mutation mutation,
                                                                            ConsistencyLevel consistencyLevel,
                                                                            ConsistencyLevel batchConsistencyLevel,
                                                                            ReplicaLayout.ForTokenWrite liveAndDown,
                                                                            AtomicLong baseComplete,
                                                                            WriteType writeType,
                                                                            BatchlogResponseHandler.BatchlogCleanup cleanup,
                                                                            long queryStartNanoTime)
    {
<span class="nc" id="L1422">        Keyspace keyspace = Keyspace.open(mutation.getKeyspaceName());</span>
<span class="nc" id="L1423">        ReplicaPlan.ForWrite replicaPlan = ReplicaPlans.forWrite(keyspace, consistencyLevel, liveAndDown, ReplicaPlans.writeAll);</span>
<span class="nc" id="L1424">        AbstractReplicationStrategy replicationStrategy = replicaPlan.replicationStrategy();</span>
<span class="nc" id="L1425">        AbstractWriteResponseHandler&lt;IMutation&gt; writeHandler = replicationStrategy.getWriteResponseHandler(replicaPlan, () -&gt; {</span>
<span class="nc" id="L1426">            long delay = Math.max(0, currentTimeMillis() - baseComplete.get());</span>
<span class="nc" id="L1427">            viewWriteMetrics.viewWriteLatency.update(delay, MILLISECONDS);</span>
<span class="nc" id="L1428">        }, writeType, mutation, queryStartNanoTime);</span>
<span class="nc" id="L1429">        BatchlogResponseHandler&lt;IMutation&gt; batchHandler = new ViewWriteMetricsWrapped(writeHandler, batchConsistencyLevel.blockFor(replicationStrategy), cleanup, queryStartNanoTime);</span>
<span class="nc" id="L1430">        return new WriteResponseHandlerWrapper(batchHandler, mutation);</span>
    }

    // used by atomic_batch_mutate to decouple availability check from the write itself, caches consistency level and endpoints.
    private static class WriteResponseHandlerWrapper
    {
        final BatchlogResponseHandler&lt;IMutation&gt; handler;
        final Mutation mutation;

        WriteResponseHandlerWrapper(BatchlogResponseHandler&lt;IMutation&gt; handler, Mutation mutation)
<span class="fc" id="L1440">        {</span>
<span class="fc" id="L1441">            this.handler = handler;</span>
<span class="fc" id="L1442">            this.mutation = mutation;</span>
<span class="fc" id="L1443">        }</span>
    }

    /**
     * Send the mutations to the right targets, write it locally if it corresponds or writes a hint when the node
     * is not available.
     *
     * Note about hints:
     * &lt;pre&gt;
     * {@code
     * | Hinted Handoff | Consist. Level |
     * | on             |       &gt;=1      | --&gt; wait for hints. We DO NOT notify the handler with handler.response() for hints;
     * | on             |       ANY      | --&gt; wait for hints. Responses count towards consistency.
     * | off            |       &gt;=1      | --&gt; DO NOT fire hints. And DO NOT wait for them to complete.
     * | off            |       ANY      | --&gt; DO NOT fire hints. And DO NOT wait for them to complete.
     * }
     * &lt;/pre&gt;
     *
     * @throws OverloadedException if the hints cannot be written/enqueued
     */
    public static void sendToHintedReplicas(final Mutation mutation,
                                            ReplicaPlan.ForWrite plan,
                                            AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler,
                                            String localDataCenter,
                                            Stage stage)
    throws OverloadedException
    {
        // this dc replicas:
<span class="fc" id="L1471">        Collection&lt;Replica&gt; localDc = null;</span>
        // extra-datacenter replicas, grouped by dc
<span class="fc" id="L1473">        Map&lt;String, Collection&lt;Replica&gt;&gt; dcGroups = null;</span>
        // only need to create a Message for non-local writes
<span class="fc" id="L1475">        Message&lt;Mutation&gt; message = null;</span>

<span class="fc" id="L1477">        boolean insertLocal = false;</span>
<span class="fc" id="L1478">        Replica localReplica = null;</span>
<span class="fc" id="L1479">        Collection&lt;Replica&gt; endpointsToHint = null;</span>

<span class="fc" id="L1481">        List&lt;InetAddressAndPort&gt; backPressureHosts = null;</span>

        // For performance, Mutation caches serialized buffers that are computed lazily in serializedBuffer(). That
        // computation is not synchronized however and we will potentially call that method concurrently for each
        // dispatched message (not that concurrent calls to serializedBuffer() are &quot;unsafe&quot; per se, just that they
        // may result in multiple computations, making the caching optimization moot). So forcing the serialization
        // here to make sure it's already cached/computed when it's concurrently used later.
        // Side note: we have one cached buffers for each used EncodingVersion and this only pre-compute the one for
        // the current version, but it's just an optimization and we're ok not optimizing for mixed-version clusters.
<span class="fc" id="L1490">        Mutation.serializer.prepareSerializedBuffer(mutation, MessagingService.current_version);</span>

<span class="fc bfc" id="L1492" title="All 2 branches covered.">        for (Replica destination : plan.contacts())</span>
        {
<span class="fc" id="L1494">            checkHintOverload(destination);</span>

<span class="fc bfc" id="L1496" title="All 2 branches covered.">            if (plan.isAlive(destination))</span>
            {
<span class="fc bfc" id="L1498" title="All 2 branches covered.">                if (destination.isSelf())</span>
                {
<span class="fc" id="L1500">                    insertLocal = true;</span>
<span class="fc" id="L1501">                    localReplica = destination;</span>
                }
                else
                {
                    // belongs on a different server
<span class="fc bfc" id="L1506" title="All 2 branches covered.">                    if (message == null)</span>
<span class="fc" id="L1507">                        message = Message.outWithFlag(MUTATION_REQ, mutation, MessageFlag.CALL_BACK_ON_FAILURE);</span>

<span class="fc" id="L1509">                    String dc = DatabaseDescriptor.getEndpointSnitch().getDatacenter(destination);</span>

                    // direct writes to local DC or old Cassandra versions
                    // (1.1 knows how to forward old-style String message IDs; updated to int in 2.0)
<span class="fc bfc" id="L1513" title="All 2 branches covered.">                    if (localDataCenter.equals(dc))</span>
                    {
<span class="fc bfc" id="L1515" title="All 2 branches covered.">                        if (localDc == null)</span>
<span class="fc" id="L1516">                            localDc = new ArrayList&lt;&gt;(plan.contacts().size());</span>

<span class="fc" id="L1518">                        localDc.add(destination);</span>
                    }
                    else
                    {
<span class="fc bfc" id="L1522" title="All 2 branches covered.">                        if (dcGroups == null)</span>
<span class="fc" id="L1523">                            dcGroups = new HashMap&lt;&gt;();</span>

<span class="fc" id="L1525">                        Collection&lt;Replica&gt; messages = dcGroups.get(dc);</span>
<span class="fc bfc" id="L1526" title="All 2 branches covered.">                        if (messages == null)</span>
<span class="fc" id="L1527">                            messages = dcGroups.computeIfAbsent(dc, (v) -&gt; new ArrayList&lt;&gt;(3)); // most DCs will have &lt;= 3 replicas</span>

<span class="fc" id="L1529">                        messages.add(destination);</span>
                    }

<span class="fc bfc" id="L1532" title="All 2 branches covered.">                    if (backPressureHosts == null)</span>
<span class="fc" id="L1533">                        backPressureHosts = new ArrayList&lt;&gt;(plan.contacts().size());</span>

<span class="fc" id="L1535">                    backPressureHosts.add(destination.endpoint());</span>
<span class="fc" id="L1536">                }</span>
            }
            else
            {
                //Immediately mark the response as expired since the request will not be sent
<span class="fc" id="L1541">                responseHandler.expired();</span>
<span class="pc bpc" id="L1542" title="1 of 2 branches missed.">                if (shouldHint(destination))</span>
                {
<span class="pc bpc" id="L1544" title="1 of 2 branches missed.">                    if (endpointsToHint == null)</span>
<span class="fc" id="L1545">                        endpointsToHint = new ArrayList&lt;&gt;();</span>

<span class="fc" id="L1547">                    endpointsToHint.add(destination);</span>
                }
            }
<span class="fc" id="L1550">        }</span>

<span class="fc bfc" id="L1552" title="All 2 branches covered.">        if (endpointsToHint != null)</span>
<span class="fc" id="L1553">            submitHint(mutation, EndpointsForToken.copyOf(mutation.key().getToken(), endpointsToHint), responseHandler);</span>

<span class="fc bfc" id="L1555" title="All 2 branches covered.">        if (insertLocal)</span>
        {
<span class="fc" id="L1557">            Preconditions.checkNotNull(localReplica);</span>
<span class="fc" id="L1558">            performLocally(stage, localReplica, mutation::apply, responseHandler, mutation);</span>
        }

<span class="fc bfc" id="L1561" title="All 2 branches covered.">        if (localDc != null)</span>
        {
<span class="fc bfc" id="L1563" title="All 2 branches covered.">            for (Replica destination : localDc)</span>
<span class="fc" id="L1564">                MessagingService.instance().sendWriteWithCallback(message, destination, responseHandler);</span>
        }
<span class="fc bfc" id="L1566" title="All 2 branches covered.">        if (dcGroups != null)</span>
        {
            // for each datacenter, send the message to one node to relay the write to other replicas
<span class="fc bfc" id="L1569" title="All 2 branches covered.">            for (Collection&lt;Replica&gt; dcTargets : dcGroups.values())</span>
<span class="fc" id="L1570">                sendMessagesToNonlocalDC(message, EndpointsForToken.copyOf(mutation.key().getToken(), dcTargets), responseHandler);</span>
        }
<span class="fc" id="L1572">    }</span>

    private static void checkHintOverload(Replica destination)
    {
        // avoid OOMing due to excess hints.  we need to do this check even for &quot;live&quot; nodes, since we can
        // still generate hints for those if it's overloaded or simply dead but not yet known-to-be-dead.
        // The idea is that if we have over maxHintsInProgress hints in flight, this is probably due to
        // a small number of nodes causing problems, so we should avoid shutting down writes completely to
        // healthy nodes.  Any node with no hintsInProgress is considered healthy.
<span class="pc bpc" id="L1581" title="1 of 2 branches missed.">        if (StorageMetrics.totalHintsInProgress.getCount() &gt; maxHintsInProgress</span>
<span class="nc bnc" id="L1582" title="All 4 branches missed.">                &amp;&amp; (getHintsInProgressFor(destination.endpoint()).get() &gt; 0 &amp;&amp; shouldHint(destination)))</span>
        {
<span class="nc" id="L1584">            throw new OverloadedException(&quot;Too many in flight hints: &quot; + StorageMetrics.totalHintsInProgress.getCount() +</span>
                                          &quot; destination: &quot; + destination +
<span class="nc" id="L1586">                                          &quot; destination hints: &quot; + getHintsInProgressFor(destination.endpoint()).get());</span>
        }
<span class="fc" id="L1588">    }</span>

    /*
     * Send the message to the first replica of targets, and have it forward the message to others in its DC
     */
    private static void sendMessagesToNonlocalDC(Message&lt;? extends IMutation&gt; message,
                                                 EndpointsForToken targets,
                                                 AbstractWriteResponseHandler&lt;IMutation&gt; handler)
    {
        final Replica target;

<span class="fc bfc" id="L1599" title="All 2 branches covered.">        if (targets.size() &gt; 1)</span>
        {
<span class="fc" id="L1601">            target = pickReplica(targets);</span>
<span class="fc bfc" id="L1602" title="All 2 branches covered.">            EndpointsForToken forwardToReplicas = targets.filter(r -&gt; r != target, targets.size());</span>

<span class="fc bfc" id="L1604" title="All 2 branches covered.">            for (Replica replica : forwardToReplicas)</span>
            {
<span class="fc" id="L1606">                MessagingService.instance().callbacks.addWithExpiration(handler, message, replica);</span>
<span class="fc" id="L1607">                logger.trace(&quot;Adding FWD message to {}@{}&quot;, message.id(), replica);</span>
<span class="fc" id="L1608">            }</span>

            // starting with 4.0, use the same message id for all replicas
<span class="fc" id="L1611">            long[] messageIds = new long[forwardToReplicas.size()];</span>
<span class="fc" id="L1612">            Arrays.fill(messageIds, message.id());</span>

<span class="fc" id="L1614">            message = message.withForwardTo(new ForwardingInfo(forwardToReplicas.endpointList(), messageIds));</span>
<span class="fc" id="L1615">        }</span>
        else
        {
<span class="fc" id="L1618">            target = targets.get(0);</span>
        }

<span class="fc" id="L1621">        Tracing.trace(&quot;Sending mutation to remote replica {}&quot;, target);</span>
<span class="fc" id="L1622">        MessagingService.instance().sendWriteWithCallback(message, target, handler);</span>
<span class="fc" id="L1623">        logger.trace(&quot;Sending message to {}@{}&quot;, message.id(), target);</span>
<span class="fc" id="L1624">    }</span>

    private static Replica pickReplica(EndpointsForToken targets)
    {
<span class="pc bpc" id="L1628" title="1 of 2 branches missed.">        EndpointsForToken healthy = targets.filter(r -&gt; DynamicEndpointSnitch.getSeverity(r.endpoint()) == 0);</span>
<span class="pc bpc" id="L1629" title="1 of 2 branches missed.">        EndpointsForToken select = healthy.isEmpty() ? targets : healthy;</span>
<span class="fc" id="L1630">        return select.get(ThreadLocalRandom.current().nextInt(0, select.size()));</span>
    }

    private static void performLocally(Stage stage, Replica localReplica, final Runnable runnable, String description)
    {
<span class="nc" id="L1635">        stage.maybeExecuteImmediately(new LocalMutationRunnable(localReplica)</span>
<span class="nc" id="L1636">        {</span>
            public void runMayThrow()
            {
                try
                {
<span class="nc" id="L1641">                    runnable.run();</span>
                }
<span class="nc" id="L1643">                catch (Exception ex)</span>
                {
<span class="nc" id="L1645">                    logger.error(&quot;Failed to apply mutation locally : &quot;, ex);</span>
<span class="nc" id="L1646">                }</span>
<span class="nc" id="L1647">            }</span>

            @Override
            public String description()
            {
<span class="nc" id="L1652">                return description;</span>
            }

            @Override
            protected Verb verb()
            {
<span class="nc" id="L1658">                return Verb.MUTATION_REQ;</span>
            }
        });
<span class="nc" id="L1661">    }</span>

    private static void performLocally(Stage stage, Replica localReplica, final Runnable runnable, final RequestCallback&lt;?&gt; handler, Object description)
    {
<span class="fc" id="L1665">        stage.maybeExecuteImmediately(new LocalMutationRunnable(localReplica)</span>
<span class="fc" id="L1666">        {</span>
            public void runMayThrow()
            {
                try
                {
<span class="fc" id="L1671">                    runnable.run();</span>
<span class="fc" id="L1672">                    handler.onResponse(null);</span>
                }
<span class="nc" id="L1674">                catch (Exception ex)</span>
                {
<span class="nc bnc" id="L1676" title="All 2 branches missed.">                    if (!(ex instanceof WriteTimeoutException))</span>
<span class="nc" id="L1677">                        logger.error(&quot;Failed to apply mutation locally : &quot;, ex);</span>
<span class="nc" id="L1678">                    handler.onFailure(FBUtilities.getBroadcastAddressAndPort(), RequestFailureReason.forException(ex));</span>
<span class="fc" id="L1679">                }</span>
<span class="fc" id="L1680">            }</span>

            @Override
            public String description()
            {
                // description is an Object and toString() called so we do not have to evaluate the Mutation.toString()
                // unless expliclitly checked
<span class="nc" id="L1687">                return description.toString();</span>
            }

            @Override
            protected Verb verb()
            {
<span class="fc" id="L1693">                return Verb.MUTATION_REQ;</span>
            }
        });
<span class="fc" id="L1696">    }</span>

    /**
     * Handle counter mutation on the coordinator host.
     *
     * A counter mutation needs to first be applied to a replica (that we'll call the leader for the mutation) before being
     * replicated to the other endpoint. To achieve so, there is two case:
     *   1) the coordinator host is a replica: we proceed to applying the update locally and replicate throug
     *   applyCounterMutationOnCoordinator
     *   2) the coordinator is not a replica: we forward the (counter)mutation to a chosen replica (that will proceed through
     *   applyCounterMutationOnLeader upon receive) and wait for its acknowledgment.
     *
     * Implementation note: We check if we can fulfill the CL on the coordinator host even if he is not a replica to allow
     * quicker response and because the WriteResponseHandlers don't make it easy to send back an error. We also always gather
     * the write latencies at the coordinator node to make gathering point similar to the case of standard writes.
     */
    public static AbstractWriteResponseHandler&lt;IMutation&gt; mutateCounter(CounterMutation cm, String localDataCenter, long queryStartNanoTime) throws UnavailableException, OverloadedException
    {
<span class="fc" id="L1714">        Replica replica = findSuitableReplica(cm.getKeyspaceName(), cm.key(), localDataCenter, cm.consistency());</span>

<span class="fc bfc" id="L1716" title="All 2 branches covered.">        if (replica.isSelf())</span>
        {
<span class="fc" id="L1718">            return applyCounterMutationOnCoordinator(cm, localDataCenter, queryStartNanoTime);</span>
        }
        else
        {
            // Exit now if we can't fulfill the CL here instead of forwarding to the leader replica
<span class="fc" id="L1723">            String keyspaceName = cm.getKeyspaceName();</span>
<span class="fc" id="L1724">            Keyspace keyspace = Keyspace.open(keyspaceName);</span>
<span class="fc" id="L1725">            Token tk = cm.key().getToken();</span>

            // we build this ONLY to perform the sufficiency check that happens on construction
<span class="fc" id="L1728">            ReplicaPlans.forWrite(keyspace, cm.consistency(), tk, ReplicaPlans.writeAll);</span>

            // This host isn't a replica, so mark the request as being remote. If this host is a
            // replica, applyCounterMutationOnCoordinator() in the branch above will call performWrite(), and
            // there we'll mark a local request against the metrics.
<span class="fc" id="L1733">            writeMetrics.remoteRequests.mark();</span>

            // Forward the actual update to the chosen leader replica
<span class="fc" id="L1736">            AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler = new WriteResponseHandler&lt;&gt;(ReplicaPlans.forForwardingCounterWrite(keyspace, tk, replica),</span>
                                                                                                 WriteType.COUNTER, null, queryStartNanoTime);

<span class="fc" id="L1739">            Tracing.trace(&quot;Enqueuing counter update to {}&quot;, replica);</span>
<span class="fc" id="L1740">            Message message = Message.outWithFlag(Verb.COUNTER_MUTATION_REQ, cm, MessageFlag.CALL_BACK_ON_FAILURE);</span>
<span class="fc" id="L1741">            MessagingService.instance().sendWriteWithCallback(message, replica, responseHandler);</span>
<span class="fc" id="L1742">            return responseHandler;</span>
        }
    }

    /**
     * Find a suitable replica as leader for counter update.
     * For now, we pick a random replica in the local DC (or ask the snitch if
     * there is no replica alive in the local DC).
     * TODO: if we track the latency of the counter writes (which makes sense
     * contrarily to standard writes since there is a read involved), we could
     * trust the dynamic snitch entirely, which may be a better solution. It
     * is unclear we want to mix those latencies with read latencies, so this
     * may be a bit involved.
     */
    private static Replica findSuitableReplica(String keyspaceName, DecoratedKey key, String localDataCenter, ConsistencyLevel cl) throws UnavailableException
    {
<span class="fc" id="L1758">        Keyspace keyspace = Keyspace.open(keyspaceName);</span>
<span class="fc" id="L1759">        IEndpointSnitch snitch = DatabaseDescriptor.getEndpointSnitch();</span>
<span class="fc" id="L1760">        AbstractReplicationStrategy replicationStrategy = keyspace.getReplicationStrategy();</span>
<span class="fc" id="L1761">        EndpointsForToken replicas = replicationStrategy.getNaturalReplicasForToken(key);</span>

        // CASSANDRA-13043: filter out those endpoints not accepting clients yet, maybe because still bootstrapping
<span class="fc" id="L1764">        replicas = replicas.filter(replica -&gt; StorageService.instance.isRpcReady(replica.endpoint()));</span>

        // CASSANDRA-17411: filter out endpoints that are not alive
<span class="fc" id="L1767">        replicas = replicas.filter(replica -&gt; FailureDetector.instance.isAlive(replica.endpoint()));</span>

        // TODO have a way to compute the consistency level
<span class="pc bpc" id="L1770" title="1 of 2 branches missed.">        if (replicas.isEmpty())</span>
<span class="nc" id="L1771">            throw UnavailableException.create(cl, cl.blockFor(replicationStrategy), 0);</span>

<span class="fc" id="L1773">        List&lt;Replica&gt; localReplicas = new ArrayList&lt;&gt;(replicas.size());</span>

<span class="fc bfc" id="L1775" title="All 2 branches covered.">        for (Replica replica : replicas)</span>
<span class="pc bpc" id="L1776" title="1 of 2 branches missed.">            if (snitch.getDatacenter(replica).equals(localDataCenter))</span>
<span class="fc" id="L1777">                localReplicas.add(replica);</span>

<span class="pc bpc" id="L1779" title="1 of 2 branches missed.">        if (localReplicas.isEmpty())</span>
        {
            // If the consistency required is local then we should not involve other DCs
<span class="nc bnc" id="L1782" title="All 2 branches missed.">            if (cl.isDatacenterLocal())</span>
<span class="nc" id="L1783">                throw UnavailableException.create(cl, cl.blockFor(replicationStrategy), 0);</span>

            // No endpoint in local DC, pick the closest endpoint according to the snitch
<span class="nc" id="L1786">            replicas = snitch.sortedByProximity(FBUtilities.getBroadcastAddressAndPort(), replicas);</span>
<span class="nc" id="L1787">            return replicas.get(0);</span>
        }

<span class="fc" id="L1790">        return localReplicas.get(ThreadLocalRandom.current().nextInt(localReplicas.size()));</span>
    }

    // Must be called on a replica of the mutation. This replica becomes the
    // leader of this mutation.
    public static AbstractWriteResponseHandler&lt;IMutation&gt; applyCounterMutationOnLeader(CounterMutation cm, String localDataCenter, Runnable callback, long queryStartNanoTime)
    throws UnavailableException, OverloadedException
    {
<span class="fc" id="L1798">        return performWrite(cm, cm.consistency(), localDataCenter, counterWritePerformer, callback, WriteType.COUNTER, queryStartNanoTime);</span>
    }

    // Same as applyCounterMutationOnLeader but must with the difference that it use the MUTATION stage to execute the write (while
    // applyCounterMutationOnLeader assumes it is on the MUTATION stage already)
    public static AbstractWriteResponseHandler&lt;IMutation&gt; applyCounterMutationOnCoordinator(CounterMutation cm, String localDataCenter, long queryStartNanoTime)
    throws UnavailableException, OverloadedException
    {
<span class="fc" id="L1806">        return performWrite(cm, cm.consistency(), localDataCenter, counterWriteOnCoordinatorPerformer, null, WriteType.COUNTER, queryStartNanoTime);</span>
    }

    private static Runnable counterWriteTask(final IMutation mutation,
                                             final ReplicaPlan.ForWrite replicaPlan,
                                             final AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler,
                                             final String localDataCenter)
    {
<span class="fc" id="L1814">        return new DroppableRunnable(Verb.COUNTER_MUTATION_REQ)</span>
<span class="fc" id="L1815">        {</span>
            @Override
            public void runMayThrow() throws OverloadedException, WriteTimeoutException
            {
<span class="pc bpc" id="L1819" title="1 of 2 branches missed.">                assert mutation instanceof CounterMutation;</span>

<span class="fc" id="L1821">                Mutation result = ((CounterMutation) mutation).applyCounterMutation();</span>
<span class="fc" id="L1822">                responseHandler.onResponse(null);</span>
<span class="fc" id="L1823">                sendToHintedReplicas(result, replicaPlan, responseHandler, localDataCenter, Stage.COUNTER_MUTATION);</span>
<span class="fc" id="L1824">            }</span>
        };
    }

    private static boolean systemKeyspaceQuery(List&lt;? extends ReadCommand&gt; cmds)
    {
<span class="nc bnc" id="L1830" title="All 2 branches missed.">        for (ReadCommand cmd : cmds)</span>
<span class="nc bnc" id="L1831" title="All 2 branches missed.">            if (!SchemaConstants.isLocalSystemKeyspace(cmd.metadata().keyspace))</span>
<span class="nc" id="L1832">                return false;</span>
<span class="nc" id="L1833">        return true;</span>
    }

    public static RowIterator readOne(SinglePartitionReadCommand command, ConsistencyLevel consistencyLevel, long queryStartNanoTime)
    throws UnavailableException, IsBootstrappingException, ReadFailureException, ReadTimeoutException, InvalidRequestException
    {
<span class="fc" id="L1839">        return PartitionIterators.getOnlyElement(read(SinglePartitionReadCommand.Group.one(command), consistencyLevel, queryStartNanoTime), command);</span>
    }

    /**
     * Performs the actual reading of a row out of the StorageService, fetching
     * a specific set of column names from a given column family.
     */
    public static PartitionIterator read(SinglePartitionReadCommand.Group group, ConsistencyLevel consistencyLevel, long queryStartNanoTime)
    throws UnavailableException, IsBootstrappingException, ReadFailureException, ReadTimeoutException, InvalidRequestException
    {
<span class="pc bpc" id="L1849" title="1 of 2 branches missed.">        if (!isSafeToPerformRead(group.queries))</span>
        {
<span class="nc" id="L1851">            readMetrics.unavailables.mark();</span>
<span class="nc" id="L1852">            readMetricsForLevel(consistencyLevel).unavailables.mark();</span>
<span class="nc" id="L1853">            IsBootstrappingException exception = new IsBootstrappingException();</span>
<span class="nc" id="L1854">            logRequestException(exception, group.queries);</span>
<span class="nc" id="L1855">            throw exception;</span>
        }

<span class="pc bpc" id="L1858" title="3 of 4 branches missed.">        if (DatabaseDescriptor.getPartitionDenylistEnabled() &amp;&amp; DatabaseDescriptor.getDenylistReadsEnabled())</span>
        {
<span class="nc bnc" id="L1860" title="All 2 branches missed.">            for (SinglePartitionReadCommand command : group.queries)</span>
            {
<span class="nc bnc" id="L1862" title="All 2 branches missed.">                if (!partitionDenylist.isKeyPermitted(command.metadata().id, command.partitionKey().getKey()))</span>
                {
<span class="nc" id="L1864">                    denylistMetrics.incrementReadsRejected();</span>
<span class="nc" id="L1865">                    throw new InvalidRequestException(String.format(&quot;Unable to read denylisted partition [0x%s] in %s/%s&quot;,</span>
<span class="nc" id="L1866">                                                                    command.partitionKey().toString(), command.metadata().keyspace, command.metadata().name));</span>
                }
<span class="nc" id="L1868">            }</span>
        }

<span class="fc bfc" id="L1871" title="All 2 branches covered.">        return consistencyLevel.isSerialConsistency()</span>
<span class="fc" id="L1872">             ? readWithPaxos(group, consistencyLevel, queryStartNanoTime)</span>
<span class="fc" id="L1873">             : readRegular(group, consistencyLevel, queryStartNanoTime);</span>
    }

    public static boolean isSafeToPerformRead(List&lt;SinglePartitionReadCommand&gt; queries)
    {
<span class="pc bpc" id="L1878" title="3 of 4 branches missed.">        return isSafeToPerformRead() || systemKeyspaceQuery(queries);</span>
    }

    public static boolean isSafeToPerformRead()
    {
<span class="pc bpc" id="L1883" title="1 of 2 branches missed.">        return !StorageService.instance.isBootstrapMode();</span>
    }

    private static PartitionIterator readWithPaxos(SinglePartitionReadCommand.Group group, ConsistencyLevel consistencyLevel, long queryStartNanoTime)
    throws InvalidRequestException, UnavailableException, ReadFailureException, ReadTimeoutException
    {
<span class="pc bpc" id="L1889" title="1 of 2 branches missed.">        return Paxos.useV2()</span>
<span class="nc" id="L1890">                ? Paxos.read(group, consistencyLevel)</span>
<span class="fc" id="L1891">                : legacyReadWithPaxos(group, consistencyLevel, queryStartNanoTime);</span>
    }

    private static PartitionIterator legacyReadWithPaxos(SinglePartitionReadCommand.Group group, ConsistencyLevel consistencyLevel, long queryStartNanoTime)
    throws InvalidRequestException, UnavailableException, ReadFailureException, ReadTimeoutException
    {
<span class="pc bpc" id="L1897" title="1 of 2 branches missed.">        if (group.queries.size() &gt; 1)</span>
<span class="nc" id="L1898">            throw new InvalidRequestException(&quot;SERIAL/LOCAL_SERIAL consistency may only be requested for one partition at a time&quot;);</span>

<span class="fc" id="L1900">        long start = nanoTime();</span>
<span class="fc" id="L1901">        SinglePartitionReadCommand command = group.queries.get(0);</span>
<span class="fc" id="L1902">        TableMetadata metadata = command.metadata();</span>
<span class="fc" id="L1903">        DecoratedKey key = command.partitionKey();</span>
        // calculate the blockFor before repair any paxos round to avoid RS being altered in between.
<span class="fc" id="L1905">        int blockForRead = consistencyLevel.blockFor(Keyspace.open(metadata.keyspace).getReplicationStrategy());</span>

<span class="fc" id="L1907">        PartitionIterator result = null;</span>
        try
        {
<span class="pc bpc" id="L1910" title="1 of 2 branches missed.">            final ConsistencyLevel consistencyForReplayCommitsOrFetch = consistencyLevel == ConsistencyLevel.LOCAL_SERIAL</span>
<span class="nc" id="L1911">                                                                        ? ConsistencyLevel.LOCAL_QUORUM</span>
<span class="fc" id="L1912">                                                                        : ConsistencyLevel.QUORUM;</span>

            try
            {
                // Commit an empty update to make sure all in-progress updates that should be finished first is, _and_
                // that no other in-progress can get resurrected.
                Function&lt;Ballot, Pair&lt;PartitionUpdate, RowIterator&gt;&gt; updateProposer =
<span class="pc bpc" id="L1919" title="1 of 2 branches missed.">                    !Paxos.isLinearizable()</span>
<span class="nc" id="L1920">                    ? ballot -&gt; null</span>
<span class="fc" id="L1921">                    : ballot -&gt; Pair.create(PartitionUpdate.emptyUpdate(metadata, key), null);</span>
                // When replaying, we commit at quorum/local quorum, as we want to be sure the following read (done at
                // quorum/local_quorum) sees any replayed updates. Our own update is however empty, and those don't even
                // get committed due to an optimiation described in doPaxos/beingRepairAndPaxos, so the commit
                // consistency is irrelevant (we use ANY just to emphasis that we don't wait on our commit).
<span class="fc" id="L1926">                doPaxos(metadata,</span>
                        key,
                        consistencyLevel,
                        consistencyForReplayCommitsOrFetch,
                        ConsistencyLevel.ANY,
                        start,
                        casReadMetrics,
                        updateProposer);
            }
<span class="nc" id="L1935">            catch (WriteTimeoutException e)</span>
            {
<span class="nc" id="L1937">                throw new ReadTimeoutException(consistencyLevel, 0, blockForRead, false);</span>
            }
<span class="nc" id="L1939">            catch (WriteFailureException e)</span>
            {
<span class="nc" id="L1941">                throw new ReadFailureException(consistencyLevel, e.received, e.blockFor, false, e.failureReasonByEndpoint);</span>
<span class="fc" id="L1942">            }</span>

<span class="fc" id="L1944">            result = fetchRows(group.queries, consistencyForReplayCommitsOrFetch, queryStartNanoTime);</span>
        }
<span class="nc" id="L1946">        catch (UnavailableException e)</span>
        {
<span class="nc" id="L1948">            readMetrics.unavailables.mark();</span>
<span class="nc" id="L1949">            casReadMetrics.unavailables.mark();</span>
<span class="nc" id="L1950">            readMetricsForLevel(consistencyLevel).unavailables.mark();</span>
<span class="nc" id="L1951">            logRequestException(e, group.queries);</span>
<span class="nc" id="L1952">            throw e;</span>
        }
<span class="nc" id="L1954">        catch (ReadTimeoutException e)</span>
        {
<span class="nc" id="L1956">            readMetrics.timeouts.mark();</span>
<span class="nc" id="L1957">            casReadMetrics.timeouts.mark();</span>
<span class="nc" id="L1958">            readMetricsForLevel(consistencyLevel).timeouts.mark();</span>
<span class="nc" id="L1959">            logRequestException(e, group.queries);</span>
<span class="nc" id="L1960">            throw e;</span>
        }
<span class="nc" id="L1962">        catch (ReadAbortException e)</span>
        {
<span class="nc" id="L1964">            readMetrics.markAbort(e);</span>
<span class="nc" id="L1965">            casReadMetrics.markAbort(e);</span>
<span class="nc" id="L1966">            readMetricsForLevel(consistencyLevel).markAbort(e);</span>
<span class="nc" id="L1967">            throw e;</span>
        }
<span class="nc" id="L1969">        catch (ReadFailureException e)</span>
        {
<span class="nc" id="L1971">            readMetrics.failures.mark();</span>
<span class="nc" id="L1972">            casReadMetrics.failures.mark();</span>
<span class="nc" id="L1973">            readMetricsForLevel(consistencyLevel).failures.mark();</span>
<span class="nc" id="L1974">            throw e;</span>
        }
        finally
        {
<span class="fc" id="L1978">            long latency = nanoTime() - start;</span>
<span class="fc" id="L1979">            readMetrics.addNano(latency);</span>
<span class="fc" id="L1980">            casReadMetrics.addNano(latency);</span>
<span class="fc" id="L1981">            readMetricsForLevel(consistencyLevel).addNano(latency);</span>
<span class="fc" id="L1982">            Keyspace.open(metadata.keyspace).getColumnFamilyStore(metadata.name).metric.coordinatorReadLatency.update(latency, TimeUnit.NANOSECONDS);</span>
        }

<span class="fc" id="L1985">        return result;</span>
    }

    @SuppressWarnings(&quot;resource&quot;)
    private static PartitionIterator readRegular(SinglePartitionReadCommand.Group group, ConsistencyLevel consistencyLevel, long queryStartNanoTime)
    throws UnavailableException, ReadFailureException, ReadTimeoutException
    {
<span class="fc" id="L1992">        long start = nanoTime();</span>
        try
        {
<span class="fc" id="L1995">            PartitionIterator result = fetchRows(group.queries, consistencyLevel, queryStartNanoTime);</span>
            // Note that the only difference between the command in a group must be the partition key on which
            // they applied.
<span class="fc" id="L1998">            boolean enforceStrictLiveness = group.queries.get(0).metadata().enforceStrictLiveness();</span>
            // If we have more than one command, then despite each read command honoring the limit, the total result
            // might not honor it and so we should enforce it
<span class="fc bfc" id="L2001" title="All 2 branches covered.">            if (group.queries.size() &gt; 1)</span>
<span class="fc" id="L2002">                result = group.limits().filter(result, group.nowInSec(), group.selectsFullPartition(), enforceStrictLiveness);</span>
<span class="fc" id="L2003">            return result;</span>
        }
<span class="fc" id="L2005">        catch (UnavailableException e)</span>
        {
<span class="fc" id="L2007">            readMetrics.unavailables.mark();</span>
<span class="fc" id="L2008">            readMetricsForLevel(consistencyLevel).unavailables.mark();</span>
<span class="fc" id="L2009">            logRequestException(e, group.queries);</span>
<span class="fc" id="L2010">            throw e;</span>
        }
<span class="nc" id="L2012">        catch (ReadTimeoutException e)</span>
        {
<span class="nc" id="L2014">            readMetrics.timeouts.mark();</span>
<span class="nc" id="L2015">            readMetricsForLevel(consistencyLevel).timeouts.mark();</span>
<span class="nc" id="L2016">            logRequestException(e, group.queries);</span>
<span class="nc" id="L2017">            throw e;</span>
        }
<span class="nc" id="L2019">        catch (ReadAbortException e)</span>
        {
<span class="nc" id="L2021">            recordReadRegularAbort(consistencyLevel, e);</span>
<span class="nc" id="L2022">            throw e;</span>
        }
<span class="nc" id="L2024">        catch (ReadFailureException e)</span>
        {
<span class="nc" id="L2026">            readMetrics.failures.mark();</span>
<span class="nc" id="L2027">            readMetricsForLevel(consistencyLevel).failures.mark();</span>
<span class="nc" id="L2028">            throw e;</span>
        }
        finally
        {
<span class="fc" id="L2032">            long latency = nanoTime() - start;</span>
<span class="fc" id="L2033">            readMetrics.addNano(latency);</span>
<span class="fc" id="L2034">            readMetricsForLevel(consistencyLevel).addNano(latency);</span>
            // TODO avoid giving every command the same latency number.  Can fix this in CASSADRA-5329
<span class="fc bfc" id="L2036" title="All 2 branches covered.">            for (ReadCommand command : group.queries)</span>
<span class="fc" id="L2037">                Keyspace.openAndGetStore(command.metadata()).metric.coordinatorReadLatency.update(latency, TimeUnit.NANOSECONDS);</span>
        }
    }

    public static void recordReadRegularAbort(ConsistencyLevel consistencyLevel, Throwable cause)
    {
<span class="nc" id="L2043">        readMetrics.markAbort(cause);</span>
<span class="nc" id="L2044">        readMetricsForLevel(consistencyLevel).markAbort(cause);</span>
<span class="nc" id="L2045">    }</span>

    public static PartitionIterator concatAndBlockOnRepair(List&lt;PartitionIterator&gt; iterators, List&lt;ReadRepair&lt;?, ?&gt;&gt; repairs)
    {
<span class="fc" id="L2049">        PartitionIterator concatenated = PartitionIterators.concat(iterators);</span>

<span class="pc bpc" id="L2051" title="1 of 2 branches missed.">        if (repairs.isEmpty())</span>
<span class="nc" id="L2052">            return concatenated;</span>

<span class="fc" id="L2054">        return new PartitionIterator()</span>
<span class="fc" id="L2055">        {</span>
            public void close()
            {
<span class="fc" id="L2058">                concatenated.close();</span>
<span class="fc" id="L2059">                repairs.forEach(ReadRepair::maybeSendAdditionalWrites);</span>
<span class="fc" id="L2060">                repairs.forEach(ReadRepair::awaitWrites);</span>
<span class="fc" id="L2061">            }</span>

            public boolean hasNext()
            {
<span class="fc" id="L2065">                return concatenated.hasNext();</span>
            }

            public RowIterator next()
            {
<span class="fc" id="L2070">                return concatenated.next();</span>
            }
        };
    }

    /**
     * This function executes local and remote reads, and blocks for the results:
     *
     * 1. Get the replica locations, sorted by response time according to the snitch
     * 2. Send a data request to the closest replica, and digest requests to either
     *    a) all the replicas, if read repair is enabled
     *    b) the closest R-1 replicas, where R is the number required to satisfy the ConsistencyLevel
     * 3. Wait for a response from R replicas
     * 4. If the digests (if any) match the data return the data
     * 5. else carry out read repair by getting data from all the nodes.
     */
    private static PartitionIterator fetchRows(List&lt;SinglePartitionReadCommand&gt; commands, ConsistencyLevel consistencyLevel, long queryStartNanoTime)
    throws UnavailableException, ReadFailureException, ReadTimeoutException
    {
<span class="fc" id="L2089">        int cmdCount = commands.size();</span>

<span class="fc" id="L2091">        AbstractReadExecutor[] reads = new AbstractReadExecutor[cmdCount];</span>

        // Get the replica locations, sorted by response time according to the snitch, and create a read executor
        // for type of speculation we'll use in this read
<span class="fc bfc" id="L2095" title="All 2 branches covered.">        for (int i=0; i&lt;cmdCount; i++)</span>
        {
<span class="fc" id="L2097">            reads[i] = AbstractReadExecutor.getReadExecutor(commands.get(i), consistencyLevel, queryStartNanoTime);</span>

<span class="fc bfc" id="L2099" title="All 2 branches covered.">            if (reads[i].hasLocalRead())</span>
<span class="fc" id="L2100">                readMetrics.localRequests.mark();</span>
            else
<span class="fc" id="L2102">                readMetrics.remoteRequests.mark();</span>
        }

        // sends a data request to the closest replica, and a digest request to the others. If we have a speculating
        // read executoe, we'll only send read requests to enough replicas to satisfy the consistency level
<span class="fc bfc" id="L2107" title="All 2 branches covered.">        for (int i=0; i&lt;cmdCount; i++)</span>
        {
<span class="fc" id="L2109">            reads[i].executeAsync();</span>
        }

        // if we have a speculating read executor and it looks like we may not receive a response from the initial
        // set of replicas we sent messages to, speculatively send an additional messages to an un-contacted replica
<span class="fc bfc" id="L2114" title="All 2 branches covered.">        for (int i=0; i&lt;cmdCount; i++)</span>
        {
<span class="fc" id="L2116">            reads[i].maybeTryAdditionalReplicas();</span>
        }

        // wait for enough responses to meet the consistency level. If there's a digest mismatch, begin the read
        // repair process by sending full data reads to all replicas we received responses from.
<span class="fc" id="L2121">        boolean logBlockingRepairAttempts = instance.isLoggingReadRepairs();</span>
<span class="fc bfc" id="L2122" title="All 2 branches covered.">        for (int i=0; i&lt;cmdCount; i++)</span>
        {
<span class="fc" id="L2124">            reads[i].awaitResponses(logBlockingRepairAttempts);</span>
        }

        // read repair - if it looks like we may not receive enough full data responses to meet CL, send
        // an additional request to any remaining replicas we haven't contacted (if there are any)
<span class="fc bfc" id="L2129" title="All 2 branches covered.">        for (int i=0; i&lt;cmdCount; i++)</span>
        {
<span class="fc" id="L2131">            reads[i].maybeSendAdditionalDataRequests();</span>
        }

        // read repair - block on full data responses
<span class="fc bfc" id="L2135" title="All 2 branches covered.">        for (int i=0; i&lt;cmdCount; i++)</span>
        {
<span class="fc" id="L2137">            reads[i].awaitReadRepair();</span>
        }

        // if we didn't do a read repair, return the contents of the data response, if we did do a read
        // repair, merge the full data reads
<span class="fc" id="L2142">        List&lt;PartitionIterator&gt; results = new ArrayList&lt;&gt;(cmdCount);</span>
<span class="fc" id="L2143">        List&lt;ReadRepair&lt;?, ?&gt;&gt; repairs = new ArrayList&lt;&gt;(cmdCount);</span>
<span class="fc bfc" id="L2144" title="All 2 branches covered.">        for (int i=0; i&lt;cmdCount; i++)</span>
        {
<span class="fc" id="L2146">            results.add(reads[i].getResult());</span>
<span class="fc" id="L2147">            repairs.add(reads[i].getReadRepair());</span>
        }

        // if we did a read repair, assemble repair mutation and block on them
<span class="fc" id="L2151">        return concatAndBlockOnRepair(results, repairs);</span>
    }

<span class="fc" id="L2154">    public static class LocalReadRunnable extends DroppableRunnable implements RunnableDebuggableTask</span>
    {
        private final ReadCommand command;
        private final ReadCallback handler;
        private final boolean trackRepairedStatus;

        public LocalReadRunnable(ReadCommand command, ReadCallback handler)
        {
<span class="fc" id="L2162">            this(command, handler, false);</span>
<span class="fc" id="L2163">        }</span>

        public LocalReadRunnable(ReadCommand command, ReadCallback handler, boolean trackRepairedStatus)
        {
<span class="fc" id="L2167">            super(Verb.READ_REQ);</span>
<span class="fc" id="L2168">            this.command = command;</span>
<span class="fc" id="L2169">            this.handler = handler;</span>
<span class="fc" id="L2170">            this.trackRepairedStatus = trackRepairedStatus;</span>
<span class="fc" id="L2171">        }</span>

        protected void runMayThrow()
        {
            try
            {
<span class="fc" id="L2177">                MessageParams.reset();</span>

<span class="fc" id="L2179">                boolean readRejected = false;</span>
<span class="fc" id="L2180">                command.setMonitoringTime(approxCreationTimeNanos, false, verb.expiresAfterNanos(), DatabaseDescriptor.getSlowQueryTimeout(NANOSECONDS));</span>

                ReadResponse response;
<span class="fc" id="L2183">                try (ReadExecutionController controller = command.executionController(trackRepairedStatus);</span>
<span class="fc" id="L2184">                     UnfilteredPartitionIterator iterator = command.executeLocally(controller))</span>
                {
<span class="fc" id="L2186">                    response = command.createResponse(iterator, controller.getRepairedDataInfo());</span>
                }
<span class="fc" id="L2188">                catch (RejectException e)</span>
                {
<span class="pc bpc" id="L2190" title="1 of 2 branches missed.">                    if (!command.isTrackingWarnings())</span>
<span class="fc" id="L2191">                        throw e;</span>
                    
<span class="nc" id="L2193">                    response = command.createEmptyResponse();</span>
<span class="nc" id="L2194">                    readRejected = true;</span>
                }
<span class="nc" id="L2196">                catch (QueryCancelledException e)</span>
                {
<span class="nc" id="L2198">                    logger.debug(&quot;Query cancelled (timeout)&quot;, e);</span>
<span class="nc" id="L2199">                    response = null;</span>
<span class="nc bnc" id="L2200" title="All 2 branches missed.">                    assert !command.isCompleted() : &quot;Local read marked as completed despite being aborted by timeout to table &quot; + command.metadata();</span>
<span class="pc" id="L2201">                }</span>

<span class="pc bpc" id="L2203" title="1 of 2 branches missed.">                if (command.complete())</span>
                {
<span class="fc" id="L2205">                    handler.response(response);</span>
                }
                else
                {
<span class="nc" id="L2209">                    MessagingService.instance().metrics.recordSelfDroppedMessage(verb, MonotonicClock.Global.approxTime.now() - approxCreationTimeNanos, NANOSECONDS);</span>
<span class="nc" id="L2210">                    handler.onFailure(FBUtilities.getBroadcastAddressAndPort(), RequestFailureReason.UNKNOWN);</span>
                }

<span class="pc bpc" id="L2213" title="1 of 2 branches missed.">                if (!readRejected)</span>
<span class="fc" id="L2214">                    MessagingService.instance().latencySubscribers.add(FBUtilities.getBroadcastAddressAndPort(), MonotonicClock.Global.approxTime.now() - approxCreationTimeNanos, NANOSECONDS);</span>
            }
<span class="fc" id="L2216">            catch (Throwable t)</span>
            {
<span class="pc bpc" id="L2218" title="1 of 2 branches missed.">                if (t instanceof TombstoneOverwhelmingException)</span>
                {
<span class="fc" id="L2220">                    handler.onFailure(FBUtilities.getBroadcastAddressAndPort(), RequestFailureReason.READ_TOO_MANY_TOMBSTONES);</span>
<span class="fc" id="L2221">                    logger.error(t.getMessage());</span>
                }
                else
                {
<span class="nc" id="L2225">                    handler.onFailure(FBUtilities.getBroadcastAddressAndPort(), RequestFailureReason.UNKNOWN);</span>
<span class="nc" id="L2226">                    throw t;</span>
                }
<span class="fc" id="L2228">            }</span>
<span class="fc" id="L2229">        }</span>

        @Override
        public long creationTimeNanos()
        {
<span class="nc" id="L2234">            return approxCreationTimeNanos;</span>
        }

        @Override
        public long startTimeNanos()
        {
<span class="nc" id="L2240">            return approxStartTimeNanos;</span>
        }

        @Override
        public String description()
        {
<span class="nc" id="L2246">            return command.toCQLString();</span>
        }
    }

    public static PartitionIterator getRangeSlice(PartitionRangeReadCommand command,
                                                  ConsistencyLevel consistencyLevel,
                                                  long queryStartNanoTime)
    {
<span class="pc bpc" id="L2254" title="3 of 4 branches missed.">        if (DatabaseDescriptor.getPartitionDenylistEnabled() &amp;&amp; DatabaseDescriptor.getDenylistRangeReadsEnabled())</span>
        {
<span class="nc" id="L2256">            final int denylisted = partitionDenylist.getDeniedKeysInRangeCount(command.metadata().id, command.dataRange().keyRange());</span>
<span class="nc bnc" id="L2257" title="All 2 branches missed.">            if (denylisted &gt; 0)</span>
            {
<span class="nc" id="L2259">                denylistMetrics.incrementRangeReadsRejected();</span>
<span class="nc" id="L2260">                String tokens = command.loggableTokens();</span>
<span class="nc" id="L2261">                throw new InvalidRequestException(String.format(&quot;Attempted to read a range containing %d denylisted keys in %s/%s.&quot; +</span>
<span class="nc" id="L2262">                                                                &quot; Range read: %s&quot;, denylisted, command.metadata().keyspace, command.metadata().name,</span>
                                                                tokens));
            }
        }
<span class="fc" id="L2266">        return RangeCommands.partitions(command, consistencyLevel, queryStartNanoTime);</span>
    }

    public Map&lt;String, List&lt;String&gt;&gt; getSchemaVersions()
    {
<span class="nc" id="L2271">        return describeSchemaVersions(false);</span>
    }

    public Map&lt;String, List&lt;String&gt;&gt; getSchemaVersionsWithPort()
    {
<span class="nc" id="L2276">        return describeSchemaVersions(true);</span>
    }

    /**
     * initiate a request/response session with each live node to check whether or not everybody is using the same
     * migration id. This is useful for determining if a schema change has propagated through the cluster. Disagreement
     * is assumed if any node fails to respond.
     */
    public static Map&lt;String, List&lt;String&gt;&gt; describeSchemaVersions(boolean withPort)
    {
<span class="nc" id="L2286">        final String myVersion = Schema.instance.getVersion().toString();</span>
<span class="nc" id="L2287">        final Map&lt;InetAddressAndPort, UUID&gt; versions = new ConcurrentHashMap&lt;&gt;();</span>
<span class="nc" id="L2288">        final Set&lt;InetAddressAndPort&gt; liveHosts = Gossiper.instance.getLiveMembers();</span>
<span class="nc" id="L2289">        final CountDownLatch latch = newCountDownLatch(liveHosts.size());</span>

<span class="nc" id="L2291">        RequestCallback&lt;UUID&gt; cb = message -&gt;</span>
        {
            // record the response from the remote node.
<span class="nc" id="L2294">            versions.put(message.from(), message.payload);</span>
<span class="nc" id="L2295">            latch.decrement();</span>
<span class="nc" id="L2296">        };</span>
        // an empty message acts as a request to the SchemaVersionVerbHandler.
<span class="nc" id="L2298">        Message message = out(SCHEMA_VERSION_REQ, noPayload);</span>
<span class="nc bnc" id="L2299" title="All 2 branches missed.">        for (InetAddressAndPort endpoint : liveHosts)</span>
<span class="nc" id="L2300">            MessagingService.instance().sendWithCallback(message, endpoint, cb);</span>

        try
        {
            // wait for as long as possible. timeout-1s if possible.
<span class="nc" id="L2305">            latch.await(DatabaseDescriptor.getRpcTimeout(NANOSECONDS), NANOSECONDS);</span>
        }
<span class="nc" id="L2307">        catch (InterruptedException e)</span>
        {
<span class="nc" id="L2309">            throw new UncheckedInterruptedException(e);</span>
<span class="nc" id="L2310">        }</span>

        // maps versions to hosts that are on that version.
<span class="nc" id="L2313">        Map&lt;String, List&lt;String&gt;&gt; results = new HashMap&lt;String, List&lt;String&gt;&gt;();</span>
<span class="nc" id="L2314">        Iterable&lt;InetAddressAndPort&gt; allHosts = concat(Gossiper.instance.getLiveMembers(), Gossiper.instance.getUnreachableMembers());</span>
<span class="nc bnc" id="L2315" title="All 2 branches missed.">        for (InetAddressAndPort host : allHosts)</span>
        {
<span class="nc" id="L2317">            UUID version = versions.get(host);</span>
<span class="nc bnc" id="L2318" title="All 2 branches missed.">            String stringVersion = version == null ? UNREACHABLE : version.toString();</span>
<span class="nc" id="L2319">            List&lt;String&gt; hosts = results.get(stringVersion);</span>
<span class="nc bnc" id="L2320" title="All 2 branches missed.">            if (hosts == null)</span>
            {
<span class="nc" id="L2322">                hosts = new ArrayList&lt;String&gt;();</span>
<span class="nc" id="L2323">                results.put(stringVersion, hosts);</span>
            }
<span class="nc" id="L2325">            hosts.add(host.getHostAddress(withPort));</span>
<span class="nc" id="L2326">        }</span>

        // we're done: the results map is ready to return to the client.  the rest is just debug logging:
<span class="nc bnc" id="L2329" title="All 2 branches missed.">        if (results.get(UNREACHABLE) != null)</span>
<span class="nc" id="L2330">            logger.debug(&quot;Hosts not in agreement. Didn't get a response from everybody: {}&quot;, join(results.get(UNREACHABLE), &quot;,&quot;));</span>
<span class="nc bnc" id="L2331" title="All 2 branches missed.">        for (Map.Entry&lt;String, List&lt;String&gt;&gt; entry : results.entrySet())</span>
        {
            // check for version disagreement. log the hosts that don't agree.
<span class="nc bnc" id="L2334" title="All 4 branches missed.">            if (entry.getKey().equals(UNREACHABLE) || entry.getKey().equals(myVersion))</span>
<span class="nc" id="L2335">                continue;</span>
<span class="nc bnc" id="L2336" title="All 2 branches missed.">            for (String host : entry.getValue())</span>
<span class="nc" id="L2337">                logger.debug(&quot;{} disagrees ({})&quot;, host, entry.getKey());</span>
<span class="nc" id="L2338">        }</span>
<span class="nc bnc" id="L2339" title="All 2 branches missed.">        if (results.size() == 1)</span>
<span class="nc" id="L2340">            logger.debug(&quot;Schemas are in agreement.&quot;);</span>

<span class="nc" id="L2342">        return results;</span>
    }

    public boolean getHintedHandoffEnabled()
    {
<span class="nc" id="L2347">        return DatabaseDescriptor.hintedHandoffEnabled();</span>
    }

    public void setHintedHandoffEnabled(boolean b)
    {
<span class="nc" id="L2352">        synchronized (StorageService.instance)</span>
        {
<span class="nc bnc" id="L2354" title="All 2 branches missed.">            if (b)</span>
<span class="nc" id="L2355">                StorageService.instance.checkServiceAllowedToStart(&quot;hinted handoff&quot;);</span>

<span class="nc" id="L2357">            DatabaseDescriptor.setHintedHandoffEnabled(b);</span>
<span class="nc" id="L2358">        }</span>
<span class="nc" id="L2359">    }</span>

    public void enableHintsForDC(String dc)
    {
<span class="nc" id="L2363">        DatabaseDescriptor.enableHintsForDC(dc);</span>
<span class="nc" id="L2364">    }</span>

    public void disableHintsForDC(String dc)
    {
<span class="nc" id="L2368">        DatabaseDescriptor.disableHintsForDC(dc);</span>
<span class="nc" id="L2369">    }</span>

    public Set&lt;String&gt; getHintedHandoffDisabledDCs()
    {
<span class="nc" id="L2373">        return DatabaseDescriptor.hintedHandoffDisabledDCs();</span>
    }

    public int getMaxHintWindow()
    {
<span class="nc" id="L2378">        return DatabaseDescriptor.getMaxHintWindow();</span>
    }

    public void setMaxHintWindow(int ms)
    {
<span class="nc" id="L2383">        DatabaseDescriptor.setMaxHintWindow(ms);</span>
<span class="nc" id="L2384">    }</span>

    public int getMaxHintsSizePerHostInMiB()
    {
<span class="nc" id="L2388">        return DatabaseDescriptor.getMaxHintsSizePerHostInMiB();</span>
    }

    public void setMaxHintsSizePerHostInMiB(int value)
    {
<span class="nc" id="L2393">        DatabaseDescriptor.setMaxHintsSizePerHostInMiB(value);</span>
<span class="nc" id="L2394">    }</span>

    public static boolean shouldHint(Replica replica)
    {
<span class="fc" id="L2398">        return shouldHint(replica, true);</span>
    }

    /**
     * Determines whether a hint should be stored or not.
     * It rejects early if any of the condition is met:
     * - Hints disabled entirely or for the belonging datacetner of the replica
     * - The replica is transient or is the self node
     * - The replica is no longer part of the ring
     * - The hint window has expired
     * - The hints have reached to the size limit for the node
     * Otherwise, it permits.
     *
     * @param replica, the replica for the hint
     * @param tryEnablePersistentWindow, true to consider hint_window_persistent_enabled; otherwise, ignores
     * @return true to permit or false to reject hint
     */
    public static boolean shouldHint(Replica replica, boolean tryEnablePersistentWindow)
    {
<span class="pc bpc" id="L2417" title="1 of 2 branches missed.">        if (!DatabaseDescriptor.hintedHandoffEnabled()</span>
<span class="pc bpc" id="L2418" title="1 of 2 branches missed.">            || replica.isTransient()</span>
<span class="pc bpc" id="L2419" title="1 of 2 branches missed.">            || replica.isSelf())</span>
<span class="nc" id="L2420">            return false;</span>

<span class="fc" id="L2422">        Set&lt;String&gt; disabledDCs = DatabaseDescriptor.hintedHandoffDisabledDCs();</span>
<span class="pc bpc" id="L2423" title="1 of 2 branches missed.">        if (!disabledDCs.isEmpty())</span>
        {
<span class="nc" id="L2425">            final String dc = DatabaseDescriptor.getEndpointSnitch().getDatacenter(replica);</span>
<span class="nc bnc" id="L2426" title="All 2 branches missed.">            if (disabledDCs.contains(dc))</span>
            {
<span class="nc" id="L2428">                Tracing.trace(&quot;Not hinting {} since its data center {} has been disabled {}&quot;, replica, dc, disabledDCs);</span>
<span class="nc" id="L2429">                return false;</span>
            }
        }

<span class="fc" id="L2433">        InetAddressAndPort endpoint = replica.endpoint();</span>
<span class="fc" id="L2434">        int maxHintWindow = DatabaseDescriptor.getMaxHintWindow();</span>
<span class="fc" id="L2435">        long endpointDowntime = Gossiper.instance.getEndpointDowntime(endpoint);</span>
<span class="pc bpc" id="L2436" title="1 of 2 branches missed.">        boolean hintWindowExpired = endpointDowntime &gt; maxHintWindow;</span>

<span class="fc" id="L2438">        UUID hostIdForEndpoint = StorageService.instance.getHostIdForEndpoint(endpoint);</span>
<span class="pc bpc" id="L2439" title="1 of 2 branches missed.">        if (hostIdForEndpoint == null)</span>
        {
<span class="nc" id="L2441">            Tracing.trace(&quot;Discarding hint for endpoint not part of ring: {}&quot;, endpoint);</span>
<span class="nc" id="L2442">            return false;</span>
        }

        // if persisting hints window, hintWindowExpired might be updated according to the timestamp of the earliest hint
<span class="pc bpc" id="L2446" title="3 of 6 branches missed.">        if (tryEnablePersistentWindow &amp;&amp; !hintWindowExpired &amp;&amp; DatabaseDescriptor.hintWindowPersistentEnabled())</span>
        {
<span class="fc" id="L2448">            long earliestHint = HintsService.instance.getEarliestHintForHost(hostIdForEndpoint);</span>
<span class="pc bpc" id="L2449" title="1 of 2 branches missed.">            hintWindowExpired = Clock.Global.currentTimeMillis() - maxHintWindow &gt; earliestHint;</span>
<span class="pc bpc" id="L2450" title="1 of 2 branches missed.">            if (hintWindowExpired)</span>
<span class="nc" id="L2451">                Tracing.trace(&quot;Not hinting {} for which there is the earliest hint stored at {}&quot;, replica, earliestHint);</span>
        }

<span class="pc bpc" id="L2454" title="1 of 2 branches missed.">        if (hintWindowExpired)</span>
        {
<span class="nc" id="L2456">            HintsService.instance.metrics.incrPastWindow(endpoint);</span>
<span class="nc" id="L2457">            Tracing.trace(&quot;Not hinting {} which has been down {} ms&quot;, endpoint, endpointDowntime);</span>
<span class="nc" id="L2458">            return false;</span>
        }

<span class="fc" id="L2461">        long maxHintsSize = DatabaseDescriptor.getMaxHintsSizePerHost();</span>
<span class="fc" id="L2462">        long actualTotalHintsSize = HintsService.instance.getTotalHintsSize(hostIdForEndpoint);</span>
<span class="pc bpc" id="L2463" title="3 of 4 branches missed.">        boolean hasHintsReachedMaxSize = maxHintsSize &gt; 0 &amp;&amp; actualTotalHintsSize &gt; maxHintsSize;</span>
<span class="pc bpc" id="L2464" title="1 of 2 branches missed.">        if (hasHintsReachedMaxSize)</span>
        {
<span class="nc" id="L2466">            Tracing.trace(&quot;Not hinting {} which has reached to the max hints size {} bytes on disk. The actual hints size on disk: {}&quot;,</span>
<span class="nc" id="L2467">                          endpoint, maxHintsSize, actualTotalHintsSize);</span>
<span class="nc" id="L2468">            return false;</span>
        }

<span class="fc" id="L2471">        return true;</span>
    }

    /**
     * Performs the truncate operatoin, which effectively deletes all data from
     * the column family cfname
     * @param keyspace
     * @param cfname
     * @throws UnavailableException If some of the hosts in the ring are down.
     * @throws TimeoutException
     */
    public static void truncateBlocking(String keyspace, String cfname) throws UnavailableException, TimeoutException
    {
<span class="fc" id="L2484">        logger.debug(&quot;Starting a blocking truncate operation on keyspace {}, CF {}&quot;, keyspace, cfname);</span>
<span class="pc bpc" id="L2485" title="1 of 2 branches missed.">        if (isAnyStorageHostDown())</span>
        {
<span class="nc" id="L2487">            logger.info(&quot;Cannot perform truncate, some hosts are down&quot;);</span>
            // Since the truncate operation is so aggressive and is typically only
            // invoked by an admin, for simplicity we require that all nodes are up
            // to perform the operation.
<span class="nc" id="L2491">            int liveMembers = Gossiper.instance.getLiveMembers().size();</span>
<span class="nc" id="L2492">            throw UnavailableException.create(ConsistencyLevel.ALL, liveMembers + Gossiper.instance.getUnreachableMembers().size(), liveMembers);</span>
        }

<span class="fc" id="L2495">        Set&lt;InetAddressAndPort&gt; allEndpoints = StorageService.instance.getLiveRingMembers(true);</span>

<span class="fc" id="L2497">        int blockFor = allEndpoints.size();</span>
<span class="fc" id="L2498">        final TruncateResponseHandler responseHandler = new TruncateResponseHandler(blockFor);</span>

        // Send out the truncate calls and track the responses with the callbacks.
<span class="fc" id="L2501">        Tracing.trace(&quot;Enqueuing truncate messages to hosts {}&quot;, allEndpoints);</span>
<span class="fc" id="L2502">        Message&lt;TruncateRequest&gt; message = Message.out(TRUNCATE_REQ, new TruncateRequest(keyspace, cfname));</span>
<span class="fc bfc" id="L2503" title="All 2 branches covered.">        for (InetAddressAndPort endpoint : allEndpoints)</span>
<span class="fc" id="L2504">            MessagingService.instance().sendWithCallback(message, endpoint, responseHandler);</span>

        // Wait for all
        try
        {
<span class="fc" id="L2509">            responseHandler.get();</span>
        }
<span class="nc" id="L2511">        catch (TimeoutException e)</span>
        {
<span class="nc" id="L2513">            Tracing.trace(&quot;Timed out&quot;);</span>
<span class="nc" id="L2514">            throw e;</span>
<span class="fc" id="L2515">        }</span>
<span class="fc" id="L2516">    }</span>

    /**
     * Asks the gossiper if there are any nodes that are currently down.
     * @return true if the gossiper thinks all nodes are up.
     */
    private static boolean isAnyStorageHostDown()
    {
<span class="pc bpc" id="L2524" title="1 of 2 branches missed.">        return !Gossiper.instance.getUnreachableTokenOwners().isEmpty();</span>
    }

    public interface WritePerformer
    {
        public void apply(IMutation mutation,
                          ReplicaPlan.ForWrite targets,
                          AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler,
                          String localDataCenter) throws OverloadedException;
    }

    /**
     * This class captures metrics for views writes.
     */
    private static class ViewWriteMetricsWrapped extends BatchlogResponseHandler&lt;IMutation&gt;
    {
        public ViewWriteMetricsWrapped(AbstractWriteResponseHandler&lt;IMutation&gt; writeHandler, int i, BatchlogCleanup cleanup, long queryStartNanoTime)
        {
<span class="nc" id="L2542">            super(writeHandler, i, cleanup, queryStartNanoTime);</span>
<span class="nc" id="L2543">            viewWriteMetrics.viewReplicasAttempted.inc(candidateReplicaCount());</span>
<span class="nc" id="L2544">        }</span>

        public void onResponse(Message&lt;IMutation&gt; msg)
        {
<span class="nc" id="L2548">            super.onResponse(msg);</span>
<span class="nc" id="L2549">            viewWriteMetrics.viewReplicasSuccess.inc();</span>
<span class="nc" id="L2550">        }</span>
    }

    /**
     * A Runnable that aborts if it doesn't start running before it times out
     */
    private static abstract class DroppableRunnable implements Runnable
    {
        protected final long approxCreationTimeNanos;
        protected volatile long approxStartTimeNanos;
        
        final Verb verb;

        public DroppableRunnable(Verb verb)
<span class="fc" id="L2564">        {</span>
<span class="fc" id="L2565">            this.approxCreationTimeNanos = MonotonicClock.Global.approxTime.now();</span>
<span class="fc" id="L2566">            this.verb = verb;</span>
<span class="fc" id="L2567">        }</span>

        public final void run()
        {
<span class="fc" id="L2571">            approxStartTimeNanos = MonotonicClock.Global.approxTime.now();</span>
<span class="fc" id="L2572">            long expirationTimeNanos = verb.expiresAtNanos(approxCreationTimeNanos);</span>
<span class="pc bpc" id="L2573" title="1 of 2 branches missed.">            if (approxStartTimeNanos &gt; expirationTimeNanos)</span>
            {
<span class="nc" id="L2575">                long timeTakenNanos = approxStartTimeNanos - approxCreationTimeNanos;</span>
<span class="nc" id="L2576">                MessagingService.instance().metrics.recordSelfDroppedMessage(verb, timeTakenNanos, NANOSECONDS);</span>
<span class="nc" id="L2577">                return;</span>
            }
            try
            {
<span class="fc" id="L2581">                runMayThrow();</span>
            }
<span class="nc" id="L2583">            catch (Exception e)</span>
            {
<span class="nc" id="L2585">                throw new RuntimeException(e);</span>
<span class="fc" id="L2586">            }</span>
<span class="fc" id="L2587">        }</span>

        abstract protected void runMayThrow() throws Exception;
    }

    /**
     * Like DroppableRunnable, but if it aborts, it will rerun (on the mutation stage) after
     * marking itself as a hint in progress so that the hint backpressure mechanism can function.
     */
    private static abstract class LocalMutationRunnable implements RunnableDebuggableTask
    {
<span class="fc" id="L2598">        private final long approxCreationTimeNanos = MonotonicClock.Global.approxTime.now();</span>
        private volatile long approxStartTimeNanos;

        private final Replica localReplica;

        LocalMutationRunnable(Replica localReplica)
<span class="fc" id="L2604">        {</span>
<span class="fc" id="L2605">            this.localReplica = localReplica;</span>
<span class="fc" id="L2606">        }</span>

        public final void run()
        {
<span class="fc" id="L2610">            final Verb verb = verb();</span>
<span class="fc" id="L2611">            approxStartTimeNanos = MonotonicClock.Global.approxTime.now();</span>
<span class="fc" id="L2612">            long expirationTimeNanos = verb.expiresAtNanos(approxCreationTimeNanos);</span>
            
<span class="pc bpc" id="L2614" title="1 of 2 branches missed.">            if (approxStartTimeNanos &gt; expirationTimeNanos)</span>
            {
<span class="nc" id="L2616">                long timeTakenNanos = approxStartTimeNanos - approxCreationTimeNanos;</span>
<span class="nc" id="L2617">                MessagingService.instance().metrics.recordSelfDroppedMessage(Verb.MUTATION_REQ, timeTakenNanos, NANOSECONDS);</span>

<span class="nc" id="L2619">                HintRunnable runnable = new HintRunnable(EndpointsForToken.of(localReplica.range().right, localReplica))</span>
<span class="nc" id="L2620">                {</span>
                    protected void runMayThrow() throws Exception
                    {
<span class="nc" id="L2623">                        LocalMutationRunnable.this.runMayThrow();</span>
<span class="nc" id="L2624">                    }</span>
                };
<span class="nc" id="L2626">                submitHint(runnable);</span>
<span class="nc" id="L2627">                return;</span>
            }

            try
            {
<span class="fc" id="L2632">                runMayThrow();</span>
            }
<span class="nc" id="L2634">            catch (Exception e)</span>
            {
<span class="nc" id="L2636">                throw new RuntimeException(e);</span>
<span class="fc" id="L2637">            }</span>
<span class="fc" id="L2638">        }</span>

        @Override
        public long creationTimeNanos()
        {
<span class="nc" id="L2643">            return approxCreationTimeNanos;</span>
        }

        @Override
        public long startTimeNanos()
        {
<span class="nc" id="L2649">            return approxStartTimeNanos;</span>
        }

        @Override
        abstract public String description();

        abstract protected Verb verb();
        abstract protected void runMayThrow() throws Exception;
    }

    public static void logRequestException(Exception exception, Collection&lt;? extends ReadCommand&gt; commands)
    {
        // Multiple different types of errors can happen, so by dedupping on the error type we can see each error
        // case rather than just exposing the first error seen; this should make sure more rare issues are exposed
        // rather than being hidden by more common errors such as timeout or unavailable
        // see CASSANDRA-17754
<span class="fc" id="L2665">        String msg = exception.getClass().getSimpleName() + &quot; \&quot;{}\&quot; while executing {}&quot;;</span>
<span class="fc" id="L2666">        NoSpamLogger.log(logger, NoSpamLogger.Level.INFO, FAILURE_LOGGING_INTERVAL_SECONDS, TimeUnit.SECONDS,</span>
                         msg,
<span class="fc" id="L2668">                         () -&gt; new Object[]</span>
                               {
<span class="fc" id="L2670">                                   exception.getMessage(),</span>
<span class="fc" id="L2671">                                   commands.stream().map(ReadCommand::toCQLString).collect(Collectors.joining(&quot;; &quot;))</span>
                               });
<span class="fc" id="L2673">    }</span>

    /**
     * HintRunnable will decrease totalHintsInProgress and targetHints when finished.
     * It is the caller's responsibility to increment them initially.
     */
    private abstract static class HintRunnable implements Runnable
    {
        public final EndpointsForToken targets;

        protected HintRunnable(EndpointsForToken targets)
<span class="fc" id="L2684">        {</span>
<span class="fc" id="L2685">            this.targets = targets;</span>
<span class="fc" id="L2686">        }</span>

        public void run()
        {
            try
            {
<span class="fc" id="L2692">                runMayThrow();</span>
            }
<span class="nc" id="L2694">            catch (Exception e)</span>
            {
<span class="nc" id="L2696">                throw new RuntimeException(e);</span>
            }
            finally
            {
<span class="fc" id="L2700">                StorageMetrics.totalHintsInProgress.dec(targets.size());</span>
<span class="fc bfc" id="L2701" title="All 2 branches covered.">                for (InetAddressAndPort target : targets.endpoints())</span>
<span class="fc" id="L2702">                    getHintsInProgressFor(target).decrementAndGet();</span>
            }
<span class="fc" id="L2704">        }</span>

        abstract protected void runMayThrow() throws Exception;
    }

    public long getTotalHints()
    {
<span class="nc" id="L2711">        return StorageMetrics.totalHints.getCount();</span>
    }

    public int getMaxHintsInProgress()
    {
<span class="nc" id="L2716">        return maxHintsInProgress;</span>
    }

    public void setMaxHintsInProgress(int qs)
    {
<span class="nc" id="L2721">        maxHintsInProgress = qs;</span>
<span class="nc" id="L2722">    }</span>

    public int getHintsInProgress()
    {
<span class="nc" id="L2726">        return (int) StorageMetrics.totalHintsInProgress.getCount();</span>
    }

    public void verifyNoHintsInProgress()
    {
<span class="nc bnc" id="L2731" title="All 2 branches missed.">        if (getHintsInProgress() &gt; 0)</span>
<span class="nc" id="L2732">            logger.warn(&quot;Some hints were not written before shutdown.  This is not supposed to happen.  You should (a) run repair, and (b) file a bug report&quot;);</span>
<span class="nc" id="L2733">    }</span>

    private static AtomicInteger getHintsInProgressFor(InetAddressAndPort destination)
    {
        try
        {
<span class="fc" id="L2739">            return hintsInProgress.load(destination);</span>
        }
<span class="nc" id="L2741">        catch (Exception e)</span>
        {
<span class="nc" id="L2743">            throw new AssertionError(e);</span>
        }
    }

    public static Future&lt;Void&gt; submitHint(Mutation mutation, Replica target, AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler)
    {
<span class="nc" id="L2749">        return submitHint(mutation, EndpointsForToken.of(target.range().right, target), responseHandler);</span>
    }

    public static Future&lt;Void&gt; submitHint(Mutation mutation,
                                          EndpointsForToken targets,
                                          AbstractWriteResponseHandler&lt;IMutation&gt; responseHandler)
    {
<span class="fc" id="L2756">        Replicas.assertFull(targets); // hints should not be written for transient replicas</span>
<span class="fc" id="L2757">        HintRunnable runnable = new HintRunnable(targets)</span>
<span class="fc" id="L2758">        {</span>
            public void runMayThrow()
            {
<span class="fc" id="L2761">                Set&lt;InetAddressAndPort&gt; validTargets = new HashSet&lt;&gt;(targets.size());</span>
<span class="fc" id="L2762">                Set&lt;UUID&gt; hostIds = new HashSet&lt;&gt;(targets.size());</span>
<span class="fc bfc" id="L2763" title="All 2 branches covered.">                for (InetAddressAndPort target : targets.endpoints())</span>
                {
<span class="fc" id="L2765">                    UUID hostId = StorageService.instance.getHostIdForEndpoint(target);</span>
<span class="pc bpc" id="L2766" title="1 of 2 branches missed.">                    if (hostId != null)</span>
                    {
<span class="fc" id="L2768">                        hostIds.add(hostId);</span>
<span class="fc" id="L2769">                        validTargets.add(target);</span>
                    }
                    else
<span class="nc" id="L2772">                        logger.debug(&quot;Discarding hint for endpoint not part of ring: {}&quot;, target);</span>
<span class="fc" id="L2773">                }</span>
<span class="fc" id="L2774">                logger.trace(&quot;Adding hints for {}&quot;, validTargets);</span>
<span class="fc" id="L2775">                HintsService.instance.write(hostIds, Hint.create(mutation, currentTimeMillis()));</span>
<span class="fc" id="L2776">                validTargets.forEach(HintsService.instance.metrics::incrCreatedHints);</span>
                // Notify the handler only for CL == ANY
<span class="pc bpc" id="L2778" title="2 of 4 branches missed.">                if (responseHandler != null &amp;&amp; responseHandler.replicaPlan.consistencyLevel() == ConsistencyLevel.ANY)</span>
<span class="nc" id="L2779">                    responseHandler.onResponse(null);</span>
<span class="fc" id="L2780">            }</span>
        };

<span class="fc" id="L2783">        return submitHint(runnable);</span>
    }

    private static Future&lt;Void&gt; submitHint(HintRunnable runnable)
    {
<span class="fc" id="L2788">        StorageMetrics.totalHintsInProgress.inc(runnable.targets.size());</span>
<span class="fc bfc" id="L2789" title="All 2 branches covered.">        for (Replica target : runnable.targets)</span>
<span class="fc" id="L2790">            getHintsInProgressFor(target.endpoint()).incrementAndGet();</span>
<span class="fc" id="L2791">        return (Future&lt;Void&gt;) Stage.MUTATION.submit(runnable);</span>
    }

<span class="nc" id="L2794">    public Long getRpcTimeout() { return DatabaseDescriptor.getRpcTimeout(MILLISECONDS); }</span>
<span class="nc" id="L2795">    public void setRpcTimeout(Long timeoutInMillis) { DatabaseDescriptor.setRpcTimeout(timeoutInMillis); }</span>

<span class="nc" id="L2797">    public Long getReadRpcTimeout() { return DatabaseDescriptor.getReadRpcTimeout(MILLISECONDS); }</span>
<span class="nc" id="L2798">    public void setReadRpcTimeout(Long timeoutInMillis) { DatabaseDescriptor.setReadRpcTimeout(timeoutInMillis); }</span>

<span class="nc" id="L2800">    public Long getWriteRpcTimeout() { return DatabaseDescriptor.getWriteRpcTimeout(MILLISECONDS); }</span>
<span class="nc" id="L2801">    public void setWriteRpcTimeout(Long timeoutInMillis) { DatabaseDescriptor.setWriteRpcTimeout(timeoutInMillis); }</span>

<span class="nc" id="L2803">    public Long getCounterWriteRpcTimeout() { return DatabaseDescriptor.getCounterWriteRpcTimeout(MILLISECONDS); }</span>
<span class="nc" id="L2804">    public void setCounterWriteRpcTimeout(Long timeoutInMillis) { DatabaseDescriptor.setCounterWriteRpcTimeout(timeoutInMillis); }</span>

<span class="nc" id="L2806">    public Long getCasContentionTimeout() { return DatabaseDescriptor.getCasContentionTimeout(MILLISECONDS); }</span>
<span class="nc" id="L2807">    public void setCasContentionTimeout(Long timeoutInMillis) { DatabaseDescriptor.setCasContentionTimeout(timeoutInMillis); }</span>

<span class="nc" id="L2809">    public Long getRangeRpcTimeout() { return DatabaseDescriptor.getRangeRpcTimeout(MILLISECONDS); }</span>
<span class="nc" id="L2810">    public void setRangeRpcTimeout(Long timeoutInMillis) { DatabaseDescriptor.setRangeRpcTimeout(timeoutInMillis); }</span>

<span class="nc" id="L2812">    public Long getTruncateRpcTimeout() { return DatabaseDescriptor.getTruncateRpcTimeout(MILLISECONDS); }</span>
<span class="nc" id="L2813">    public void setTruncateRpcTimeout(Long timeoutInMillis) { DatabaseDescriptor.setTruncateRpcTimeout(timeoutInMillis); }</span>

<span class="nc" id="L2815">    public Long getNativeTransportMaxConcurrentConnections() { return DatabaseDescriptor.getNativeTransportMaxConcurrentConnections(); }</span>
<span class="nc" id="L2816">    public void setNativeTransportMaxConcurrentConnections(Long nativeTransportMaxConcurrentConnections) { DatabaseDescriptor.setNativeTransportMaxConcurrentConnections(nativeTransportMaxConcurrentConnections); }</span>

<span class="nc" id="L2818">    public Long getNativeTransportMaxConcurrentConnectionsPerIp() { return DatabaseDescriptor.getNativeTransportMaxConcurrentConnectionsPerIp(); }</span>
<span class="nc" id="L2819">    public void setNativeTransportMaxConcurrentConnectionsPerIp(Long nativeTransportMaxConcurrentConnections) { DatabaseDescriptor.setNativeTransportMaxConcurrentConnectionsPerIp(nativeTransportMaxConcurrentConnections); }</span>

<span class="nc" id="L2821">    public void reloadTriggerClasses() { TriggerExecutor.instance.reloadClasses(); }</span>

    public long getReadRepairAttempted()
    {
<span class="nc" id="L2825">        return ReadRepairMetrics.attempted.getCount();</span>
    }

    public long getReadRepairRepairedBlocking()
    {
<span class="nc" id="L2830">        return ReadRepairMetrics.repairedBlocking.getCount();</span>
    }

    public long getReadRepairRepairedBackground()
    {
<span class="nc" id="L2835">        return ReadRepairMetrics.repairedBackground.getCount();</span>
    }

    public long getReadRepairRepairTimedOut()
    {
<span class="nc" id="L2840">        return ReadRepairMetrics.timedOut.getCount();</span>
    }

    public int getNumberOfTables()
    {
<span class="nc" id="L2845">        return Schema.instance.getNumberOfTables();</span>
    }

    public String getIdealConsistencyLevel()
    {
<span class="nc" id="L2850">        return Objects.toString(DatabaseDescriptor.getIdealConsistencyLevel(), &quot;&quot;);</span>
    }

    public String setIdealConsistencyLevel(String cl)
    {
<span class="nc" id="L2855">        ConsistencyLevel original = DatabaseDescriptor.getIdealConsistencyLevel();</span>
<span class="nc" id="L2856">        ConsistencyLevel newCL = ConsistencyLevel.valueOf(cl.trim().toUpperCase());</span>
<span class="nc" id="L2857">        DatabaseDescriptor.setIdealConsistencyLevel(newCL);</span>
<span class="nc" id="L2858">        return String.format(&quot;Updating ideal consistency level new value: %s old value %s&quot;, newCL, original.toString());</span>
    }

    @Deprecated
    public int getOtcBacklogExpirationInterval() {
<span class="nc" id="L2863">        return 0;</span>
    }

    @Deprecated
<span class="nc" id="L2867">    public void setOtcBacklogExpirationInterval(int intervalInMillis) { }</span>

    @Override
    public void enableRepairedDataTrackingForRangeReads()
    {
<span class="nc" id="L2872">        DatabaseDescriptor.setRepairedDataTrackingForRangeReadsEnabled(true);</span>
<span class="nc" id="L2873">    }</span>

    @Override
    public void disableRepairedDataTrackingForRangeReads()
    {
<span class="nc" id="L2878">        DatabaseDescriptor.setRepairedDataTrackingForRangeReadsEnabled(false);</span>
<span class="nc" id="L2879">    }</span>

    @Override
    public boolean getRepairedDataTrackingEnabledForRangeReads()
    {
<span class="nc" id="L2884">        return DatabaseDescriptor.getRepairedDataTrackingForRangeReadsEnabled();</span>
    }

    @Override
    public void enableRepairedDataTrackingForPartitionReads()
    {
<span class="nc" id="L2890">        DatabaseDescriptor.setRepairedDataTrackingForPartitionReadsEnabled(true);</span>
<span class="nc" id="L2891">    }</span>

    @Override
    public void disableRepairedDataTrackingForPartitionReads()
    {
<span class="nc" id="L2896">        DatabaseDescriptor.setRepairedDataTrackingForPartitionReadsEnabled(false);</span>
<span class="nc" id="L2897">    }</span>

    @Override
    public boolean getRepairedDataTrackingEnabledForPartitionReads()
    {
<span class="nc" id="L2902">        return DatabaseDescriptor.getRepairedDataTrackingForPartitionReadsEnabled();</span>
    }

    @Override
    public void enableReportingUnconfirmedRepairedDataMismatches()
    {
<span class="nc" id="L2908">        DatabaseDescriptor.reportUnconfirmedRepairedDataMismatches(true);</span>
<span class="nc" id="L2909">    }</span>

    @Override
    public void disableReportingUnconfirmedRepairedDataMismatches()
    {
<span class="nc" id="L2914">       DatabaseDescriptor.reportUnconfirmedRepairedDataMismatches(false);</span>
<span class="nc" id="L2915">    }</span>

    @Override
    public boolean getReportingUnconfirmedRepairedDataMismatchesEnabled()
    {
<span class="nc" id="L2920">        return DatabaseDescriptor.reportUnconfirmedRepairedDataMismatches();</span>
    }

    @Override
    public boolean getSnapshotOnRepairedDataMismatchEnabled()
    {
<span class="nc" id="L2926">        return DatabaseDescriptor.snapshotOnRepairedDataMismatch();</span>
    }

    @Override
    public void enableSnapshotOnRepairedDataMismatch()
    {
<span class="nc" id="L2932">        DatabaseDescriptor.setSnapshotOnRepairedDataMismatch(true);</span>
<span class="nc" id="L2933">    }</span>

    @Override
    public void disableSnapshotOnRepairedDataMismatch()
    {
<span class="nc" id="L2938">        DatabaseDescriptor.setSnapshotOnRepairedDataMismatch(false);</span>
<span class="nc" id="L2939">    }</span>

    static class PaxosBallotAndContention
    {
        final Ballot ballot;
        final int contentions;

        PaxosBallotAndContention(Ballot ballot, int contentions)
<span class="fc" id="L2947">        {</span>
<span class="fc" id="L2948">            this.ballot = ballot;</span>
<span class="fc" id="L2949">            this.contentions = contentions;</span>
<span class="fc" id="L2950">        }</span>

        @Override
        public final int hashCode()
        {
<span class="nc bnc" id="L2955" title="All 2 branches missed.">            int hashCode = 31 + (ballot == null ? 0 : ballot.hashCode());</span>
<span class="nc" id="L2956">            return 31 * hashCode * this.contentions;</span>
        }

        @Override
        public final boolean equals(Object o)
        {
<span class="nc bnc" id="L2962" title="All 2 branches missed.">            if(!(o instanceof PaxosBallotAndContention))</span>
<span class="nc" id="L2963">                return false;</span>
<span class="nc" id="L2964">            PaxosBallotAndContention that = (PaxosBallotAndContention)o;</span>
            // handles nulls properly
<span class="nc bnc" id="L2966" title="All 4 branches missed.">            return Objects.equals(ballot, that.ballot) &amp;&amp; contentions == that.contentions;</span>
        }
    }

    @Override
    public boolean getSnapshotOnDuplicateRowDetectionEnabled()
    {
<span class="nc" id="L2973">        return DatabaseDescriptor.snapshotOnDuplicateRowDetection();</span>
    }

    @Override
    public void enableSnapshotOnDuplicateRowDetection()
    {
<span class="nc" id="L2979">        DatabaseDescriptor.setSnapshotOnDuplicateRowDetection(true);</span>
<span class="nc" id="L2980">    }</span>

    @Override
    public void disableSnapshotOnDuplicateRowDetection()
    {
<span class="nc" id="L2985">        DatabaseDescriptor.setSnapshotOnDuplicateRowDetection(false);</span>
<span class="nc" id="L2986">    }</span>

    @Override
    public boolean getCheckForDuplicateRowsDuringReads()
    {
<span class="nc" id="L2991">        return DatabaseDescriptor.checkForDuplicateRowsDuringReads();</span>
    }

    @Override
    public void enableCheckForDuplicateRowsDuringReads()
    {
<span class="nc" id="L2997">        DatabaseDescriptor.setCheckForDuplicateRowsDuringReads(true);</span>
<span class="nc" id="L2998">    }</span>

    @Override
    public void disableCheckForDuplicateRowsDuringReads()
    {
<span class="nc" id="L3003">        DatabaseDescriptor.setCheckForDuplicateRowsDuringReads(false);</span>
<span class="nc" id="L3004">    }</span>

    @Override
    public boolean getCheckForDuplicateRowsDuringCompaction()
    {
<span class="nc" id="L3009">        return DatabaseDescriptor.checkForDuplicateRowsDuringCompaction();</span>
    }

    @Override
    public void enableCheckForDuplicateRowsDuringCompaction()
    {
<span class="nc" id="L3015">        DatabaseDescriptor.setCheckForDuplicateRowsDuringCompaction(true);</span>
<span class="nc" id="L3016">    }</span>

    @Override
    public void disableCheckForDuplicateRowsDuringCompaction()
    {
<span class="nc" id="L3021">        DatabaseDescriptor.setCheckForDuplicateRowsDuringCompaction(false);</span>
<span class="nc" id="L3022">    }</span>

    public void initialLoadPartitionDenylist()
    {
<span class="fc" id="L3026">        partitionDenylist.initialLoad();</span>
<span class="fc" id="L3027">    }</span>

    @Override
    public void loadPartitionDenylist()
    {
<span class="nc" id="L3032">        partitionDenylist.load();</span>
<span class="nc" id="L3033">    }</span>

    @Override
    public int getPartitionDenylistLoadAttempts()
    {
<span class="nc" id="L3038">        return partitionDenylist.getLoadAttempts();</span>
    }

    @Override
    public int getPartitionDenylistLoadSuccesses()
    {
<span class="nc" id="L3044">        return partitionDenylist.getLoadSuccesses();</span>
    }

    @Override
    public void setEnablePartitionDenylist(boolean enabled)
    {
<span class="nc" id="L3050">        DatabaseDescriptor.setPartitionDenylistEnabled(enabled);</span>
<span class="nc" id="L3051">    }</span>

    @Override
    public void setEnableDenylistWrites(boolean enabled)
    {
<span class="nc" id="L3056">        DatabaseDescriptor.setDenylistWritesEnabled(enabled);</span>
<span class="nc" id="L3057">    }</span>

    @Override
    public void setEnableDenylistReads(boolean enabled)
    {
<span class="nc" id="L3062">        DatabaseDescriptor.setDenylistReadsEnabled(enabled);</span>
<span class="nc" id="L3063">    }</span>

    @Override
    public void setEnableDenylistRangeReads(boolean enabled)
    {
<span class="nc" id="L3068">        DatabaseDescriptor.setDenylistRangeReadsEnabled(enabled);</span>
<span class="nc" id="L3069">    }</span>

    @Override
    public void setDenylistMaxKeysPerTable(int value)
    {
<span class="nc" id="L3074">        DatabaseDescriptor.setDenylistMaxKeysPerTable(value);</span>
<span class="nc" id="L3075">    }</span>

    @Override
    public void setDenylistMaxKeysTotal(int value)
    {
<span class="nc" id="L3080">        DatabaseDescriptor.setDenylistMaxKeysTotal(value);</span>
<span class="nc" id="L3081">    }</span>

    /**
     * Actively denies read and write access to the provided Partition Key
     * @param keyspace Name of keyspace containing the PK you wish to deny access to
     * @param table Name of table containing the PK you wish to deny access to
     * @param partitionKeyAsString String representation of the PK you want to deny access to
     * @return true if successfully added, false if failure
     */
    @Override
    public boolean denylistKey(String keyspace, String table, String partitionKeyAsString)
    {
<span class="nc bnc" id="L3093" title="All 2 branches missed.">        if (!Schema.instance.getKeyspaces().contains(keyspace))</span>
<span class="nc" id="L3094">            return false;</span>

<span class="nc" id="L3096">        final ColumnFamilyStore cfs = ColumnFamilyStore.getIfExists(keyspace, table);</span>
<span class="nc bnc" id="L3097" title="All 2 branches missed.">        if (cfs == null)</span>
<span class="nc" id="L3098">            return false;</span>

<span class="nc" id="L3100">        final ByteBuffer bytes = cfs.metadata.get().partitionKeyType.fromString(partitionKeyAsString);</span>
<span class="nc" id="L3101">        return partitionDenylist.addKeyToDenylist(keyspace, table, bytes);</span>
    }

    /**
     * Attempts to remove the provided pk from the ks + table deny list
     * @param keyspace Keyspace containing the pk to remove the denylist entry for
     * @param table Table containing the pk to remove denylist entry for
     * @param partitionKeyAsString String representation of the PK you want to re-allow access to
     * @return true if found and removed, false if not
     */
    @Override
    public boolean removeDenylistKey(String keyspace, String table, String partitionKeyAsString)
    {
<span class="nc bnc" id="L3114" title="All 2 branches missed.">        if (!Schema.instance.getKeyspaces().contains(keyspace))</span>
<span class="nc" id="L3115">            return false;</span>

<span class="nc" id="L3117">        final ColumnFamilyStore cfs = ColumnFamilyStore.getIfExists(keyspace, table);</span>
<span class="nc bnc" id="L3118" title="All 2 branches missed.">        if (cfs == null)</span>
<span class="nc" id="L3119">            return false;</span>

<span class="nc" id="L3121">        final ByteBuffer bytes = cfs.metadata.get().partitionKeyType.fromString(partitionKeyAsString);</span>
<span class="nc" id="L3122">        return partitionDenylist.removeKeyFromDenylist(keyspace, table, bytes);</span>
    }

    /**
     * A simple check for operators to determine what the denylisted value for a pk is on a node
     */
    public boolean isKeyDenylisted(String keyspace, String table, String partitionKeyAsString)
    {
<span class="nc bnc" id="L3130" title="All 2 branches missed.">        if (!Schema.instance.getKeyspaces().contains(keyspace))</span>
<span class="nc" id="L3131">            return false;</span>

<span class="nc" id="L3133">        final ColumnFamilyStore cfs = ColumnFamilyStore.getIfExists(keyspace, table);</span>
<span class="nc bnc" id="L3134" title="All 2 branches missed.">        if (cfs == null)</span>
<span class="nc" id="L3135">            return false;</span>

<span class="nc" id="L3137">        final ByteBuffer bytes = cfs.metadata.get().partitionKeyType.fromString(partitionKeyAsString);</span>
<span class="nc bnc" id="L3138" title="All 2 branches missed.">        return !partitionDenylist.isKeyPermitted(keyspace, table, bytes);</span>
    }

    @Override
    public void logBlockingReadRepairAttemptsForNSeconds(int seconds)
    {
<span class="nc" id="L3144">        logBlockingReadRepairAttemptsUntilNanos = nanoTime() + TimeUnit.SECONDS.toNanos(seconds);</span>
<span class="nc" id="L3145">    }</span>

    @Override
    public boolean isLoggingReadRepairs()
    {
<span class="pc bpc" id="L3150" title="1 of 2 branches missed.">        return nanoTime() &lt;= StorageProxy.instance.logBlockingReadRepairAttemptsUntilNanos;</span>
    }

    @Override
    public void setPaxosVariant(String variant)
    {
<span class="nc" id="L3156">        Preconditions.checkNotNull(variant);</span>
<span class="nc" id="L3157">        Paxos.setPaxosVariant(Config.PaxosVariant.valueOf(variant));</span>
<span class="nc" id="L3158">    }</span>

    @Override
    public String getPaxosVariant()
    {
<span class="nc" id="L3163">        return Paxos.getPaxosVariant().toString();</span>
    }

    @Override
    public boolean getUseStatementsEnabled()
    {
<span class="nc" id="L3169">        return DatabaseDescriptor.getUseStatementsEnabled();</span>
    }

    @Override
    public void setUseStatementsEnabled(boolean enabled)
    {
<span class="nc" id="L3175">        DatabaseDescriptor.setUseStatementsEnabled(enabled);</span>
<span class="nc" id="L3176">    }</span>

    public void setPaxosContentionStrategy(String spec)
    {
<span class="nc" id="L3180">        ContentionStrategy.setStrategy(spec);</span>
<span class="nc" id="L3181">    }</span>

    public String getPaxosContentionStrategy()
    {
<span class="nc" id="L3185">        return ContentionStrategy.getStrategySpec();</span>
    }

    @Override
    public void setPaxosCoordinatorLockingDisabled(boolean disabled)
    {
<span class="nc" id="L3191">        PaxosState.setDisableCoordinatorLocking(disabled);</span>
<span class="nc" id="L3192">    }</span>

    @Override
    public boolean getPaxosCoordinatorLockingDisabled()
    {
<span class="nc" id="L3197">        return PaxosState.getDisableCoordinatorLocking();</span>
    }

    @Override
    public boolean getDumpHeapOnUncaughtException()
    {
<span class="nc" id="L3203">        return DatabaseDescriptor.getDumpHeapOnUncaughtException();</span>
    }

    @Override
    public void setDumpHeapOnUncaughtException(boolean enabled)
    {
<span class="nc" id="L3209">        DatabaseDescriptor.setDumpHeapOnUncaughtException(enabled);</span>
<span class="nc" id="L3210">    }</span>

    @Override
    public boolean getSStableReadRatePersistenceEnabled()
    {
<span class="nc" id="L3215">        return DatabaseDescriptor.getSStableReadRatePersistenceEnabled();</span>
    }

    @Override
    public void setSStableReadRatePersistenceEnabled(boolean enabled)
    {
<span class="nc" id="L3221">        DatabaseDescriptor.setSStableReadRatePersistenceEnabled(enabled);</span>
<span class="nc" id="L3222">    }</span>

    @Override
    public boolean getClientRequestSizeMetricsEnabled()
    {
<span class="nc" id="L3227">        return DatabaseDescriptor.getClientRequestSizeMetricsEnabled();</span>
    }

    @Override
    public void setClientRequestSizeMetricsEnabled(boolean enabled)
    {
<span class="nc" id="L3233">        DatabaseDescriptor.setClientRequestSizeMetricsEnabled(enabled);</span>
<span class="nc" id="L3234">    }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>